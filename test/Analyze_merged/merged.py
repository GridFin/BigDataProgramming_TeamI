#!/usr/bin/env python
# coding: utf-8

# In[1]:


import os
import pandas as pd

data_dir = os.path.abspath("../../Data/LocalPeople")
print("ë°ì´í„° í´ë” ê²½ë¡œ:", data_dir)


def load_localpeople_quarter(year, quarter, data_dir):
    months = {
        1: ["01", "02", "03"],
        2: ["04", "05", "06"],
        3: ["07", "08", "09"],
        4: ["10", "11", "12"],
    }[quarter]

    dfs = []
    for m in months:
        filename = f"LOCAL_PEOPLE_DONG_{year}{m}.csv"
        file = os.path.join(data_dir, filename)

        if not os.path.exists(file):
            print(f"íŒŒì¼ ì—†ìŒ: {filename}")
            continue

        try:
            # ğŸ”¥ ì˜¬ë°”ë¥¸ CSV ì½ê¸° ë°©ì‹ (Analyze_LocalPeople.py ì°¸ì¡°)
            expected_cols = [
                "ê¸°ì¤€ì¼ID",
                "ì‹œê°„ëŒ€êµ¬ë¶„",
                "í–‰ì •ë™ì½”ë“œ",
                "ì´ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ë‚¨ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜",
                "ì—¬ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜",
            ]

            try:
                df = pd.read_csv(
                    file,
                    encoding="utf-8",
                    dtype={"ê¸°ì¤€ì¼ID": str, "ì‹œê°„ëŒ€êµ¬ë¶„": str, "í–‰ì •ë™ì½”ë“œ": str},
                    usecols=expected_cols,
                    header=0,
                )
            except:
                df = pd.read_csv(
                    file,
                    encoding="cp949",
                    dtype={"ê¸°ì¤€ì¼ID": str, "ì‹œê°„ëŒ€êµ¬ë¶„": str, "í–‰ì •ë™ì½”ë“œ": str},
                    usecols=expected_cols,
                    header=0,
                )

            df["í–‰ì •ë™ì½”ë“œ"] = df["í–‰ì •ë™ì½”ë“œ"].astype(str).str.zfill(8)
            selected_cols = ["í–‰ì •ë™ì½”ë“œ", "ì´ìƒí™œì¸êµ¬ìˆ˜"] + [
                col
                for col in df.columns
                if "ìƒí™œì¸êµ¬ìˆ˜" in col and ("ë‚¨ì" in col or "ì—¬ì" in col)
            ]
            df = df[selected_cols]
            dfs.append(df)
            print(f"{filename} ë¡œë“œ ì™„ë£Œ, {len(df)}í–‰")
        except Exception as e:
            print(f"{filename} ì½ê¸° ì‹¤íŒ¨: {e}")

    if not dfs:
        print(f"{year}ë…„ {quarter}ë¶„ê¸°: ìœ íš¨í•œ íŒŒì¼ ì—†ìŒ â†’ ê±´ë„ˆëœ€")
        return None

    merged = pd.concat(dfs)
    result = merged.groupby("í–‰ì •ë™ì½”ë“œ").sum().reset_index()
    result["ì—°ë„"] = year
    result["ë¶„ê¸°"] = quarter
    result["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] = int(f"{year}{quarter}")
    print(f"{year}ë…„ {quarter}ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, {len(result)}ê°œ í–‰ì •ë™")
    return result


all_local = []
for year in range(2019, 2025):
    for quarter in [1, 2, 3, 4]:
        print(f"\n{year}ë…„ {quarter}ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘")
        res = load_localpeople_quarter(year, quarter, data_dir)
        if res is not None:
            all_local.append(res)

if all_local:
    local_df = pd.concat(all_local, ignore_index=True)
    print(
        f"\nì „ì²´ ì™„ë£Œ: ì´ {len(local_df)}í–‰, {local_df['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'].nunique()}ê°œ ë¶„ê¸°"
    )
else:
    print("\nì˜¤ë¥˜: ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ ë˜ëŠ” íŒŒì¼ ëˆ„ë½ ì—¬ë¶€ í™•ì¸í•˜ì„¸ìš”.")


# In[2]:


from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
import joblib

company_path = os.path.abspath("../../Data/CompanyPeople/CompanyPeople.csv")
trading_dir = os.path.abspath("../../Data/Trading_Area")

# results í´ë” ìƒì„±
os.makedirs("results", exist_ok=True)

# ì§ì¥ì¸ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
company_df = pd.read_csv(company_path, encoding="euc-kr")
company_df["í–‰ì •ë™ì½”ë“œ"] = company_df["í–‰ì •ë™_ì½”ë“œ"].astype(str).str.zfill(8)
company_df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] = company_df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"].astype(int)


# ë³‘í•© í•¨ìˆ˜ ì •ì˜
def load_trading_area(year, trading_dir):
    file_path = os.path.join(trading_dir, f"Trading_Area_{year}.csv")
    df = pd.read_csv(file_path, encoding="utf-8")
    df["í–‰ì •ë™ì½”ë“œ"] = df["í–‰ì •ë™_ì½”ë“œ"].astype(str).str.zfill(8)
    df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] = df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"].astype(int)
    return df


# ë§ˆìŠ¤í„° ë°ì´í„° ìƒì„±
all_merged = []

for year in range(2019, 2025):
    trading_df = load_trading_area(year, trading_dir)

    for quarter in [1, 2, 3, 4]:
        quarter_code = int(f"{year}{quarter}")
        print(f"{quarter_code} ë³‘í•© ì¤‘...")

        # ë¶„ê¸°ë³„ ë°ì´í„° í•„í„°ë§
        trade_q = trading_df[trading_df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] == quarter_code].copy()
        local_q = local_df[local_df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] == quarter_code].copy()
        comp_q = company_df[company_df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] == quarter_code].copy()

        if trade_q.empty:
            print(f"ë§¤ì¶œ ë°ì´í„° ì—†ìŒ: {quarter_code}")
            continue

        # ë³‘í•©: ë§¤ì¶œ + ì‹¤ê±°ì£¼ (í–‰ì •ë™ì½”ë“œ + ë¶„ê¸° ê¸°ì¤€)
        merged = pd.merge(
            trade_q,
            local_q,
            on=["í–‰ì •ë™ì½”ë“œ", "ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"],
            how="left",
        )

        # ë³‘í•©: + ì§ì¥ì¸ (ë™ì¼í•˜ê²Œ í–‰ì •ë™ì½”ë“œ + ë¶„ê¸° ê¸°ì¤€)
        merged = pd.merge(
            merged,
            comp_q,
            on=["í–‰ì •ë™ì½”ë“œ", "ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"],
            how="left",
        )

        print(f"â†’ ë³‘í•© ì™„ë£Œ: {len(merged)}í–‰")
        all_merged.append(merged)

# ë§ˆìŠ¤í„° ë°ì´í„°í”„ë ˆì„ ì™„ì„±
master_df = pd.concat(all_merged, ignore_index=True)
print(f"\nìµœì¢… ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ í¬ê¸°: {master_df.shape}")


# In[3]:


X_all = master_df.drop(columns=["ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡"])
X_all_numeric = X_all.select_dtypes(include=["number"])

print("ì „ì²´ ì»¬ëŸ¼ ìˆ˜:", X_all.shape[1])
print("ìˆ«ìí˜• ì»¬ëŸ¼ ìˆ˜:", X_all_numeric.shape[1])
print("ìˆ«ìí˜• ì»¬ëŸ¼ ì´ë¦„:\n", list(X_all_numeric.columns))


# In[4]:


non_numeric_cols = X_all.select_dtypes(exclude=["number"]).columns.tolist()
numeric_cols = X_all.select_dtypes(include=["number"]).columns.tolist()

print("ìˆ«ìí˜• ì»¬ëŸ¼ ìˆ˜:", len(numeric_cols))
print("ë¹„ìˆ«ìí˜• ì»¬ëŸ¼ ìˆ˜:", len(non_numeric_cols))
print("ë¹„ìˆ«ìí˜• ì»¬ëŸ¼ ëª©ë¡:\n", non_numeric_cols)


# In[5]:


def preprocess_master(df, test_year=2024):
    df = df.copy(deep=False)

    drop_cols = [
        "í–‰ì •ë™_ì½”ë“œ_ëª…",
        "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…",
        "í–‰ì •ë™ëª…",
        "í–‰ì •ë™_ì½”ë“œ_ëª…_x",
        "í–‰ì •ë™_ì½”ë“œ_ëª…_y",
    ]
    leakage_cols = [
        col for col in df.columns if "ë§¤ì¶œ" in col and col != "ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡"
    ]
    df.drop(
        columns=[col for col in drop_cols + leakage_cols if col in df.columns],
        inplace=True,
    )

    if "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ" in df.columns:
        le = LabelEncoder()
        df["ì—…ì¢…ì½”ë“œ_encoded"] = le.fit_transform(df["ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"].astype(str))
        df.drop(columns=["ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"], inplace=True)
        joblib.dump(le, "results/label_encoder.joblib")

    y_all = df["ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡"].reset_index(drop=True)
    quarter_col = df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"].reset_index(drop=True)

    X_all = df.drop(columns=["ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡"])
    X_all_numeric = X_all.select_dtypes(include=["number"]).copy()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Imputer: fit on train only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    train_mask = quarter_col < test_year * 10 + 1
    test_mask = ~train_mask

    imputer = SimpleImputer(strategy="mean")
    X_train = pd.DataFrame(
        imputer.fit_transform(X_all_numeric[train_mask]),
        columns=X_all_numeric.columns,
        index=X_all_numeric[train_mask].index,
    )
    X_test = pd.DataFrame(
        imputer.transform(X_all_numeric[test_mask]),
        columns=X_all_numeric.columns,
        index=X_all_numeric[test_mask].index,
    )
    joblib.dump(imputer, "results/imputer.joblib")

    y_train = y_all[train_mask]
    y_test = y_all[test_mask]

    print(
        f"í•™ìŠµìš©: {len(X_train)}í–‰ / ê²€ì¦ìš©: {len(X_test)}í–‰ / íŠ¹ì„± ìˆ˜: {X_train.shape[1]}"
    )
    return X_train, X_test, y_train, y_test, quarter_col[test_mask]


# In[6]:


X_train, X_test, y_train, y_test, quarter_test = preprocess_master(master_df)


# In[7]:


from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np

# ë¡œê·¸ ë³€í™˜í•˜ì—¬ í•™ìŠµ
y_train_log = np.log1p(y_train.clip(lower=0))

# ëª¨ë¸ ì •ì˜
model = RandomForestRegressor(
    n_estimators=100, max_depth=15, random_state=42, n_jobs=-1, oob_score=True
)

print("ëª¨ë¸ í•™ìŠµ ì¤‘...")
model.fit(X_train, y_train_log)
print("í•™ìŠµ ì™„ë£Œ")

# ì˜ˆì¸¡ ë° ë¡œê·¸ ì—­ë³€í™˜
y_pred_log = model.predict(X_test)
y_pred = np.expm1(y_pred_log).clip(min=0)

# í‰ê°€ ì§€í‘œ ê³„ì‚°
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)

print("\nëª¨ë¸ í‰ê°€ ê²°ê³¼")
print(f"MSE:  {mse:,.0f}")
print(f"RMSE: {rmse:,.0f} ì›")
print(f"MAE:  {mae:,.0f} ì›")
print(f"OOB Score: {model.oob_score_:.4f}")


# In[8]:


# ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½ì„ ìœ„í•œ ë©”íƒ€ ì •ë³´ ì¶”ì¶œ
meta_cols = ["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ", "í–‰ì •ë™ì½”ë“œ", "í–‰ì •ë™_ì½”ë“œ_ëª…_x", "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"]
test_meta = master_df[master_df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"].isin(quarter_test)].copy()
test_meta = test_meta[meta_cols].reset_index(drop=True)

# ì˜ˆì¸¡ ê²°ê³¼ ê²°í•©
test_meta["ì˜ˆì¸¡_ë§¤ì¶œ"] = y_pred
test_meta["ì‹¤ì œ_ë§¤ì¶œ"] = y_test.reset_index(drop=True)
test_meta["ì—°ë„"] = test_meta["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] // 10

# ì—°ë„+ë™+ì—…ì¢… ë‹¨ìœ„ë¡œ ì§‘ê³„
summary_2024 = (
    test_meta.groupby(["ì—°ë„", "í–‰ì •ë™ì½”ë“œ", "í–‰ì •ë™_ì½”ë“œ_ëª…_x", "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"])
    .agg(ì´ë§¤ì¶œ=("ì‹¤ì œ_ë§¤ì¶œ", "sum"), ì˜ˆì¸¡_ì´ë§¤ì¶œ=("ì˜ˆì¸¡_ë§¤ì¶œ", "sum"))
    .reset_index()
)

# ìˆœìœ„: í–‰ì •ë™ë³„ ì—…ì¢… ìˆœìœ„
summary_2024["ìˆœìœ„"] = summary_2024.groupby(["ì—°ë„", "í–‰ì •ë™ì½”ë“œ"])["ì˜ˆì¸¡_ì´ë§¤ì¶œ"].rank(
    ascending=False, method="min"
)

# ê²°ê³¼ ì •ë¦¬
df_2024_result = summary_2024.rename(
    columns={"í–‰ì •ë™_ì½”ë“œ_ëª…_x": "í–‰ì •ë™ëª…", "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ": "ì—…ì¢…"}
)[["ì—°ë„", "í–‰ì •ë™ì½”ë“œ", "í–‰ì •ë™ëª…", "ì—…ì¢…", "ì˜ˆì¸¡_ì´ë§¤ì¶œ", "ìˆœìœ„"]]


print(df_2024_result.head())


# In[9]:


# master_dfì—ì„œ ì—…ì¢… ì½”ë“œ â†” ì—…ì¢…ëª… ë§µí•‘ ì¶”ì¶œ
ì—…ì¢…ì½”ë“œ_ë§¤í•‘ = master_df[["ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ", "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…"]].drop_duplicates()

# df_2024_resultì— ì—…ì¢…ëª… ë¶™ì´ê¸°
df_2024_result = pd.merge(
    df_2024_result,
    ì—…ì¢…ì½”ë“œ_ë§¤í•‘,
    how="left",
    left_on="ì—…ì¢…",
    right_on="ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ",
).drop(columns=["ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"])

# ì»¬ëŸ¼ëª… ì •ë¦¬
df_2024_result = df_2024_result.rename(columns={"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…": "ì—…ì¢…ëª…"})


# In[10]:


# 1. 2019~2023 ì‹¤ì œ ë§¤ì¶œ ìš”ì•½
train_meta_cols = [
    "ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ",
    "í–‰ì •ë™ì½”ë“œ",
    "í–‰ì •ë™_ì½”ë“œ_ëª…_x",
    "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ",
    "ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡",
]
train_meta = master_df[master_df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] < 20241].copy()
train_meta = train_meta[train_meta_cols].copy()
train_meta["ì—°ë„"] = train_meta["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] // 10

summary_2019_2023 = (
    train_meta.groupby(["ì—°ë„", "í–‰ì •ë™ì½”ë“œ", "í–‰ì •ë™_ì½”ë“œ_ëª…_x", "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"])
    .agg(ì´ë§¤ì¶œ=("ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡", "sum"))
    .reset_index()
)

summary_2019_2023 = summary_2019_2023.rename(
    columns={"í–‰ì •ë™_ì½”ë“œ_ëª…_x": "í–‰ì •ë™ëª…", "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ": "ì—…ì¢…"}
)

# 2. ì—…ì¢…ëª… ë¶™ì´ê¸°
summary_2019_2023 = pd.merge(
    summary_2019_2023,
    ì—…ì¢…ì½”ë“œ_ë§¤í•‘,
    how="left",
    left_on="ì—…ì¢…",
    right_on="ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ",
).drop(columns=["ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"])

summary_2019_2023 = summary_2019_2023.rename(columns={"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…": "ì—…ì¢…ëª…"})

# 3. í–‰ì •ë™ ë‚´ ì—…ì¢…ë³„ ìˆœìœ„ ê³„ì‚°
summary_2019_2023["ìˆœìœ„"] = summary_2019_2023.groupby(["ì—°ë„", "í–‰ì •ë™ì½”ë“œ"])[
    "ì´ë§¤ì¶œ"
].rank(ascending=False, method="min")

# 4. 2024 ì˜ˆì¸¡ ê²°ê³¼ í¬ë§· ë§ì¶”ê¸°
df_2024_actual = df_2024_result.rename(columns={"ì˜ˆì¸¡_ì´ë§¤ì¶œ": "ì´ë§¤ì¶œ"})

# 5. 2019~2024 í†µí•©
df_2019_2024 = pd.concat([summary_2019_2023, df_2024_actual], ignore_index=True)

# 6. í™•ì¸ + ì—°ë„ ì •ìˆ˜ ì²˜ë¦¬
df_2019_2024["ì—°ë„"] = df_2019_2024["ì—°ë„"].astype(int)
df_2019_2024.head()


# In[11]:


# ì—°ë„ ìˆœìœ¼ë¡œ ì •ë ¬ í›„ ì €ì¥
df_2019_2024_sorted = df_2019_2024.sort_values(by=["ì—°ë„", "í–‰ì •ë™ì½”ë“œ", "ìˆœìœ„"])
df_2019_2024_sorted.to_csv("analysis_2019_2024.csv", index=False, encoding="utf-8-sig")


# In[12]:


# 1. 2023~2024ë…„ ë°ì´í„° ê¸°ë°˜
df_recent = master_df[master_df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] >= 20231].copy()

# 2. ì €ì¥ëœ LabelEncoder ë¡œë“œ (ë¦¬í‚¤ì§€ ë°©ì§€)
le = joblib.load("results/label_encoder.joblib")
df_recent["ì—…ì¢…ì½”ë“œ_encoded"] = le.transform(df_recent["ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"].astype(str))

# 3. ê¸°ë³¸ ë©”íƒ€ ì •ë³´: í–‰ì •ë™ + ì—…ì¢… ì¡°í•©
meta_cols = ["í–‰ì •ë™ì½”ë“œ", "í–‰ì •ë™_ì½”ë“œ_ëª…_x", "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"]
df_meta = df_recent[meta_cols].drop_duplicates()

# 4. ì…ë ¥ íŠ¹ì„± í‰ê· ê°’ ê³„ì‚°
feature_cols = X_train.columns.tolist()
X_recent = df_recent[feature_cols + meta_cols].copy()
X_avg = (
    X_recent.groupby(["í–‰ì •ë™ì½”ë“œ", "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"])[feature_cols]
    .mean()
    .reset_index()
)

# 5. ë©”íƒ€ì •ë³´ì™€ í‰ê· ê°’ ë³‘í•© â†’ X_2025 êµ¬ì„±
df_2025_input = pd.merge(
    df_meta, X_avg, on=["í–‰ì •ë™ì½”ë“œ", "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"], how="inner"
)
df_2025_input["ì—°ë„"] = 2025

# 6. ì˜ˆì¸¡
X_2025 = df_2025_input[feature_cols]
y_2025_log = model.predict(X_2025)
y_2025 = np.expm1(y_2025_log).clip(min=0)

# 7. ê²°ê³¼ êµ¬ì„±
df_2025_result = df_2025_input[
    ["ì—°ë„", "í–‰ì •ë™ì½”ë“œ", "í–‰ì •ë™_ì½”ë“œ_ëª…_x", "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"]
].copy()
df_2025_result["ì˜ˆì¸¡_ì´ë§¤ì¶œ"] = y_2025

# 8. ì—…ì¢…ëª… ë¶™ì´ê¸° (ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ ìœ ì§€í•˜ë©´ì„œ merge)
df_2025_result = pd.merge(
    df_2025_result,
    ì—…ì¢…ì½”ë“œ_ë§¤í•‘,
    how="left",
    left_on="ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ",
    right_on="ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ",
)

# 9. ì»¬ëŸ¼ ì •ë¦¬ ë° ìˆœìœ„ ê³„ì‚°
df_2025_result = df_2025_result.rename(
    columns={
        "í–‰ì •ë™_ì½”ë“œ_ëª…_x": "í–‰ì •ë™ëª…",
        "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ": "ì—…ì¢…",
        "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…": "ì—…ì¢…ëª…",
    }
)

df_2025_result["ìˆœìœ„"] = df_2025_result.groupby("í–‰ì •ë™ì½”ë“œ")["ì˜ˆì¸¡_ì´ë§¤ì¶œ"].rank(
    ascending=False, method="min"
)

df_2025_result = df_2025_result[
    ["ì—°ë„", "í–‰ì •ë™ì½”ë“œ", "í–‰ì •ë™ëª…", "ì—…ì¢…", "ì—…ì¢…ëª…", "ì˜ˆì¸¡_ì´ë§¤ì¶œ", "ìˆœìœ„"]
]

# 10. ì €ì¥
df_2025_sorted = df_2025_result.sort_values(by=["í–‰ì •ë™ì½”ë“œ", "ìˆœìœ„"])
df_2025_sorted.to_csv("prediction_2025.csv", index=False, encoding="utf-8-sig")


# í™•ì¸
df_2025_result.head()
