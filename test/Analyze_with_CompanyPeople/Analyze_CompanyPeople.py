import os
import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
import warnings
import gc
import joblib
from datetime import datetime

warnings.filterwarnings("ignore")


def load_companypeople_quarterly_fixed(year, quarter, people_dir):
    """ìˆ˜ì •ëœ ë¶„ê¸°ë³„ CompanyPeople ë°ì´í„° ë¡œë“œ"""

    file_path = os.path.join(people_dir, "CompanyPeople.csv")

    if not os.path.exists(file_path):
        print(f"    âŒ CompanyPeople íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
        return None

    print(f"    {year}ë…„ {quarter}ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...")

    try:
        # CSV ì½ê¸° - euc-kr ì¸ì½”ë”© ìš°ì„  ì‹œë„
        try:
            df = pd.read_csv(file_path, encoding="euc-kr")
        except:
            try:
                df = pd.read_csv(file_path, encoding="cp949")
            except:
                df = pd.read_csv(file_path, encoding="utf-8")

        # í•´ë‹¹ ë…„ë„/ë¶„ê¸° ë°ì´í„° í•„í„°ë§
        quarter_code = int(f"{year}{quarter}")
        df_filtered = df[df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] == quarter_code].copy()

        if len(df_filtered) == 0:
            print(f"    âŒ {year}ë…„ {quarter}ë¶„ê¸° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None

        # í–‰ì •ë™ì½”ë“œ ì •ë¦¬
        df_filtered["í–‰ì •ë™ì½”ë“œ"] = df_filtered["í–‰ì •ë™_ì½”ë“œ"].astype(str).str.zfill(8)

        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = [
            "ì´_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ë‚¨ì„±_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ì—¬ì„±_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ì—°ë ¹ëŒ€_10_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ì—°ë ¹ëŒ€_20_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ì—°ë ¹ëŒ€_30_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ì—°ë ¹ëŒ€_40_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ì—°ë ¹ëŒ€_50_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ì—°ë ¹ëŒ€_60_ì´ìƒ_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ë‚¨ì„±ì—°ë ¹ëŒ€_10_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ë‚¨ì„±ì—°ë ¹ëŒ€_20_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ë‚¨ì„±ì—°ë ¹ëŒ€_30_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ë‚¨ì„±ì—°ë ¹ëŒ€_40_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ë‚¨ì„±ì—°ë ¹ëŒ€_50_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ë‚¨ì„±ì—°ë ¹ëŒ€_60_ì´ìƒ_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ì—¬ì„±ì—°ë ¹ëŒ€_10_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ì—¬ì„±ì—°ë ¹ëŒ€_20_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ì—¬ì„±ì—°ë ¹ëŒ€_30_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ì—¬ì„±ì—°ë ¹ëŒ€_40_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ì—¬ì„±ì—°ë ¹ëŒ€_50_ì§ì¥_ì¸êµ¬_ìˆ˜",
            "ì—¬ì„±ì—°ë ¹ëŒ€_60_ì´ìƒ_ì§ì¥_ì¸êµ¬_ìˆ˜",
        ]

        keep_cols = ["í–‰ì •ë™ì½”ë“œ"] + [
            col for col in numeric_cols if col in df_filtered.columns
        ]
        result_df = df_filtered[keep_cols].copy()

        print(
            f"    âœ… {year}ë…„ {quarter}ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(result_df)}ê°œ í–‰ì •ë™"
        )
        return result_df

    except Exception as e:
        print(f"    âŒ {year}ë…„ {quarter}ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def load_trading_area_data(year, biz_dir):
    """Trading Area ë°ì´í„° ë¡œë“œ"""
    file_path = os.path.join(biz_dir, f"Trading_Area_{year}.csv")

    if not os.path.exists(file_path):
        return None

    try:
        try:
            df = pd.read_csv(file_path, encoding="utf-8")
        except:
            df = pd.read_csv(file_path, encoding="cp949")

        df = df.rename(columns={"í–‰ì •ë™_ì½”ë“œ": "í–‰ì •ë™ì½”ë“œ"})
        df["í–‰ì •ë™ì½”ë“œ"] = df["í–‰ì •ë™ì½”ë“œ"].astype(str).str.zfill(8)

        print(f"  Trading Area {year} ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰")
        return df

    except Exception as e:
        print(f"  Trading Area {year} ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None


def create_master_dataset_fixed(years, people_dir, biz_dir):
    """ìˆ˜ì •ëœ ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± (CompanyPeople ë²„ì „)"""
    print("=== CompanyPeople ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘ ===")

    all_data = []

    for year in years:
        print(f"\nğŸ“… {year}ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...")

        # Trading Area ë°ì´í„° ë¡œë“œ
        biz_df = load_trading_area_data(year, biz_dir)
        if biz_df is None:
            continue

        # ê° ë¶„ê¸°ë³„ë¡œ ì²˜ë¦¬
        for quarter in [1, 2, 3, 4]:
            print(f"  ğŸ”„ {year}ë…„ {quarter}ë¶„ê¸° ì²˜ë¦¬ ì¤‘...")

            # í•´ë‹¹ ë¶„ê¸° Trading Area ë°ì´í„° í•„í„°ë§
            quarter_code = int(f"{year}{quarter}")
            biz_quarter = biz_df[biz_df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] == quarter_code].copy()

            if len(biz_quarter) == 0:
                print(f"    âŒ {year}ë…„ {quarter}ë¶„ê¸° ë§¤ì¶œ ë°ì´í„° ì—†ìŒ")
                continue

            # CompanyPeople ë°ì´í„° ë¡œë“œ
            people_quarter = load_companypeople_quarterly_fixed(
                year, quarter, people_dir
            )

            if people_quarter is None:
                print(f"    âŒ {year}ë…„ {quarter}ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ì—†ìŒ")
                continue

            # ë°ì´í„° ë³‘í•©
            merged_data = pd.merge(
                biz_quarter, people_quarter, on="í–‰ì •ë™ì½”ë“œ", how="left"
            )

            # ë³‘í•© ê²°ê³¼ í™•ì¸
            people_cols = [col for col in people_quarter.columns if col != "í–‰ì •ë™ì½”ë“œ"]
            if people_cols:
                people_match_rate = (
                    (~merged_data[people_cols[0]].isna()).sum() / len(merged_data) * 100
                )
            else:
                people_match_rate = 0

            print(
                f"    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ {len(biz_quarter)} + ì§ì¥ì¸êµ¬ {len(people_quarter)} â†’ {len(merged_data)}í–‰"
            )
            print(f"    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : {people_match_rate:.1f}%")

            all_data.append(merged_data)

            # ë©”ëª¨ë¦¬ ì •ë¦¬
            del biz_quarter, people_quarter, merged_data
            gc.collect()

    if not all_data:
        raise ValueError("ìƒì„±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")

    # ì „ì²´ ë°ì´í„° ê²°í•©
    print("\nğŸ”— ì „ì²´ ë°ì´í„° ê²°í•© ì¤‘...")
    final_df = pd.concat(all_data, ignore_index=True)
    print(f"âœ… ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {final_df.shape}")

    return final_df


def preprocess_data_fixed(df):
    """ìˆ˜ì •ëœ ë°ì´í„° ì „ì²˜ë¦¬ (CompanyPeople ë²„ì „)"""
    print("\n=== ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ===")
    print(f"ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}")

    # íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸
    if "ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡" not in df.columns:
        raise ValueError("íƒ€ê²Ÿ ë³€ìˆ˜ 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'ì´ ì—†ìŠµë‹ˆë‹¤!")

    # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° + ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€
    drop_cols = ["í–‰ì •ë™_ì½”ë“œ_ëª…", "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…"]

    # ğŸ”¥ ë§¤ì¶œ ê´€ë ¨ íŠ¹ì„± ì œê±° (ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€)
    sales_cols = [
        col
        for col in df.columns
        if any(
            keyword in col
            for keyword in [
                "ë§¤ì¶œ_ê¸ˆì•¡",
                "ë§¤ì¶œ_ê±´ìˆ˜",
                "ì›”ìš”ì¼_",
                "í™”ìš”ì¼_",
                "ìˆ˜ìš”ì¼_",
                "ëª©ìš”ì¼_",
                "ê¸ˆìš”ì¼_",
                "í† ìš”ì¼_",
                "ì¼ìš”ì¼_",
                "ì£¼ì¤‘_",
                "ì£¼ë§_",
                "ì‹œê°„ëŒ€_",
                "ë‚¨ì„±_ë§¤ì¶œ",
                "ì—¬ì„±_ë§¤ì¶œ",
                "ì—°ë ¹ëŒ€_",
            ]
        )
    ]

    # íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ìœ ì§€
    sales_cols = [col for col in sales_cols if col != "ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡"]

    print(f"ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€ë¥¼ ìœ„í•´ ì œê±°í•  ë§¤ì¶œ ê´€ë ¨ ì»¬ëŸ¼: {len(sales_cols)}ê°œ")
    print(f"ì œê±° ì»¬ëŸ¼ ì˜ˆì‹œ: {sales_cols[:5]}")

    drop_cols.extend(sales_cols)
    df = df.drop(columns=[col for col in drop_cols if col in df.columns])

    # ê²°ì¸¡ê°’ì´ ë„ˆë¬´ ë§ì€ ì»¬ëŸ¼ ì œê±° (70% ì´ìƒ)
    null_ratio = df.isnull().mean()
    high_null_cols = null_ratio[null_ratio > 0.7].index.tolist()
    print(f"ê²°ì¸¡ë¥  70% ì´ìƒ ì»¬ëŸ¼ ì œê±°: {len(high_null_cols)}ê°œ")
    if high_null_cols:
        df = df.drop(columns=high_null_cols)

    # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
    if "ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ" in df.columns:
        le = LabelEncoder()
        df["ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_encoded"] = le.fit_transform(
            df["ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"].astype(str)
        )
        df = df.drop(columns=["ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ"])

    # CompanyPeople ê´€ë ¨ ì»¬ëŸ¼ í™•ì¸
    people_cols = [
        col
        for col in df.columns
        if any(
            keyword in col
            for keyword in ["ì§ì¥_ì¸êµ¬_ìˆ˜", "ë‚¨ì„±_ì§ì¥", "ì—¬ì„±_ì§ì¥", "ì—°ë ¹ëŒ€_"]
        )
    ]
    print(f"ğŸ“Š CompanyPeople ê´€ë ¨ ì»¬ëŸ¼: {len(people_cols)}ê°œ")

    if len(people_cols) == 0:
        print("âš ï¸ ê²½ê³ : CompanyPeople ë°ì´í„°ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    else:
        print("âœ… CompanyPeople ë°ì´í„° í¬í•¨ í™•ì¸ë¨")
        # ëª‡ ê°œ ì»¬ëŸ¼ëª… ì¶œë ¥
        sample_cols = people_cols[:5]
        print(f"   ì˜ˆì‹œ: {sample_cols}")

    print(f"ì „ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: {df.shape}")
    return df


def train_and_evaluate_model_fixed(X_train, y_train, X_test, y_test):
    """ìˆ˜ì •ëœ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ (CompanyPeople ë²„ì „)"""
    print("\n=== ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ===")
    print(f"í›ˆë ¨ ë°ì´í„°: {X_train.shape}, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}")

    # íƒ€ê²Ÿ ë³€ìˆ˜ ë¡œê·¸ ë³€í™˜
    y_train_log = np.log1p(y_train.clip(lower=0))

    # RandomForest ëª¨ë¸
    model = RandomForestRegressor(
        n_estimators=100, max_depth=15, random_state=42, n_jobs=-1, oob_score=True
    )

    print("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    model.fit(X_train, y_train_log)
    print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")

    # ì˜ˆì¸¡
    print("ğŸ”® ì˜ˆì¸¡ ì¤‘...")
    y_pred_log = model.predict(X_test)
    y_pred = np.expm1(y_pred_log)
    y_pred = np.clip(y_pred, 0, None)  # ìŒìˆ˜ ì œê±°

    # ì„±ëŠ¥ í‰ê°€
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)

    print("\n" + "=" * 60)
    print("ğŸ¯ CompanyPeople ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼")
    print("=" * 60)
    print(f"MSE:  {mse:,.0f}")
    print(f"RMSE: {rmse:,.0f} ì›")
    print(f"MAE:  {mae:,.0f} ì›")
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê·  ë§¤ì¶œ: {y_test.mean():,.0f} ì›")
    print(f"Out-of-Bag Score: {model.oob_score_:.4f}")

    # ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ì¶œë ¥
    feature_importance = pd.DataFrame(
        {"feature": X_train.columns, "importance": model.feature_importances_}
    ).sort_values("importance", ascending=False)

    print(f"\n--- ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ---")
    for i, (_, row) in enumerate(feature_importance.head(20).iterrows(), 1):
        is_people = any(
            keyword in row["feature"]
            for keyword in ["ì§ì¥_ì¸êµ¬_ìˆ˜", "ë‚¨ì„±_ì§ì¥", "ì—¬ì„±_ì§ì¥", "ì—°ë ¹ëŒ€_"]
        )
        marker = "ğŸ¢" if is_people else "ğŸª"
        print(f"{i:2d}. {marker} {row['feature'][:50]}: {row['importance']:.4f}")

    # CompanyPeople ë°ì´í„° ê¸°ì—¬ë„
    people_features = feature_importance[
        feature_importance["feature"].str.contains(
            "ì§ì¥_ì¸êµ¬_ìˆ˜|ë‚¨ì„±_ì§ì¥|ì—¬ì„±_ì§ì¥|ì—°ë ¹ëŒ€_", regex=True
        )
    ]
    people_importance = people_features["importance"].sum()

    print(
        f"\nğŸ“Š CompanyPeople ë°ì´í„° ì´ ê¸°ì—¬ë„: {people_importance:.4f} ({people_importance*100:.1f}%)"
    )

    if people_importance < 0.05:
        print("âš ï¸ CompanyPeople ë°ì´í„° ê¸°ì—¬ë„ê°€ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤.")
    elif people_importance < 0.15:
        print("ğŸ”¶ CompanyPeople ë°ì´í„° ê¸°ì—¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.")
    else:
        print("âœ… CompanyPeople ë°ì´í„°ê°€ ìœ ì˜ë¯¸í•˜ê²Œ ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.")

    return (
        model,
        {"mse": mse, "rmse": rmse, "mae": mae},
        feature_importance,
        people_importance,
    )


def save_model_and_metrics(
    model, metrics, feature_importance_df, people_importance, config
):
    """ëª¨ë¸ê³¼ í‰ê°€ì§€í‘œ ì €ì¥ (CompanyPeople ë²„ì „)"""

    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
    script_dir = os.path.dirname(os.path.abspath(__file__))
    results_dir = os.path.join(script_dir, "results")
    if not os.path.exists(results_dir):
        os.makedirs(results_dir)
        print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±: {results_dir}")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # 1. ëª¨ë¸ ì €ì¥
    model_filename = os.path.join(
        results_dir, f"companypeople_model_{timestamp}.joblib"
    )
    joblib.dump(model, model_filename)
    print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_filename}")

    # 2. í‰ê°€ì§€í‘œ CSV ì €ì¥
    metrics_data = {
        "ì‹¤í–‰ì‹œê°„": [timestamp],
        "MSE": [metrics["mse"]],
        "RMSE": [metrics["rmse"]],
        "MAE": [metrics["mae"]],
        "CompanyPeople_ê¸°ì—¬ë„": [people_importance],
        "CompanyPeople_ê¸°ì—¬ë„_í¼ì„¼íŠ¸": [people_importance * 100],
        "OOB_Score": [model.oob_score_],
        "í…ŒìŠ¤íŠ¸_ë…„ë„": [config["test_year"]],
        "í›ˆë ¨_ë°ì´í„°_í¬ê¸°": [config["train_size"]],
        "í…ŒìŠ¤íŠ¸_ë°ì´í„°_í¬ê¸°": [config["test_size"]],
        "íŠ¹ì„±_ê°œìˆ˜": [config["n_features"]],
    }

    metrics_df = pd.DataFrame(metrics_data)
    metrics_filename = os.path.join(
        results_dir, f"companypeople_metrics_{timestamp}.csv"
    )
    metrics_df.to_csv(metrics_filename, index=False, encoding="utf-8-sig")
    print(f"ğŸ“Š í‰ê°€ì§€í‘œ CSV ì €ì¥ ì™„ë£Œ: {metrics_filename}")

    # 3. íŠ¹ì„± ì¤‘ìš”ë„ ì €ì¥
    importance_filename = os.path.join(
        results_dir, f"companypeople_importance_{timestamp}.csv"
    )
    feature_importance_df.to_csv(importance_filename, index=False, encoding="utf-8-sig")
    print(f"ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ CSV ì €ì¥ ì™„ë£Œ: {importance_filename}")

    # 4. ì‹¤í–‰ ì •ë³´ ìš”ì•½ ì €ì¥
    summary_data = {
        "í•­ëª©": [
            "ì‹¤í–‰ì‹œê°„",
            "MSE",
            "RMSE (ì›)",
            "MAE (ì›)",
            "CompanyPeople ê¸°ì—¬ë„ (%)",
            "OOB Score",
            "í…ŒìŠ¤íŠ¸ ë…„ë„",
            "í›ˆë ¨ ë°ì´í„° í¬ê¸°",
            "í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°",
            "íŠ¹ì„± ê°œìˆ˜",
        ],
        "ê°’": [
            timestamp,
            f"{metrics['mse']:,.0f}",
            f"{metrics['rmse']:,.0f}",
            f"{metrics['mae']:,.0f}",
            f"{people_importance*100:.1f}%",
            f"{model.oob_score_:.4f}",
            config["test_year"],
            f"{config['train_size']:,}",
            f"{config['test_size']:,}",
            config["n_features"],
        ],
    }

    summary_df = pd.DataFrame(summary_data)
    summary_filename = os.path.join(
        results_dir, f"companypeople_summary_{timestamp}.csv"
    )
    summary_df.to_csv(summary_filename, index=False, encoding="utf-8-sig")
    print(f"ğŸ“‹ ëª¨ë¸ ìš”ì•½ CSV ì €ì¥ ì™„ë£Œ: {summary_filename}")

    print(f"\nğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ '{results_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
    return {
        "model_file": model_filename,
        "metrics_file": metrics_filename,
        "importance_file": importance_filename,
        "summary_file": summary_filename,
    }


def main():
    """main í•¨ìˆ˜ (CompanyPeople ë²„ì „)"""
    print("ğŸš€ CompanyPeople ìƒê¶Œ ë§¤ì¶œ ì˜ˆì¸¡ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸")
    print("=" * 50)

    # ì„¤ì •
    YEARS = range(2019, 2025)
    PEOPLE_DIR = "Data/CompanyPeople"
    BIZ_DIR = "Data/Trading_Area"
    TEST_YEAR = 2024

    try:
        # 1. ë°ì´í„° ë¡œë“œ ë° ë³‘í•©
        master_df = create_master_dataset_fixed(YEARS, PEOPLE_DIR, BIZ_DIR)

        # 2. ë°ì´í„° ì „ì²˜ë¦¬
        processed_df = preprocess_data_fixed(master_df)

        # 3. ë°ì´í„° ë¶„í• 
        print(f"\n=== ë°ì´í„° ë¶„í•  ({TEST_YEAR}ë…„ í…ŒìŠ¤íŠ¸) ===")
        train_mask = processed_df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] < (TEST_YEAR * 10 + 1)
        test_mask = processed_df["ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ"] >= (TEST_YEAR * 10 + 1)

        train_df = processed_df[train_mask].copy()
        test_df = processed_df[test_mask].copy()

        print(f"í›ˆë ¨ ë°ì´í„°: {len(train_df)}í–‰")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}í–‰")

        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬
        target_col = "ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡"
        feature_cols = [col for col in train_df.columns if col != target_col]

        X_train = train_df[feature_cols]
        y_train = train_df[target_col]
        X_test = test_df[feature_cols]
        y_test = test_df[target_col]

        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        print("ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...")
        imputer = SimpleImputer(strategy="mean")
        X_train_filled = pd.DataFrame(
            imputer.fit_transform(X_train), columns=X_train.columns
        )
        X_test_filled = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)

        # 4. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
        model, metrics, feature_importance, people_importance = (
            train_and_evaluate_model_fixed(
                X_train_filled, y_train, X_test_filled, y_test
            )
        )

        print("\nğŸ‰ CompanyPeople ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
        print("=" * 50)

        # 5. ëª¨ë¸ ë° ê²°ê³¼ ì €ì¥
        config = {
            "test_year": TEST_YEAR,
            "train_size": len(train_df),
            "test_size": len(test_df),
            "n_features": len(feature_cols),
        }
        result = save_model_and_metrics(
            model, metrics, feature_importance, people_importance, config
        )

        print("\nğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("=" * 50)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
