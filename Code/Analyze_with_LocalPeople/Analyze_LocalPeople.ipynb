{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7890dd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜ ì•ˆ í–ˆë‹¤ë©´ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰ì‹œí‚¤ì„¸ìš”.\n",
    "# !pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e9e5d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… LocalPeople í´ë”ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ìƒëµ.\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ê±°ì£¼ ì¸êµ¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "base_dir = \"../../Data\"\n",
    "localpeople_dir = os.path.join(base_dir, \"LocalPeople\")\n",
    "zip_url = \"https://huggingface.co/datasets/uhjin1130/LocalPeople/resolve/main/LocalPeople.zip\"\n",
    "zip_path = os.path.join(localpeople_dir, \"LocalPeople.zip\")\n",
    "\n",
    "# LocalPeople í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„± ë° ë‹¤ìš´ë¡œë“œ\n",
    "if not os.path.exists(localpeople_dir):\n",
    "    print(\"ğŸ“ LocalPeople í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ ì‹œì‘...\")\n",
    "\n",
    "    os.makedirs(localpeople_dir, exist_ok=True)\n",
    "\n",
    "    # ë‹¤ìš´ë¡œë“œ\n",
    "    print(\"ğŸ”½ LocalPeople.zip ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "    response = requests.get(zip_url)\n",
    "    with open(zip_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
    "\n",
    "    # ì••ì¶• í•´ì œ (í•´ë‹¹ í´ë” ì•ˆìœ¼ë¡œ)\n",
    "    print(\"ğŸ“¦ ì••ì¶• í•´ì œ ì¤‘...\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(localpeople_dir)\n",
    "    print(\"âœ… ì••ì¶• í•´ì œ ì™„ë£Œ!\")\n",
    "\n",
    "    # ì••ì¶• íŒŒì¼ ì‚­ì œ\n",
    "    os.remove(zip_path)\n",
    "    print(\"ğŸ§¹ ZIP íŒŒì¼ ì‚­ì œ ì™„ë£Œ!\")\n",
    "\n",
    "else:\n",
    "    print(\"âœ… LocalPeople í´ë”ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ìƒëµ.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40dbeebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ìˆ˜ì •ëœ ìƒê¶Œ ë§¤ì¶œ ì˜ˆì¸¡ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸\n",
      "==================================================\n",
      "=== ìˆ˜ì •ëœ ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘ ===\n",
      "\n",
      "ğŸ“… 2019ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2019 ë¡œë“œ ì™„ë£Œ: 65666í–‰\n",
      "  ğŸ”„ 2019ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2019ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      201901 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201902 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201903 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2019ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16273 + ì¸êµ¬ 424 â†’ 16273í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2019ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2019ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      201904 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201905 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201906 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2019ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16418 + ì¸êµ¬ 424 â†’ 16418í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2019ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2019ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      201907 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201908 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201909 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2019ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16456 + ì¸êµ¬ 424 â†’ 16456í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2019ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2019ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      201910 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201911 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201912 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2019ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16519 + ì¸êµ¬ 424 â†’ 16519í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "\n",
      "ğŸ“… 2020ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2020 ë¡œë“œ ì™„ë£Œ: 66501í–‰\n",
      "  ğŸ”„ 2020ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2020ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202001 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202002 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202003 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2020ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16502 + ì¸êµ¬ 424 â†’ 16502í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.6%\n",
      "  ğŸ”„ 2020ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2020ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202004 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202005 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202006 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2020ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16648 + ì¸êµ¬ 424 â†’ 16648í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2020ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2020ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202007 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202008 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202009 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2020ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16676 + ì¸êµ¬ 424 â†’ 16676í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.6%\n",
      "  ğŸ”„ 2020ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2020ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202010 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202011 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202012 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2020ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16675 + ì¸êµ¬ 424 â†’ 16675í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.6%\n",
      "\n",
      "ğŸ“… 2021ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2021 ë¡œë“œ ì™„ë£Œ: 70071í–‰\n",
      "  ğŸ”„ 2021ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2021ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202101 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202102 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202103 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2021ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17536 + ì¸êµ¬ 424 â†’ 17536í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2021ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2021ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202104 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202105 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202106 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2021ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17541 + ì¸êµ¬ 424 â†’ 17541í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2021ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2021ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202107 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202108 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202109 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2021ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17514 + ì¸êµ¬ 424 â†’ 17514í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2021ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2021ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202110 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202111 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202112 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2021ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17480 + ì¸êµ¬ 424 â†’ 17480í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.6%\n",
      "\n",
      "ğŸ“… 2022ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2022 ë¡œë“œ ì™„ë£Œ: 69440í–‰\n",
      "  ğŸ”„ 2022ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2022ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202201 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202202 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202203 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2022ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17394 + ì¸êµ¬ 424 â†’ 17394í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.6%\n",
      "  ğŸ”„ 2022ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2022ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202204 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202205 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202206 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2022ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17401 + ì¸êµ¬ 424 â†’ 17401í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2022ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2022ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202207 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202208 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202209 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2022ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17346 + ì¸êµ¬ 424 â†’ 17346í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2022ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2022ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202210 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202211 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202212 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2022ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17299 + ì¸êµ¬ 424 â†’ 17299í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "\n",
      "ğŸ“… 2023ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2023 ë¡œë“œ ì™„ë£Œ: 68643í–‰\n",
      "  ğŸ”„ 2023ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2023ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202301 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202302 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202303 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2023ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17188 + ì¸êµ¬ 424 â†’ 17188í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2023ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2023ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202304 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202305 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202306 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2023ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17196 + ì¸êµ¬ 424 â†’ 17196í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2023ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2023ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202307 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202308 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202309 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2023ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17137 + ì¸êµ¬ 424 â†’ 17137í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2023ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2023ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202310 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202311 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202312 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2023ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17122 + ì¸êµ¬ 424 â†’ 17122í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "\n",
      "ğŸ“… 2024ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2024 ë¡œë“œ ì™„ë£Œ: 67900í–‰\n",
      "  ğŸ”„ 2024ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2024ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202401 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202402 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202403 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2024ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17044 + ì¸êµ¬ 424 â†’ 17044í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2024ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2024ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202404 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202405 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202406 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2024ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17048 + ì¸êµ¬ 424 â†’ 17048í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2024ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2024ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202407 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202408 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202409 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2024ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16937 + ì¸êµ¬ 424 â†’ 16937í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2024ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2024ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202410 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202411 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202412 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2024ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16871 + ì¸êµ¬ 424 â†’ 16871í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "\n",
      "ğŸ”— ì „ì²´ ë°ì´í„° ê²°í•© ì¤‘...\n",
      "âœ… ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: (408221, 82)\n",
      "\n",
      "=== ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ===\n",
      "ì›ë³¸ ë°ì´í„° í¬ê¸°: (408221, 82)\n",
      "ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€ë¥¼ ìœ„í•´ ì œê±°í•  ë§¤ì¶œ ê´€ë ¨ ì»¬ëŸ¼: 47ê°œ\n",
      "ì œê±° ì»¬ëŸ¼ ì˜ˆì‹œ: ['ë‹¹ì›”_ë§¤ì¶œ_ê±´ìˆ˜', 'ì£¼ì¤‘_ë§¤ì¶œ_ê¸ˆì•¡', 'ì£¼ë§_ë§¤ì¶œ_ê¸ˆì•¡', 'ì›”ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡', 'í™”ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡']\n",
      "ê²°ì¸¡ë¥  70% ì´ìƒ ì»¬ëŸ¼ ì œê±°: 0ê°œ\n",
      "ğŸ“Š LocalPeople ê´€ë ¨ ì»¬ëŸ¼: 29ê°œ\n",
      "âœ… LocalPeople ë°ì´í„° í¬í•¨ í™•ì¸ë¨\n",
      "   ì˜ˆì‹œ: ['ì´ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜']\n",
      "ì „ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: (408221, 33)\n",
      "\n",
      "=== ë°ì´í„° ë¶„í•  (2024ë…„ í…ŒìŠ¤íŠ¸) ===\n",
      "í›ˆë ¨ ë°ì´í„°: 340321í–‰\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°: 67900í–‰\n",
      "ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "=== ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ===\n",
      "í›ˆë ¨ ë°ì´í„°: (340321, 32), í…ŒìŠ¤íŠ¸ ë°ì´í„°: (67900, 32)\n",
      "ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n",
      "âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "ğŸ”® ì˜ˆì¸¡ ì¤‘...\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ ìˆ˜ì •ëœ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\n",
      "============================================================\n",
      "MSE:  89,950,259,987,109,216,256\n",
      "RMSE: 9,484,211,089 ì›\n",
      "MAE:  828,272,904 ì›\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê·  ë§¤ì¶œ: 1,532,612,027 ì›\n",
      "Out-of-Bag Score: 0.6897\n",
      "\n",
      "--- ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ---\n",
      " 1. ğŸª ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_encoded: 0.5833\n",
      " 2. ğŸª í–‰ì •ë™ì½”ë“œ: 0.0478\n",
      " 3. ğŸ  ì—¬ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0404\n",
      " 4. ğŸ  ë‚¨ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0345\n",
      " 5. ğŸ  ë‚¨ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0231\n",
      " 6. ğŸ  ë‚¨ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0164\n",
      " 7. ğŸ  ì—¬ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0156\n",
      " 8. ğŸ  ì—¬ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0155\n",
      " 9. ğŸ  ì—¬ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0138\n",
      "10. ğŸ  ë‚¨ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0137\n",
      "11. ğŸ  ë‚¨ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0132\n",
      "12. ğŸ  ë‚¨ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0132\n",
      "13. ğŸ  ë‚¨ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0131\n",
      "14. ğŸ  ì—¬ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0125\n",
      "15. ğŸ  ì—¬ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0117\n",
      "16. ğŸ  ì—¬ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜: 0.0116\n",
      "17. ğŸ  ë‚¨ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0113\n",
      "18. ğŸ  ë‚¨ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0106\n",
      "19. ğŸª ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ: 0.0095\n",
      "20. ğŸ  ë‚¨ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0093\n",
      "\n",
      "ğŸ“Š LocalPeople ë°ì´í„° ì´ ê¸°ì—¬ë„: 0.3595 (35.9%)\n",
      "âœ… LocalPeople ë°ì´í„°ê°€ ìœ ì˜ë¯¸í•˜ê²Œ ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ‰ ìˆ˜ì •ëœ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "==================================================\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\Code\\Analyze_with_LocalPeople\\results\\localpeople_model_20250619_115622.joblib\n",
      "ğŸ“Š í‰ê°€ì§€í‘œ CSV ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\Code\\Analyze_with_LocalPeople\\results\\localpeople_metrics_20250619_115622.csv\n",
      "ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ CSV ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\Code\\Analyze_with_LocalPeople\\results\\localpeople_importance_20250619_115622.csv\n",
      "ğŸ“‹ ëª¨ë¸ ìš”ì•½ CSV ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\Code\\Analyze_with_LocalPeople\\results\\localpeople_summary_20250619_115622.csv\n",
      "\n",
      "ğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ 'c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\Code\\Analyze_with_LocalPeople\\results' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "\n",
      "ğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import gc\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def load_localpeople_quarterly_fixed(year, quarter, people_dir):\n",
    "    \"\"\"ìˆ˜ì •ëœ ë¶„ê¸°ë³„ LocalPeople ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "\n",
    "    quarter_months = {1: [1, 2, 3], 2: [4, 5, 6], 3: [7, 8, 9], 4: [10, 11, 12]}\n",
    "\n",
    "    months = quarter_months[quarter]\n",
    "    print(f\"    {year}ë…„ {quarter}ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "    monthly_agg_list = []\n",
    "\n",
    "    for month in months:\n",
    "        month_str = f\"{year}{month:02d}\"\n",
    "        file_path = os.path.join(people_dir, f\"LOCAL_PEOPLE_DONG_{month_str}.csv\")\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # chunk ë‹¨ìœ„ë¡œ ì½ê¸°\n",
    "            chunk_list = []\n",
    "            chunksize = 50000\n",
    "\n",
    "            # ğŸ”¥ CSV ì½ê¸° ë¬¸ì œ í•´ê²°: dtype ê°•ì œ ì§€ì • + BOM ì²˜ë¦¬\n",
    "            expected_cols = [\n",
    "                \"ê¸°ì¤€ì¼ID\",\n",
    "                \"ì‹œê°„ëŒ€êµ¬ë¶„\",\n",
    "                \"í–‰ì •ë™ì½”ë“œ\",\n",
    "                \"ì´ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜\",\n",
    "            ]\n",
    "\n",
    "            try:\n",
    "                df_iter = pd.read_csv(\n",
    "                    file_path,\n",
    "                    encoding=\"utf-8\",\n",
    "                    chunksize=chunksize,\n",
    "                    dtype={\n",
    "                        \"ê¸°ì¤€ì¼ID\": str,\n",
    "                        \"ì‹œê°„ëŒ€êµ¬ë¶„\": str,\n",
    "                        \"í–‰ì •ë™ì½”ë“œ\": str,\n",
    "                    },  # í•µì‹¬: strë¡œ ê°•ì œ\n",
    "                    usecols=expected_cols,  # ì •í™•í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "                    header=0,  # ì²« ë²ˆì§¸ í–‰ì´ í—¤ë”ì„ì„ ëª…ì‹œ\n",
    "                )\n",
    "            except:\n",
    "                df_iter = pd.read_csv(\n",
    "                    file_path,\n",
    "                    encoding=\"cp949\",\n",
    "                    chunksize=chunksize,\n",
    "                    dtype={\"ê¸°ì¤€ì¼ID\": str, \"ì‹œê°„ëŒ€êµ¬ë¶„\": str, \"í–‰ì •ë™ì½”ë“œ\": str},\n",
    "                    usecols=expected_cols,\n",
    "                    header=0,\n",
    "                )\n",
    "\n",
    "            for chunk in df_iter:\n",
    "                chunk[\"í–‰ì •ë™ì½”ë“œ\"] = chunk[\"í–‰ì •ë™ì½”ë“œ\"].astype(str).str.zfill(8)\n",
    "\n",
    "                # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "                numeric_cols = [\"ì´ìƒí™œì¸êµ¬ìˆ˜\"] + [\n",
    "                    col\n",
    "                    for col in chunk.columns\n",
    "                    if (\"ë‚¨ì\" in col or \"ì—¬ì\" in col) and \"ìƒí™œì¸êµ¬ìˆ˜\" in col\n",
    "                ]\n",
    "                keep_cols = [\"í–‰ì •ë™ì½”ë“œ\"] + numeric_cols\n",
    "                chunk = chunk[keep_cols]\n",
    "\n",
    "                # í–‰ì •ë™ë³„ ì§‘ê³„\n",
    "                chunk_agg = (\n",
    "                    chunk.groupby(\"í–‰ì •ë™ì½”ë“œ\").sum(numeric_only=True).reset_index()\n",
    "                )\n",
    "                chunk_list.append(chunk_agg)\n",
    "\n",
    "            # ì›”ë³„ ë°ì´í„° í•©ì¹˜ê¸°\n",
    "            if chunk_list:\n",
    "                month_df = pd.concat(chunk_list, ignore_index=True)\n",
    "                month_agg = (\n",
    "                    month_df.groupby(\"í–‰ì •ë™ì½”ë“œ\").sum(numeric_only=True).reset_index()\n",
    "                )\n",
    "                monthly_agg_list.append(month_agg)\n",
    "                print(f\"      {month_str} ì™„ë£Œ ({len(month_agg)}ê°œ í–‰ì •ë™)\")\n",
    "\n",
    "            del chunk_list\n",
    "            gc.collect()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"      {month_str} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not monthly_agg_list:\n",
    "        return None\n",
    "\n",
    "    # ë¶„ê¸°ë³„ í‰ê·  ê³„ì‚°\n",
    "    quarter_df = monthly_agg_list[0]\n",
    "    for month_df in monthly_agg_list[1:]:\n",
    "        quarter_df = pd.merge(\n",
    "            quarter_df,\n",
    "            month_df,\n",
    "            on=\"í–‰ì •ë™ì½”ë“œ\",\n",
    "            how=\"outer\",\n",
    "            suffixes=(\"\", \"_temp\"),\n",
    "        )\n",
    "\n",
    "        # í‰ê·  ê³„ì‚°\n",
    "        for col in month_df.columns:\n",
    "            if col != \"í–‰ì •ë™ì½”ë“œ\":\n",
    "                if f\"{col}_temp\" in quarter_df.columns:\n",
    "                    quarter_df[col] = quarter_df[[col, f\"{col}_temp\"]].sum(\n",
    "                        axis=1, skipna=True\n",
    "                    )\n",
    "                    quarter_df = quarter_df.drop(columns=[f\"{col}_temp\"])\n",
    "\n",
    "    # ì´ì œ í–‰ì •ë™ì½”ë“œëŠ” ì´ë¯¸ ì˜¬ë°”ë¥¸ ì»¬ëŸ¼ì— ìˆìŒ\n",
    "\n",
    "    print(\n",
    "        f\"    {year}ë…„ {quarter}ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: {len(quarter_df)}ê°œ í–‰ì •ë™\"\n",
    "    )\n",
    "    return quarter_df\n",
    "\n",
    "\n",
    "def load_trading_area_data(year, biz_dir):\n",
    "    \"\"\"Trading Area ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "    file_path = os.path.join(biz_dir, f\"Trading_Area_{year}.csv\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "        except:\n",
    "            df = pd.read_csv(file_path, encoding=\"cp949\")\n",
    "\n",
    "        df = df.rename(columns={\"í–‰ì •ë™_ì½”ë“œ\": \"í–‰ì •ë™ì½”ë“œ\"})\n",
    "        df[\"í–‰ì •ë™ì½”ë“œ\"] = df[\"í–‰ì •ë™ì½”ë“œ\"].astype(str).str.zfill(8)\n",
    "\n",
    "        print(f\"  Trading Area {year} ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Trading Area {year} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_master_dataset_fixed(years, people_dir, biz_dir):\n",
    "    \"\"\"ìˆ˜ì •ëœ ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„±\"\"\"\n",
    "    print(\"=== ìˆ˜ì •ëœ ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘ ===\")\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for year in years:\n",
    "        print(f\"\\nğŸ“… {year}ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\")\n",
    "\n",
    "        # Trading Area ë°ì´í„° ë¡œë“œ\n",
    "        biz_df = load_trading_area_data(year, biz_dir)\n",
    "        if biz_df is None:\n",
    "            continue\n",
    "\n",
    "        # ê° ë¶„ê¸°ë³„ë¡œ ì²˜ë¦¬\n",
    "        for quarter in [1, 2, 3, 4]:\n",
    "            print(f\"  ğŸ”„ {year}ë…„ {quarter}ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\")\n",
    "\n",
    "            # í•´ë‹¹ ë¶„ê¸° Trading Area ë°ì´í„° í•„í„°ë§\n",
    "            quarter_code = int(f\"{year}{quarter}\")\n",
    "            biz_quarter = biz_df[biz_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] == quarter_code].copy()\n",
    "\n",
    "            if len(biz_quarter) == 0:\n",
    "                print(f\"    âŒ {year}ë…„ {quarter}ë¶„ê¸° ë§¤ì¶œ ë°ì´í„° ì—†ìŒ\")\n",
    "                continue\n",
    "\n",
    "            # LocalPeople ë°ì´í„° ë¡œë“œ (ìˆ˜ì •ëœ ë²„ì „)\n",
    "            people_quarter = load_localpeople_quarterly_fixed(year, quarter, people_dir)\n",
    "\n",
    "            if people_quarter is None:\n",
    "                print(f\"    âŒ {year}ë…„ {quarter}ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì—†ìŒ\")\n",
    "                continue\n",
    "\n",
    "            # ë°ì´í„° ë³‘í•©\n",
    "            merged_data = pd.merge(\n",
    "                biz_quarter, people_quarter, on=\"í–‰ì •ë™ì½”ë“œ\", how=\"left\"\n",
    "            )\n",
    "\n",
    "            # ë³‘í•© ê²°ê³¼ í™•ì¸ (ì²« ë²ˆì§¸ ì¸êµ¬ ì»¬ëŸ¼ìœ¼ë¡œ ë§¤ì¹­ë¥  í™•ì¸)\n",
    "            people_cols = [col for col in people_quarter.columns if col != \"í–‰ì •ë™ì½”ë“œ\"]\n",
    "            if people_cols:\n",
    "                people_match_rate = (\n",
    "                    (~merged_data[people_cols[0]].isna()).sum() / len(merged_data) * 100\n",
    "                )\n",
    "            else:\n",
    "                people_match_rate = 0\n",
    "\n",
    "            print(\n",
    "                f\"    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ {len(biz_quarter)} + ì¸êµ¬ {len(people_quarter)} â†’ {len(merged_data)}í–‰\"\n",
    "            )\n",
    "            print(f\"    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : {people_match_rate:.1f}%\")\n",
    "\n",
    "            all_data.append(merged_data)\n",
    "\n",
    "            # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "            del biz_quarter, people_quarter, merged_data\n",
    "            gc.collect()\n",
    "\n",
    "    if not all_data:\n",
    "        raise ValueError(\"ìƒì„±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„° ê²°í•©\n",
    "    print(\"\\nğŸ”— ì „ì²´ ë°ì´í„° ê²°í•© ì¤‘...\")\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"âœ… ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {final_df.shape}\")\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def preprocess_data_fixed(df):\n",
    "    \"\"\"ìˆ˜ì •ëœ ë°ì´í„° ì „ì²˜ë¦¬\"\"\"\n",
    "    print(\"\\n=== ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ===\")\n",
    "    print(f\"ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "\n",
    "    # íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸\n",
    "    if \"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\" not in df.columns:\n",
    "        raise ValueError(\"íƒ€ê²Ÿ ë³€ìˆ˜ 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "    # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° + ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€\n",
    "    drop_cols = [\"í–‰ì •ë™_ì½”ë“œ_ëª…\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…\"]\n",
    "\n",
    "    # ğŸ”¥ ë§¤ì¶œ ê´€ë ¨ íŠ¹ì„± ì œê±° (ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€)\n",
    "    sales_cols = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if any(\n",
    "            keyword in col\n",
    "            for keyword in [\n",
    "                \"ë§¤ì¶œ_ê¸ˆì•¡\",\n",
    "                \"ë§¤ì¶œ_ê±´ìˆ˜\",\n",
    "                \"ì›”ìš”ì¼_\",\n",
    "                \"í™”ìš”ì¼_\",\n",
    "                \"ìˆ˜ìš”ì¼_\",\n",
    "                \"ëª©ìš”ì¼_\",\n",
    "                \"ê¸ˆìš”ì¼_\",\n",
    "                \"í† ìš”ì¼_\",\n",
    "                \"ì¼ìš”ì¼_\",\n",
    "                \"ì£¼ì¤‘_\",\n",
    "                \"ì£¼ë§_\",\n",
    "                \"ì‹œê°„ëŒ€_\",\n",
    "                \"ë‚¨ì„±_ë§¤ì¶œ\",\n",
    "                \"ì—¬ì„±_ë§¤ì¶œ\",\n",
    "                \"ì—°ë ¹ëŒ€_\",\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ìœ ì§€\n",
    "    sales_cols = [col for col in sales_cols if col != \"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\"]\n",
    "\n",
    "    print(f\"ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€ë¥¼ ìœ„í•´ ì œê±°í•  ë§¤ì¶œ ê´€ë ¨ ì»¬ëŸ¼: {len(sales_cols)}ê°œ\")\n",
    "    print(f\"ì œê±° ì»¬ëŸ¼ ì˜ˆì‹œ: {sales_cols[:5]}\")\n",
    "\n",
    "    drop_cols.extend(sales_cols)\n",
    "    df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
    "\n",
    "    # ê²°ì¸¡ê°’ì´ ë„ˆë¬´ ë§ì€ ì»¬ëŸ¼ ì œê±° (70% ì´ìƒ)\n",
    "    null_ratio = df.isnull().mean()\n",
    "    high_null_cols = null_ratio[null_ratio > 0.7].index.tolist()\n",
    "    print(f\"ê²°ì¸¡ë¥  70% ì´ìƒ ì»¬ëŸ¼ ì œê±°: {len(high_null_cols)}ê°œ\")\n",
    "    if high_null_cols:\n",
    "        df = df.drop(columns=high_null_cols)\n",
    "\n",
    "    # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "    if \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\" in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_encoded\"] = le.fit_transform(\n",
    "            df[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"].astype(str)\n",
    "        )\n",
    "        df = df.drop(columns=[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"])\n",
    "\n",
    "    # LocalPeople ê´€ë ¨ ì»¬ëŸ¼ í™•ì¸\n",
    "    people_cols = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if any(keyword in col for keyword in [\"ìƒí™œì¸êµ¬ìˆ˜\", \"ë‚¨ì\", \"ì—¬ì\"])\n",
    "    ]\n",
    "    print(f\"ğŸ“Š LocalPeople ê´€ë ¨ ì»¬ëŸ¼: {len(people_cols)}ê°œ\")\n",
    "\n",
    "    if len(people_cols) == 0:\n",
    "        print(\"âš ï¸ ê²½ê³ : LocalPeople ë°ì´í„°ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
    "    else:\n",
    "        print(\"âœ… LocalPeople ë°ì´í„° í¬í•¨ í™•ì¸ë¨\")\n",
    "        # ëª‡ ê°œ ì»¬ëŸ¼ëª… ì¶œë ¥\n",
    "        sample_cols = people_cols[:5]\n",
    "        print(f\"   ì˜ˆì‹œ: {sample_cols}\")\n",
    "\n",
    "    print(f\"ì „ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def train_and_evaluate_model_fixed(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"ìˆ˜ì •ëœ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\"\"\"\n",
    "    print(\"\\n=== ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ===\")\n",
    "    print(f\"í›ˆë ¨ ë°ì´í„°: {X_train.shape}, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}\")\n",
    "\n",
    "    # íƒ€ê²Ÿ ë³€ìˆ˜ ë¡œê·¸ ë³€í™˜\n",
    "    y_train_log = np.log1p(y_train.clip(lower=0))\n",
    "\n",
    "    # RandomForest ëª¨ë¸\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100, max_depth=15, random_state=42, n_jobs=-1, oob_score=True\n",
    "    )\n",
    "\n",
    "    print(\"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
    "    model.fit(X_train, y_train_log)\n",
    "    print(\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "\n",
    "    # ì˜ˆì¸¡\n",
    "    print(\"ğŸ”® ì˜ˆì¸¡ ì¤‘...\")\n",
    "    y_pred_log = model.predict(X_test)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_pred = np.clip(y_pred, 0, None)  # ìŒìˆ˜ ì œê±°\n",
    "\n",
    "    # ì„±ëŠ¥ í‰ê°€\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ¯ ìˆ˜ì •ëœ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"MSE:  {mse:,.0f}\")\n",
    "    print(f\"RMSE: {rmse:,.0f} ì›\")\n",
    "    print(f\"MAE:  {mae:,.0f} ì›\")\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê·  ë§¤ì¶œ: {y_test.mean():,.0f} ì›\")\n",
    "    print(f\"Out-of-Bag Score: {model.oob_score_:.4f}\")\n",
    "\n",
    "    # ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ì¶œë ¥\n",
    "    feature_importance = pd.DataFrame(\n",
    "        {\"feature\": X_train.columns, \"importance\": model.feature_importances_}\n",
    "    ).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    print(f\"\\n--- ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ---\")\n",
    "    for i, (_, row) in enumerate(feature_importance.head(20).iterrows(), 1):\n",
    "        is_people = any(\n",
    "            keyword in row[\"feature\"] for keyword in [\"ìƒí™œì¸êµ¬ìˆ˜\", \"ë‚¨ì\", \"ì—¬ì\"]\n",
    "        )\n",
    "        marker = \"ğŸ \" if is_people else \"ğŸª\"\n",
    "        print(f\"{i:2d}. {marker} {row['feature'][:50]}: {row['importance']:.4f}\")\n",
    "\n",
    "    # LocalPeople ë°ì´í„° ê¸°ì—¬ë„\n",
    "    people_features = feature_importance[\n",
    "        feature_importance[\"feature\"].str.contains(\"ìƒí™œì¸êµ¬ìˆ˜|ë‚¨ì|ì—¬ì\", regex=True)\n",
    "    ]\n",
    "    people_importance = people_features[\"importance\"].sum()\n",
    "\n",
    "    print(\n",
    "        f\"\\nğŸ“Š LocalPeople ë°ì´í„° ì´ ê¸°ì—¬ë„: {people_importance:.4f} ({people_importance*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    if people_importance < 0.05:\n",
    "        print(\"âš ï¸ LocalPeople ë°ì´í„° ê¸°ì—¬ë„ê°€ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤.\")\n",
    "    elif people_importance < 0.15:\n",
    "        print(\"ğŸ”¶ LocalPeople ë°ì´í„° ê¸°ì—¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"âœ… LocalPeople ë°ì´í„°ê°€ ìœ ì˜ë¯¸í•˜ê²Œ ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    return (\n",
    "        model,\n",
    "        {\"mse\": mse, \"rmse\": rmse, \"mae\": mae},\n",
    "        feature_importance,\n",
    "        people_importance,\n",
    "    )\n",
    "\n",
    "\n",
    "def save_model_and_metrics(\n",
    "    model, metrics, feature_importance_df, people_importance, config\n",
    "):\n",
    "    \"\"\"ëª¨ë¸ê³¼ í‰ê°€ì§€í‘œ ì €ì¥\"\"\"\n",
    "\n",
    "    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ê¸°ì¤€)\n",
    "    script_dir = os.getcwd()\n",
    "    results_dir = os.path.join(script_dir, \"results\")\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "        print(f\"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±: {results_dir}\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # 1. ëª¨ë¸ ì €ì¥\n",
    "    model_filename = os.path.join(results_dir, f\"localpeople_model_{timestamp}.joblib\")\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_filename}\")\n",
    "\n",
    "    # 2. í‰ê°€ì§€í‘œ CSV ì €ì¥\n",
    "    metrics_data = {\n",
    "        \"ì‹¤í–‰ì‹œê°„\": [timestamp],\n",
    "        \"MSE\": [metrics[\"mse\"]],\n",
    "        \"RMSE\": [metrics[\"rmse\"]],\n",
    "        \"MAE\": [metrics[\"mae\"]],\n",
    "        \"LocalPeople_ê¸°ì—¬ë„\": [people_importance],\n",
    "        \"LocalPeople_ê¸°ì—¬ë„_í¼ì„¼íŠ¸\": [people_importance * 100],\n",
    "        \"OOB_Score\": [model.oob_score_],\n",
    "        \"í…ŒìŠ¤íŠ¸_ë…„ë„\": [config[\"test_year\"]],\n",
    "        \"í›ˆë ¨_ë°ì´í„°_í¬ê¸°\": [config[\"train_size\"]],\n",
    "        \"í…ŒìŠ¤íŠ¸_ë°ì´í„°_í¬ê¸°\": [config[\"test_size\"]],\n",
    "        \"íŠ¹ì„±_ê°œìˆ˜\": [config[\"n_features\"]],\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_filename = os.path.join(results_dir, f\"localpeople_metrics_{timestamp}.csv\")\n",
    "    metrics_df.to_csv(metrics_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ“Š í‰ê°€ì§€í‘œ CSV ì €ì¥ ì™„ë£Œ: {metrics_filename}\")\n",
    "\n",
    "    # 3. íŠ¹ì„± ì¤‘ìš”ë„ ì €ì¥\n",
    "    importance_filename = os.path.join(\n",
    "        results_dir, f\"localpeople_importance_{timestamp}.csv\"\n",
    "    )\n",
    "    feature_importance_df.to_csv(importance_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ CSV ì €ì¥ ì™„ë£Œ: {importance_filename}\")\n",
    "\n",
    "    # 4. ì‹¤í–‰ ì •ë³´ ìš”ì•½ ì €ì¥\n",
    "    summary_data = {\n",
    "        \"í•­ëª©\": [\n",
    "            \"ì‹¤í–‰ì‹œê°„\",\n",
    "            \"MSE\",\n",
    "            \"RMSE (ì›)\",\n",
    "            \"MAE (ì›)\",\n",
    "            \"LocalPeople ê¸°ì—¬ë„ (%)\",\n",
    "            \"OOB Score\",\n",
    "            \"í…ŒìŠ¤íŠ¸ ë…„ë„\",\n",
    "            \"í›ˆë ¨ ë°ì´í„° í¬ê¸°\",\n",
    "            \"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°\",\n",
    "            \"íŠ¹ì„± ê°œìˆ˜\",\n",
    "        ],\n",
    "        \"ê°’\": [\n",
    "            timestamp,\n",
    "            f\"{metrics['mse']:,.0f}\",\n",
    "            f\"{metrics['rmse']:,.0f}\",\n",
    "            f\"{metrics['mae']:,.0f}\",\n",
    "            f\"{people_importance*100:.1f}%\",\n",
    "            f\"{model.oob_score_:.4f}\",\n",
    "            config[\"test_year\"],\n",
    "            f\"{config['train_size']:,}\",\n",
    "            f\"{config['test_size']:,}\",\n",
    "            config[\"n_features\"],\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_filename = os.path.join(results_dir, f\"localpeople_summary_{timestamp}.csv\")\n",
    "    summary_df.to_csv(summary_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ“‹ ëª¨ë¸ ìš”ì•½ CSV ì €ì¥ ì™„ë£Œ: {summary_filename}\")\n",
    "\n",
    "    print(f\"\\nğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ '{results_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    return {\n",
    "        \"model_file\": model_filename,\n",
    "        \"metrics_file\": metrics_filename,\n",
    "        \"importance_file\": importance_filename,\n",
    "        \"summary_file\": summary_filename,\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"main í•¨ìˆ˜\"\"\"\n",
    "    print(\"ğŸš€ ìˆ˜ì •ëœ ìƒê¶Œ ë§¤ì¶œ ì˜ˆì¸¡ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # ì„¤ì •\n",
    "    YEARS = range(2019, 2025)\n",
    "    PEOPLE_DIR = \"../../Data/LocalPeople\"\n",
    "    BIZ_DIR = \"../../Data/Trading_Area\"\n",
    "    TEST_YEAR = 2024\n",
    "\n",
    "    try:\n",
    "        # 1. ë°ì´í„° ë¡œë“œ ë° ë³‘í•© (ìˆ˜ì •ëœ ë²„ì „)\n",
    "        master_df = create_master_dataset_fixed(YEARS, PEOPLE_DIR, BIZ_DIR)\n",
    "\n",
    "        # 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "        processed_df = preprocess_data_fixed(master_df)\n",
    "\n",
    "        # 3. ë°ì´í„° ë¶„í• \n",
    "        print(f\"\\n=== ë°ì´í„° ë¶„í•  ({TEST_YEAR}ë…„ í…ŒìŠ¤íŠ¸) ===\")\n",
    "        train_mask = processed_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] < (TEST_YEAR * 10 + 1)\n",
    "        test_mask = processed_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] >= (TEST_YEAR * 10 + 1)\n",
    "\n",
    "        train_df = processed_df[train_mask].copy()\n",
    "        test_df = processed_df[test_mask].copy()\n",
    "\n",
    "        print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_df)}í–‰\")\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}í–‰\")\n",
    "\n",
    "        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "        target_col = \"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\"\n",
    "        feature_cols = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "        X_train = train_df[feature_cols]\n",
    "        y_train = train_df[target_col]\n",
    "        X_test = test_df[feature_cols]\n",
    "        y_test = test_df[target_col]\n",
    "\n",
    "        # ê²°ì¸¡ê°’ ì²˜ë¦¬\n",
    "        print(\"ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...\")\n",
    "        imputer = SimpleImputer(strategy=\"mean\")\n",
    "        X_train_filled = pd.DataFrame(\n",
    "            imputer.fit_transform(X_train), columns=X_train.columns\n",
    "        )\n",
    "        X_test_filled = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "        # 4. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "        model, metrics, feature_importance, people_importance = (\n",
    "            train_and_evaluate_model_fixed(\n",
    "                X_train_filled, y_train, X_test_filled, y_test\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\"\\nğŸ‰ ìˆ˜ì •ëœ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # 5. ëª¨ë¸ ë° ê²°ê³¼ ì €ì¥\n",
    "        config = {\n",
    "            \"test_year\": TEST_YEAR,\n",
    "            \"train_size\": len(train_df),\n",
    "            \"test_size\": len(test_df),\n",
    "            \"n_features\": len(feature_cols),\n",
    "        }\n",
    "        result = save_model_and_metrics(\n",
    "            model, metrics, feature_importance, people_importance, config\n",
    "        )\n",
    "\n",
    "        print(\"\\nğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
