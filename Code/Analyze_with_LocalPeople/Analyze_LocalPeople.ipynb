{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7890dd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas>=1.5.0 (from -r ../../requirements.txt (line 2))\n",
      "  Using cached pandas-2.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting numpy>=1.21.0 (from -r ../../requirements.txt (line 3))\n",
      "  Using cached numpy-2.3.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting scikit-learn>=1.1.0 (from -r ../../requirements.txt (line 6))\n",
      "  Using cached scikit_learn-1.7.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting joblib>=1.2.0 (from -r ../../requirements.txt (line 7))\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting matplotlib>=3.5.0 (from -r ../../requirements.txt (line 11))\n",
      "  Using cached matplotlib-3.10.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
      "Collecting seaborn>=0.11.0 (from -r ../../requirements.txt (line 12))\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting jupyter>=1.0.0 (from -r ../../requirements.txt (line 15))\n",
      "  Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting notebook>=6.4.0 (from -r ../../requirements.txt (line 16))\n",
      "  Using cached notebook-7.4.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting catboost>=1.1.0 (from -r ../../requirements.txt (line 19))\n",
      "  Using cached catboost-1.2.8-cp312-cp312-macosx_11_0_universal2.whl.metadata (1.4 kB)\n",
      "Collecting plotly>=5.0.0 (from -r ../../requirements.txt (line 22))\n",
      "  Using cached plotly-6.1.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from pandas>=1.5.0->-r ../../requirements.txt (line 2)) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.5.0->-r ../../requirements.txt (line 2))\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.5.0->-r ../../requirements.txt (line 2))\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn>=1.1.0->-r ../../requirements.txt (line 6))\n",
      "  Using cached scipy-1.15.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->-r ../../requirements.txt (line 6))\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.5.0->-r ../../requirements.txt (line 11))\n",
      "  Using cached contourpy-1.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.5.0->-r ../../requirements.txt (line 11))\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.5.0->-r ../../requirements.txt (line 11))\n",
      "  Using cached fonttools-4.58.4-cp312-cp312-macosx_10_13_universal2.whl.metadata (106 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.5.0->-r ../../requirements.txt (line 11))\n",
      "  Using cached kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from matplotlib>=3.5.0->-r ../../requirements.txt (line 11)) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib>=3.5.0->-r ../../requirements.txt (line 11))\n",
      "  Using cached pillow-11.2.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.5.0->-r ../../requirements.txt (line 11))\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting jupyter-console (from jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: ipykernel in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (6.29.5)\n",
      "Collecting ipywidgets (from jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting jupyterlab (from jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached jupyterlab-4.4.3-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached jupyter_server-2.16.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim<0.3,>=0.2 (from notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from notebook>=6.4.0->-r ../../requirements.txt (line 16)) (6.5.1)\n",
      "Collecting anyio>=3.1.0 (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jinja2>=3.0.3 (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16)) (5.8.1)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pyzmq>=24 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16)) (27.0.0)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: traitlets>=5.6.0 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16)) (5.14.3)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx>=0.25.0 (from jupyterlab->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting setuptools>=41.1.0 (from jupyterlab->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting requests>=2.31 (from jupyterlab-server<3,>=2.27.1->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting graphviz (from catboost>=1.1.0->-r ../../requirements.txt (line 19))\n",
      "  Using cached graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: six in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from catboost>=1.1.0->-r ../../requirements.txt (line 19)) (1.17.0)\n",
      "Collecting narwhals>=1.15.1 (from plotly>=5.0.0->-r ../../requirements.txt (line 22))\n",
      "  Using cached narwhals-1.43.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting idna>=2.8 (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sniffio>=1.1 (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting typing_extensions>=4.5 (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl.metadata (6.7 kB)\n",
      "Collecting certifi (from httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: appnope in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (0.1.4)\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (9.3.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (1.6.0)\n",
      "Requirement already satisfied: psutil in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (7.0.0)\n",
      "Requirement already satisfied: decorator in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (0.19.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (0.8.4)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=3.0.3->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached rpds_py-0.25.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16)) (4.3.8)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pyyaml>=5.3 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached mistune-3.1.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (0.7.0)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached charset_normalizer-3.4.2-cp312-cp312-macosx_10_13_universal2.whl.metadata (35 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31->jupyterlab-server<3,>=2.27.1->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter>=1.0.0->-r ../../requirements.txt (line 15))\n",
      "  Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->notebook>=6.4.0->-r ../../requirements.txt (line 16))\n",
      "  Using cached types_python_dateutil-2.9.0.20250516-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/.venv/lib/python3.12/site-packages (from stack_data->ipython>=7.23.1->ipykernel->jupyter>=1.0.0->-r ../../requirements.txt (line 15)) (0.2.3)\n",
      "Using cached pandas-2.3.0-cp312-cp312-macosx_11_0_arm64.whl (10.7 MB)\n",
      "Using cached numpy-2.3.0-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
      "Using cached scikit_learn-1.7.0-cp312-cp312-macosx_12_0_arm64.whl (10.7 MB)\n",
      "Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Using cached matplotlib-3.10.3-cp312-cp312-macosx_11_0_arm64.whl (8.1 MB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Using cached notebook-7.4.3-py3-none-any.whl (14.3 MB)\n",
      "Using cached jupyter_server-2.16.0-py3-none-any.whl (386 kB)\n",
      "Using cached jupyterlab-4.4.3-py3-none-any.whl (12.3 MB)\n",
      "Using cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Using cached catboost-1.2.8-cp312-cp312-macosx_11_0_universal2.whl (27.8 MB)\n",
      "Using cached plotly-6.1.2-py3-none-any.whl (16.3 MB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "Using cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Using cached babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "Using cached contourpy-1.3.2-cp312-cp312-macosx_11_0_arm64.whl (255 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.58.4-cp312-cp312-macosx_10_13_universal2.whl (2.8 MB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached json5-0.12.0-py3-none-any.whl (36 kB)\n",
      "Using cached jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Using cached kiwisolver-1.4.8-cp312-cp312-macosx_11_0_arm64.whl (65 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached narwhals-1.43.1-py3-none-any.whl (362 kB)\n",
      "Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Using cached mistune-3.1.3-py3-none-any.whl (53 kB)\n",
      "Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Using cached pillow-11.2.1-cp312-cp312-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Using cached prometheus_client-0.22.1-py3-none-any.whl (58 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Using cached python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp312-cp312-macosx_10_13_universal2.whl (199 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached rpds_py-0.25.1-cp312-cp312-macosx_11_0_arm64.whl (350 kB)\n",
      "Using cached scipy-1.15.3-cp312-cp312-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl (53 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl (178 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Using cached graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Using cached ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Using cached types_python_dateutil-2.9.0.20250516-py3-none-any.whl (14 kB)\n",
      "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, pytz, fastjsonschema, widgetsnbextension, websocket-client, webcolors, urllib3, uri-template, tzdata, typing_extensions, types-python-dateutil, tinycss2, threadpoolctl, terminado, soupsieve, sniffio, setuptools, send2trash, rpds-py, rfc3986-validator, rfc3339-validator, pyyaml, python-json-logger, pyparsing, pycparser, prometheus-client, pillow, pandocfilters, overrides, numpy, narwhals, mistune, MarkupSafe, kiwisolver, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, joblib, idna, h11, graphviz, fqdn, fonttools, defusedxml, cycler, charset_normalizer, certifi, bleach, babel, attrs, async-lru, scipy, requests, referencing, plotly, pandas, jupyter-server-terminals, jinja2, httpcore, contourpy, cffi, beautifulsoup4, arrow, anyio, scikit-learn, matplotlib, jsonschema-specifications, isoduration, ipywidgets, httpx, argon2-cffi-bindings, seaborn, jupyter-console, jsonschema, catboost, argon2-cffi, nbformat, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88/88\u001b[0m [jupyter][notebook]jupyterlab]server]minals]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 anyio-4.9.0 argon2-cffi-25.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 async-lru-2.0.5 attrs-25.3.0 babel-2.17.0 beautifulsoup4-4.13.4 bleach-6.2.0 catboost-1.2.8 certifi-2025.6.15 cffi-1.17.1 charset_normalizer-3.4.2 contourpy-1.3.2 cycler-0.12.1 defusedxml-0.7.1 fastjsonschema-2.21.1 fonttools-4.58.4 fqdn-1.5.1 graphviz-0.21 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 ipywidgets-8.1.7 isoduration-20.11.0 jinja2-3.1.6 joblib-1.5.1 json5-0.12.0 jsonpointer-3.0.0 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 jupyter-1.1.1 jupyter-console-6.6.3 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.16.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.3 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 jupyterlab_widgets-3.0.15 kiwisolver-1.4.8 matplotlib-3.10.3 mistune-3.1.3 narwhals-1.43.1 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 notebook-7.4.3 notebook-shim-0.2.4 numpy-2.3.0 overrides-7.7.0 pandas-2.3.0 pandocfilters-1.5.1 pillow-11.2.1 plotly-6.1.2 prometheus-client-0.22.1 pycparser-2.22 pyparsing-3.2.3 python-json-logger-3.3.0 pytz-2025.2 pyyaml-6.0.2 referencing-0.36.2 requests-2.32.4 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.25.1 scikit-learn-1.7.0 scipy-1.15.3 seaborn-0.13.2 send2trash-1.8.3 setuptools-80.9.0 sniffio-1.3.1 soupsieve-2.7 terminado-0.18.1 threadpoolctl-3.6.0 tinycss2-1.4.0 types-python-dateutil-2.9.0.20250516 typing_extensions-4.14.0 tzdata-2025.2 uri-template-1.3.0 urllib3-2.5.0 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0 widgetsnbextension-4.0.14\n"
     ]
    }
   ],
   "source": [
    "# íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜ ì•ˆ í–ˆë‹¤ë©´ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰ì‹œí‚¤ì„¸ìš”.\n",
    "!pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e9e5d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ LocalPeople í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ ì‹œì‘...\n",
      "ğŸ”½ LocalPeople.zip ë‹¤ìš´ë¡œë“œ ì¤‘...\n",
      "âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\n",
      "ğŸ“¦ ì••ì¶• í•´ì œ ì¤‘...\n",
      "âœ… ì••ì¶• í•´ì œ ì™„ë£Œ!\n",
      "ğŸ§¹ ZIP íŒŒì¼ ì‚­ì œ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ì‹¤ê±°ì£¼ ì¸êµ¬ ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "base_dir = \"../../Data\"\n",
    "localpeople_dir = os.path.join(base_dir, \"LocalPeople\")\n",
    "zip_url = (\n",
    "    \"https://huggingface.co/datasets/uhjin1130/LocalPeople/resolve/main/LocalPeople.zip\"\n",
    ")\n",
    "zip_path = os.path.join(localpeople_dir, \"LocalPeople.zip\")\n",
    "\n",
    "# LocalPeople í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„± ë° ë‹¤ìš´ë¡œë“œ\n",
    "if not os.path.exists(localpeople_dir):\n",
    "    print(\"ğŸ“ LocalPeople í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í•´ì œ ì‹œì‘...\")\n",
    "\n",
    "    os.makedirs(localpeople_dir, exist_ok=True)\n",
    "\n",
    "    # ë‹¤ìš´ë¡œë“œ\n",
    "    print(\"ğŸ”½ LocalPeople.zip ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
    "    response = requests.get(zip_url)\n",
    "    with open(zip_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "    print(\"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!\")\n",
    "\n",
    "    # ì••ì¶• í•´ì œ (í•´ë‹¹ í´ë” ì•ˆìœ¼ë¡œ)\n",
    "    print(\"ğŸ“¦ ì••ì¶• í•´ì œ ì¤‘...\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(localpeople_dir)\n",
    "    print(\"âœ… ì••ì¶• í•´ì œ ì™„ë£Œ!\")\n",
    "\n",
    "    # ì••ì¶• íŒŒì¼ ì‚­ì œ\n",
    "    os.remove(zip_path)\n",
    "    print(\"ğŸ§¹ ZIP íŒŒì¼ ì‚­ì œ ì™„ë£Œ!\")\n",
    "\n",
    "else:\n",
    "    print(\"âœ… LocalPeople í´ë”ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œ ìƒëµ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40dbeebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import gc\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e6241a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_localpeople_quarterly_fixed(year, quarter, people_dir):\n",
    "    \"\"\"ìˆ˜ì •ëœ ë¶„ê¸°ë³„ LocalPeople ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "\n",
    "    quarter_months = {1: [1, 2, 3], 2: [4, 5, 6], 3: [7, 8, 9], 4: [10, 11, 12]}\n",
    "\n",
    "    months = quarter_months[quarter]\n",
    "    print(f\"    {year}ë…„ {quarter}ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "    monthly_agg_list = []\n",
    "\n",
    "    for month in months:\n",
    "        month_str = f\"{year}{month:02d}\"\n",
    "        file_path = os.path.join(people_dir, f\"LOCAL_PEOPLE_DONG_{month_str}.csv\")\n",
    "\n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # chunk ë‹¨ìœ„ë¡œ ì½ê¸°\n",
    "            chunk_list = []\n",
    "            chunksize = 50000\n",
    "\n",
    "            # ğŸ”¥ CSV ì½ê¸° ë¬¸ì œ í•´ê²°: dtype ê°•ì œ ì§€ì • + BOM ì²˜ë¦¬\n",
    "            expected_cols = [\n",
    "                \"ê¸°ì¤€ì¼ID\",\n",
    "                \"ì‹œê°„ëŒ€êµ¬ë¶„\",\n",
    "                \"í–‰ì •ë™ì½”ë“œ\",\n",
    "                \"ì´ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜\",\n",
    "            ]\n",
    "\n",
    "            try:\n",
    "                df_iter = pd.read_csv(\n",
    "                    file_path,\n",
    "                    encoding=\"utf-8\",\n",
    "                    chunksize=chunksize,\n",
    "                    dtype={\n",
    "                        \"ê¸°ì¤€ì¼ID\": str,\n",
    "                        \"ì‹œê°„ëŒ€êµ¬ë¶„\": str,\n",
    "                        \"í–‰ì •ë™ì½”ë“œ\": str,\n",
    "                    },  # í•µì‹¬: strë¡œ ê°•ì œ\n",
    "                    usecols=expected_cols,  # ì •í™•í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "                    header=0,  # ì²« ë²ˆì§¸ í–‰ì´ í—¤ë”ì„ì„ ëª…ì‹œ\n",
    "                )\n",
    "            except:\n",
    "                df_iter = pd.read_csv(\n",
    "                    file_path,\n",
    "                    encoding=\"cp949\",\n",
    "                    chunksize=chunksize,\n",
    "                    dtype={\"ê¸°ì¤€ì¼ID\": str, \"ì‹œê°„ëŒ€êµ¬ë¶„\": str, \"í–‰ì •ë™ì½”ë“œ\": str},\n",
    "                    usecols=expected_cols,\n",
    "                    header=0,\n",
    "                )\n",
    "\n",
    "            for chunk in df_iter:\n",
    "                chunk[\"í–‰ì •ë™ì½”ë“œ\"] = chunk[\"í–‰ì •ë™ì½”ë“œ\"].astype(str).str.zfill(8)\n",
    "\n",
    "                # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "                numeric_cols = [\"ì´ìƒí™œì¸êµ¬ìˆ˜\"] + [\n",
    "                    col\n",
    "                    for col in chunk.columns\n",
    "                    if (\"ë‚¨ì\" in col or \"ì—¬ì\" in col) and \"ìƒí™œì¸êµ¬ìˆ˜\" in col\n",
    "                ]\n",
    "                keep_cols = [\"í–‰ì •ë™ì½”ë“œ\"] + numeric_cols\n",
    "                chunk = chunk[keep_cols]\n",
    "\n",
    "                # í–‰ì •ë™ë³„ ì§‘ê³„\n",
    "                chunk_agg = (\n",
    "                    chunk.groupby(\"í–‰ì •ë™ì½”ë“œ\").sum(numeric_only=True).reset_index()\n",
    "                )\n",
    "                chunk_list.append(chunk_agg)\n",
    "\n",
    "            # ì›”ë³„ ë°ì´í„° í•©ì¹˜ê¸°\n",
    "            if chunk_list:\n",
    "                month_df = pd.concat(chunk_list, ignore_index=True)\n",
    "                month_agg = (\n",
    "                    month_df.groupby(\"í–‰ì •ë™ì½”ë“œ\").sum(numeric_only=True).reset_index()\n",
    "                )\n",
    "                monthly_agg_list.append(month_agg)\n",
    "                print(f\"      {month_str} ì™„ë£Œ ({len(month_agg)}ê°œ í–‰ì •ë™)\")\n",
    "\n",
    "            del chunk_list\n",
    "            gc.collect()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"      {month_str} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            continue\n",
    "\n",
    "    if not monthly_agg_list:\n",
    "        return None\n",
    "\n",
    "    # ë¶„ê¸°ë³„ í‰ê·  ê³„ì‚°\n",
    "    quarter_df = monthly_agg_list[0]\n",
    "    for month_df in monthly_agg_list[1:]:\n",
    "        quarter_df = pd.merge(\n",
    "            quarter_df,\n",
    "            month_df,\n",
    "            on=\"í–‰ì •ë™ì½”ë“œ\",\n",
    "            how=\"outer\",\n",
    "            suffixes=(\"\", \"_temp\"),\n",
    "        )\n",
    "\n",
    "        # í‰ê·  ê³„ì‚°\n",
    "        for col in month_df.columns:\n",
    "            if col != \"í–‰ì •ë™ì½”ë“œ\":\n",
    "                if f\"{col}_temp\" in quarter_df.columns:\n",
    "                    quarter_df[col] = quarter_df[[col, f\"{col}_temp\"]].sum(\n",
    "                        axis=1, skipna=True\n",
    "                    )\n",
    "                    quarter_df = quarter_df.drop(columns=[f\"{col}_temp\"])\n",
    "\n",
    "    # ì´ì œ í–‰ì •ë™ì½”ë“œëŠ” ì´ë¯¸ ì˜¬ë°”ë¥¸ ì»¬ëŸ¼ì— ìˆìŒ\n",
    "\n",
    "    print(\n",
    "        f\"    {year}ë…„ {quarter}ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: {len(quarter_df)}ê°œ í–‰ì •ë™\"\n",
    "    )\n",
    "    return quarter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605181e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trading_area_data(year, biz_dir):\n",
    "    \"\"\"Trading Area ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "    file_path = os.path.join(biz_dir, f\"Trading_Area_{year}.csv\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "        except:\n",
    "            df = pd.read_csv(file_path, encoding=\"cp949\")\n",
    "\n",
    "        df = df.rename(columns={\"í–‰ì •ë™_ì½”ë“œ\": \"í–‰ì •ë™ì½”ë“œ\"})\n",
    "        df[\"í–‰ì •ë™ì½”ë“œ\"] = df[\"í–‰ì •ë™ì½”ë“œ\"].astype(str).str.zfill(8)\n",
    "\n",
    "        print(f\"  Trading Area {year} ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Trading Area {year} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c0d2f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_master_dataset_fixed(years, people_dir, biz_dir):\n",
    "    \"\"\"ìˆ˜ì •ëœ ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„±\"\"\"\n",
    "    print(\"=== ìˆ˜ì •ëœ ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘ ===\")\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for year in years:\n",
    "        print(f\"\\nğŸ“… {year}ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\")\n",
    "\n",
    "        # Trading Area ë°ì´í„° ë¡œë“œ\n",
    "        biz_df = load_trading_area_data(year, biz_dir)\n",
    "        if biz_df is None:\n",
    "            continue\n",
    "\n",
    "        # ê° ë¶„ê¸°ë³„ë¡œ ì²˜ë¦¬\n",
    "        for quarter in [1, 2, 3, 4]:\n",
    "            print(f\"  ğŸ”„ {year}ë…„ {quarter}ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\")\n",
    "\n",
    "            # í•´ë‹¹ ë¶„ê¸° Trading Area ë°ì´í„° í•„í„°ë§\n",
    "            quarter_code = int(f\"{year}{quarter}\")\n",
    "            biz_quarter = biz_df[biz_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] == quarter_code].copy()\n",
    "\n",
    "            if len(biz_quarter) == 0:\n",
    "                print(f\"    âŒ {year}ë…„ {quarter}ë¶„ê¸° ë§¤ì¶œ ë°ì´í„° ì—†ìŒ\")\n",
    "                continue\n",
    "\n",
    "            # LocalPeople ë°ì´í„° ë¡œë“œ (ìˆ˜ì •ëœ ë²„ì „)\n",
    "            people_quarter = load_localpeople_quarterly_fixed(year, quarter, people_dir)\n",
    "\n",
    "            if people_quarter is None:\n",
    "                print(f\"    âŒ {year}ë…„ {quarter}ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì—†ìŒ\")\n",
    "                continue\n",
    "\n",
    "            # ë°ì´í„° ë³‘í•©\n",
    "            merged_data = pd.merge(\n",
    "                biz_quarter, people_quarter, on=\"í–‰ì •ë™ì½”ë“œ\", how=\"left\"\n",
    "            )\n",
    "\n",
    "            # ë³‘í•© ê²°ê³¼ í™•ì¸ (ì²« ë²ˆì§¸ ì¸êµ¬ ì»¬ëŸ¼ìœ¼ë¡œ ë§¤ì¹­ë¥  í™•ì¸)\n",
    "            people_cols = [col for col in people_quarter.columns if col != \"í–‰ì •ë™ì½”ë“œ\"]\n",
    "            if people_cols:\n",
    "                people_match_rate = (\n",
    "                    (~merged_data[people_cols[0]].isna()).sum() / len(merged_data) * 100\n",
    "                )\n",
    "            else:\n",
    "                people_match_rate = 0\n",
    "\n",
    "            print(\n",
    "                f\"    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ {len(biz_quarter)} + ì¸êµ¬ {len(people_quarter)} â†’ {len(merged_data)}í–‰\"\n",
    "            )\n",
    "            print(f\"    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : {people_match_rate:.1f}%\")\n",
    "\n",
    "            all_data.append(merged_data)\n",
    "\n",
    "            # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "            del biz_quarter, people_quarter, merged_data\n",
    "            gc.collect()\n",
    "\n",
    "    if not all_data:\n",
    "        raise ValueError(\"ìƒì„±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„° ê²°í•©\n",
    "    print(\"\\nğŸ”— ì „ì²´ ë°ì´í„° ê²°í•© ì¤‘...\")\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"âœ… ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {final_df.shape}\")\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1c0c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_fixed(df):\n",
    "    \"\"\"ìˆ˜ì •ëœ ë°ì´í„° ì „ì²˜ë¦¬\"\"\"\n",
    "    print(\"\\n=== ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ===\")\n",
    "    print(f\"ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "\n",
    "    # íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸\n",
    "    if \"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\" not in df.columns:\n",
    "        raise ValueError(\"íƒ€ê²Ÿ ë³€ìˆ˜ 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "    # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° + ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€\n",
    "    drop_cols = [\"í–‰ì •ë™_ì½”ë“œ_ëª…\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…\"]\n",
    "\n",
    "    # ğŸ”¥ ë§¤ì¶œ ê´€ë ¨ íŠ¹ì„± ì œê±° (ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€)\n",
    "    sales_cols = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if any(\n",
    "            keyword in col\n",
    "            for keyword in [\n",
    "                \"ë§¤ì¶œ_ê¸ˆì•¡\",\n",
    "                \"ë§¤ì¶œ_ê±´ìˆ˜\",\n",
    "                \"ì›”ìš”ì¼_\",\n",
    "                \"í™”ìš”ì¼_\",\n",
    "                \"ìˆ˜ìš”ì¼_\",\n",
    "                \"ëª©ìš”ì¼_\",\n",
    "                \"ê¸ˆìš”ì¼_\",\n",
    "                \"í† ìš”ì¼_\",\n",
    "                \"ì¼ìš”ì¼_\",\n",
    "                \"ì£¼ì¤‘_\",\n",
    "                \"ì£¼ë§_\",\n",
    "                \"ì‹œê°„ëŒ€_\",\n",
    "                \"ë‚¨ì„±_ë§¤ì¶œ\",\n",
    "                \"ì—¬ì„±_ë§¤ì¶œ\",\n",
    "                \"ì—°ë ¹ëŒ€_\",\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ìœ ì§€\n",
    "    sales_cols = [col for col in sales_cols if col != \"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\"]\n",
    "\n",
    "    print(f\"ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€ë¥¼ ìœ„í•´ ì œê±°í•  ë§¤ì¶œ ê´€ë ¨ ì»¬ëŸ¼: {len(sales_cols)}ê°œ\")\n",
    "    print(f\"ì œê±° ì»¬ëŸ¼ ì˜ˆì‹œ: {sales_cols[:5]}\")\n",
    "\n",
    "    drop_cols.extend(sales_cols)\n",
    "    df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
    "\n",
    "    # ê²°ì¸¡ê°’ì´ ë„ˆë¬´ ë§ì€ ì»¬ëŸ¼ ì œê±° (70% ì´ìƒ)\n",
    "    null_ratio = df.isnull().mean()\n",
    "    high_null_cols = null_ratio[null_ratio > 0.7].index.tolist()\n",
    "    print(f\"ê²°ì¸¡ë¥  70% ì´ìƒ ì»¬ëŸ¼ ì œê±°: {len(high_null_cols)}ê°œ\")\n",
    "    if high_null_cols:\n",
    "        df = df.drop(columns=high_null_cols)\n",
    "\n",
    "    # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "    if \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\" in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_encoded\"] = le.fit_transform(\n",
    "            df[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"].astype(str)\n",
    "        )\n",
    "        df = df.drop(columns=[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"])\n",
    "\n",
    "    # LocalPeople ê´€ë ¨ ì»¬ëŸ¼ í™•ì¸\n",
    "    people_cols = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if any(keyword in col for keyword in [\"ìƒí™œì¸êµ¬ìˆ˜\", \"ë‚¨ì\", \"ì—¬ì\"])\n",
    "    ]\n",
    "    print(f\"ğŸ“Š LocalPeople ê´€ë ¨ ì»¬ëŸ¼: {len(people_cols)}ê°œ\")\n",
    "\n",
    "    if len(people_cols) == 0:\n",
    "        print(\"âš ï¸ ê²½ê³ : LocalPeople ë°ì´í„°ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
    "    else:\n",
    "        print(\"âœ… LocalPeople ë°ì´í„° í¬í•¨ í™•ì¸ë¨\")\n",
    "        # ëª‡ ê°œ ì»¬ëŸ¼ëª… ì¶œë ¥\n",
    "        sample_cols = people_cols[:5]\n",
    "        print(f\"   ì˜ˆì‹œ: {sample_cols}\")\n",
    "\n",
    "    print(f\"ì „ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d49a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model_fixed(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"ìˆ˜ì •ëœ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\"\"\"\n",
    "    print(\"\\n=== ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ===\")\n",
    "    print(f\"í›ˆë ¨ ë°ì´í„°: {X_train.shape}, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}\")\n",
    "\n",
    "    # íƒ€ê²Ÿ ë³€ìˆ˜ ë¡œê·¸ ë³€í™˜\n",
    "    y_train_log = np.log1p(y_train.clip(lower=0))\n",
    "\n",
    "    # RandomForest ëª¨ë¸\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100, max_depth=15, random_state=42, n_jobs=-1, oob_score=True\n",
    "    )\n",
    "\n",
    "    print(\"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
    "    model.fit(X_train, y_train_log)\n",
    "    print(\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "\n",
    "    # ì˜ˆì¸¡\n",
    "    print(\"ğŸ”® ì˜ˆì¸¡ ì¤‘...\")\n",
    "    y_pred_log = model.predict(X_test)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_pred = np.clip(y_pred, 0, None)  # ìŒìˆ˜ ì œê±°\n",
    "\n",
    "    # ì„±ëŠ¥ í‰ê°€\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ¯ ìˆ˜ì •ëœ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"MSE:  {mse:,.0f}\")\n",
    "    print(f\"RMSE: {rmse:,.0f} ì›\")\n",
    "    print(f\"MAE:  {mae:,.0f} ì›\")\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê·  ë§¤ì¶œ: {y_test.mean():,.0f} ì›\")\n",
    "    print(f\"Out-of-Bag Score: {model.oob_score_:.4f}\")\n",
    "\n",
    "    # ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ì¶œë ¥\n",
    "    feature_importance = pd.DataFrame(\n",
    "        {\"feature\": X_train.columns, \"importance\": model.feature_importances_}\n",
    "    ).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    print(f\"\\n--- ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ---\")\n",
    "    for i, (_, row) in enumerate(feature_importance.head(20).iterrows(), 1):\n",
    "        is_people = any(\n",
    "            keyword in row[\"feature\"] for keyword in [\"ìƒí™œì¸êµ¬ìˆ˜\", \"ë‚¨ì\", \"ì—¬ì\"]\n",
    "        )\n",
    "        marker = \"ğŸ \" if is_people else \"ğŸª\"\n",
    "        print(f\"{i:2d}. {marker} {row['feature'][:50]}: {row['importance']:.4f}\")\n",
    "\n",
    "    # LocalPeople ë°ì´í„° ê¸°ì—¬ë„\n",
    "    people_features = feature_importance[\n",
    "        feature_importance[\"feature\"].str.contains(\"ìƒí™œì¸êµ¬ìˆ˜|ë‚¨ì|ì—¬ì\", regex=True)\n",
    "    ]\n",
    "    people_importance = people_features[\"importance\"].sum()\n",
    "\n",
    "    print(\n",
    "        f\"\\nğŸ“Š LocalPeople ë°ì´í„° ì´ ê¸°ì—¬ë„: {people_importance:.4f} ({people_importance*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    if people_importance < 0.05:\n",
    "        print(\"âš ï¸ LocalPeople ë°ì´í„° ê¸°ì—¬ë„ê°€ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤.\")\n",
    "    elif people_importance < 0.15:\n",
    "        print(\"ğŸ”¶ LocalPeople ë°ì´í„° ê¸°ì—¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"âœ… LocalPeople ë°ì´í„°ê°€ ìœ ì˜ë¯¸í•˜ê²Œ ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    return (\n",
    "        model,\n",
    "        {\"mse\": mse, \"rmse\": rmse, \"mae\": mae},\n",
    "        feature_importance,\n",
    "        people_importance,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82ac19ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_metrics(\n",
    "    model, metrics, feature_importance_df, people_importance, config\n",
    "):\n",
    "    \"\"\"ëª¨ë¸ê³¼ í‰ê°€ì§€í‘œ ì €ì¥\"\"\"\n",
    "\n",
    "    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ê¸°ì¤€)\n",
    "    script_dir = os.getcwd()\n",
    "    results_dir = os.path.join(script_dir, \"results\")\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "        print(f\"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±: {results_dir}\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # 1. ëª¨ë¸ ì €ì¥\n",
    "    model_filename = os.path.join(results_dir, f\"localpeople_model_{timestamp}.joblib\")\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_filename}\")\n",
    "\n",
    "    # 2. í‰ê°€ì§€í‘œ CSV ì €ì¥\n",
    "    metrics_data = {\n",
    "        \"ì‹¤í–‰ì‹œê°„\": [timestamp],\n",
    "        \"MSE\": [metrics[\"mse\"]],\n",
    "        \"RMSE\": [metrics[\"rmse\"]],\n",
    "        \"MAE\": [metrics[\"mae\"]],\n",
    "        \"LocalPeople_ê¸°ì—¬ë„\": [people_importance],\n",
    "        \"LocalPeople_ê¸°ì—¬ë„_í¼ì„¼íŠ¸\": [people_importance * 100],\n",
    "        \"OOB_Score\": [model.oob_score_],\n",
    "        \"í…ŒìŠ¤íŠ¸_ë…„ë„\": [config[\"test_year\"]],\n",
    "        \"í›ˆë ¨_ë°ì´í„°_í¬ê¸°\": [config[\"train_size\"]],\n",
    "        \"í…ŒìŠ¤íŠ¸_ë°ì´í„°_í¬ê¸°\": [config[\"test_size\"]],\n",
    "        \"íŠ¹ì„±_ê°œìˆ˜\": [config[\"n_features\"]],\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_filename = os.path.join(results_dir, f\"localpeople_metrics_{timestamp}.csv\")\n",
    "    metrics_df.to_csv(metrics_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ“Š í‰ê°€ì§€í‘œ CSV ì €ì¥ ì™„ë£Œ: {metrics_filename}\")\n",
    "\n",
    "    # 3. íŠ¹ì„± ì¤‘ìš”ë„ ì €ì¥\n",
    "    importance_filename = os.path.join(\n",
    "        results_dir, f\"localpeople_importance_{timestamp}.csv\"\n",
    "    )\n",
    "    feature_importance_df.to_csv(importance_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ CSV ì €ì¥ ì™„ë£Œ: {importance_filename}\")\n",
    "\n",
    "    # 4. ì‹¤í–‰ ì •ë³´ ìš”ì•½ ì €ì¥\n",
    "    summary_data = {\n",
    "        \"í•­ëª©\": [\n",
    "            \"ì‹¤í–‰ì‹œê°„\",\n",
    "            \"MSE\",\n",
    "            \"RMSE (ì›)\",\n",
    "            \"MAE (ì›)\",\n",
    "            \"LocalPeople ê¸°ì—¬ë„ (%)\",\n",
    "            \"OOB Score\",\n",
    "            \"í…ŒìŠ¤íŠ¸ ë…„ë„\",\n",
    "            \"í›ˆë ¨ ë°ì´í„° í¬ê¸°\",\n",
    "            \"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°\",\n",
    "            \"íŠ¹ì„± ê°œìˆ˜\",\n",
    "        ],\n",
    "        \"ê°’\": [\n",
    "            timestamp,\n",
    "            f\"{metrics['mse']:,.0f}\",\n",
    "            f\"{metrics['rmse']:,.0f}\",\n",
    "            f\"{metrics['mae']:,.0f}\",\n",
    "            f\"{people_importance*100:.1f}%\",\n",
    "            f\"{model.oob_score_:.4f}\",\n",
    "            config[\"test_year\"],\n",
    "            f\"{config['train_size']:,}\",\n",
    "            f\"{config['test_size']:,}\",\n",
    "            config[\"n_features\"],\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_filename = os.path.join(results_dir, f\"localpeople_summary_{timestamp}.csv\")\n",
    "    summary_df.to_csv(summary_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ“‹ ëª¨ë¸ ìš”ì•½ CSV ì €ì¥ ì™„ë£Œ: {summary_filename}\")\n",
    "\n",
    "    print(f\"\\nğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ '{results_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    return {\n",
    "        \"model_file\": model_filename,\n",
    "        \"metrics_file\": metrics_filename,\n",
    "        \"importance_file\": importance_filename,\n",
    "        \"summary_file\": summary_filename,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f12fb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ìˆ˜ì •ëœ ìƒê¶Œ ë§¤ì¶œ ì˜ˆì¸¡ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸\n",
      "==================================================\n",
      "=== ìˆ˜ì •ëœ ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘ ===\n",
      "\n",
      "ğŸ“… 2019ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2019 ë¡œë“œ ì™„ë£Œ: 65666í–‰\n",
      "  ğŸ”„ 2019ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2019ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      201901 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201902 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201903 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2019ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16273 + ì¸êµ¬ 424 â†’ 16273í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2019ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2019ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      201904 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201905 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201906 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2019ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16418 + ì¸êµ¬ 424 â†’ 16418í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2019ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2019ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      201907 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201908 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201909 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2019ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16456 + ì¸êµ¬ 424 â†’ 16456í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2019ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2019ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      201910 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201911 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      201912 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2019ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16519 + ì¸êµ¬ 424 â†’ 16519í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "\n",
      "ğŸ“… 2020ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2020 ë¡œë“œ ì™„ë£Œ: 66501í–‰\n",
      "  ğŸ”„ 2020ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2020ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202001 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202002 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202003 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2020ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16502 + ì¸êµ¬ 424 â†’ 16502í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.6%\n",
      "  ğŸ”„ 2020ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2020ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202004 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202005 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202006 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2020ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16648 + ì¸êµ¬ 424 â†’ 16648í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2020ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2020ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202007 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202008 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202009 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2020ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16676 + ì¸êµ¬ 424 â†’ 16676í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.6%\n",
      "  ğŸ”„ 2020ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2020ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202010 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202011 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202012 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2020ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16675 + ì¸êµ¬ 424 â†’ 16675í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.6%\n",
      "\n",
      "ğŸ“… 2021ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2021 ë¡œë“œ ì™„ë£Œ: 70071í–‰\n",
      "  ğŸ”„ 2021ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2021ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202101 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202102 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202103 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2021ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17536 + ì¸êµ¬ 424 â†’ 17536í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2021ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2021ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202104 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202105 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202106 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2021ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17541 + ì¸êµ¬ 424 â†’ 17541í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2021ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2021ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202107 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202108 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202109 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2021ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17514 + ì¸êµ¬ 424 â†’ 17514í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2021ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2021ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202110 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202111 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202112 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2021ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17480 + ì¸êµ¬ 424 â†’ 17480í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.6%\n",
      "\n",
      "ğŸ“… 2022ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2022 ë¡œë“œ ì™„ë£Œ: 69440í–‰\n",
      "  ğŸ”„ 2022ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2022ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202201 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202202 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202203 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2022ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17394 + ì¸êµ¬ 424 â†’ 17394í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.6%\n",
      "  ğŸ”„ 2022ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2022ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202204 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202205 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202206 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2022ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17401 + ì¸êµ¬ 424 â†’ 17401í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2022ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2022ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202207 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202208 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202209 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2022ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17346 + ì¸êµ¬ 424 â†’ 17346í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2022ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2022ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202210 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202211 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202212 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2022ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17299 + ì¸êµ¬ 424 â†’ 17299í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "\n",
      "ğŸ“… 2023ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2023 ë¡œë“œ ì™„ë£Œ: 68643í–‰\n",
      "  ğŸ”„ 2023ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2023ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202301 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202302 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202303 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2023ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17188 + ì¸êµ¬ 424 â†’ 17188í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2023ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2023ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202304 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202305 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202306 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2023ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17196 + ì¸êµ¬ 424 â†’ 17196í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2023ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2023ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202307 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202308 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202309 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2023ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17137 + ì¸êµ¬ 424 â†’ 17137í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2023ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2023ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202310 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202311 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202312 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2023ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17122 + ì¸êµ¬ 424 â†’ 17122í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "\n",
      "ğŸ“… 2024ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2024 ë¡œë“œ ì™„ë£Œ: 67900í–‰\n",
      "  ğŸ”„ 2024ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2024ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202401 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202402 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202403 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2024ë…„ 1ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17044 + ì¸êµ¬ 424 â†’ 17044í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2024ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2024ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202404 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202405 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202406 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2024ë…„ 2ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17048 + ì¸êµ¬ 424 â†’ 17048í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2024ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2024ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202407 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202408 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202409 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2024ë…„ 3ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16937 + ì¸êµ¬ 424 â†’ 16937í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "  ğŸ”„ 2024ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2024ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "      202410 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202411 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "      202412 ì™„ë£Œ (424ê°œ í–‰ì •ë™)\n",
      "    2024ë…„ 4ë¶„ê¸° ì¸êµ¬ ë°ì´í„° ì§‘ê³„ ì™„ë£Œ: 424ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16871 + ì¸êµ¬ 424 â†’ 16871í–‰\n",
      "    ğŸ“Š ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.5%\n",
      "\n",
      "ğŸ”— ì „ì²´ ë°ì´í„° ê²°í•© ì¤‘...\n",
      "âœ… ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: (408221, 82)\n",
      "\n",
      "=== ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ===\n",
      "ì›ë³¸ ë°ì´í„° í¬ê¸°: (408221, 82)\n",
      "ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€ë¥¼ ìœ„í•´ ì œê±°í•  ë§¤ì¶œ ê´€ë ¨ ì»¬ëŸ¼: 47ê°œ\n",
      "ì œê±° ì»¬ëŸ¼ ì˜ˆì‹œ: ['ë‹¹ì›”_ë§¤ì¶œ_ê±´ìˆ˜', 'ì£¼ì¤‘_ë§¤ì¶œ_ê¸ˆì•¡', 'ì£¼ë§_ë§¤ì¶œ_ê¸ˆì•¡', 'ì›”ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡', 'í™”ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡']\n",
      "ê²°ì¸¡ë¥  70% ì´ìƒ ì»¬ëŸ¼ ì œê±°: 0ê°œ\n",
      "ğŸ“Š LocalPeople ê´€ë ¨ ì»¬ëŸ¼: 29ê°œ\n",
      "âœ… LocalPeople ë°ì´í„° í¬í•¨ í™•ì¸ë¨\n",
      "   ì˜ˆì‹œ: ['ì´ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜']\n",
      "ì „ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: (408221, 33)\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ ìˆ˜ì •ëœ ìƒê¶Œ ë§¤ì¶œ ì˜ˆì¸¡ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ì„¤ì •\n",
    "YEARS = range(2019, 2025)\n",
    "PEOPLE_DIR = \"../../Data/LocalPeople\"\n",
    "BIZ_DIR = \"../../Data/Trading_Area\"\n",
    "TEST_YEAR = 2024\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ ë° ë³‘í•© (ìˆ˜ì •ëœ ë²„ì „)\n",
    "master_df = create_master_dataset_fixed(YEARS, PEOPLE_DIR, BIZ_DIR)\n",
    "\n",
    "# 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "processed_df = preprocess_data_fixed(master_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f27d508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ë°ì´í„° ë¶„í•  (2024ë…„ í…ŒìŠ¤íŠ¸) ===\n",
      "í›ˆë ¨ ë°ì´í„°: 340321í–‰\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°: 67900í–‰\n"
     ]
    }
   ],
   "source": [
    "# 3. ë°ì´í„° ë¶„í• \n",
    "print(f\"\\n=== ë°ì´í„° ë¶„í•  ({TEST_YEAR}ë…„ í…ŒìŠ¤íŠ¸) ===\")\n",
    "train_mask = processed_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] < (TEST_YEAR * 10 + 1)\n",
    "test_mask = processed_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] >= (TEST_YEAR * 10 + 1)\n",
    "\n",
    "train_df = processed_df[train_mask].copy()\n",
    "test_df = processed_df[test_mask].copy()\n",
    "\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_df)}í–‰\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}í–‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81345844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...\n"
     ]
    }
   ],
   "source": [
    "# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "target_col = \"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\"\n",
    "feature_cols = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df[target_col]\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df[target_col]\n",
    "\n",
    "# ê²°ì¸¡ê°’ ì²˜ë¦¬\n",
    "print(\"ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...\")\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "X_train_filled = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_test_filled = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31420ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ===\n",
      "í›ˆë ¨ ë°ì´í„°: (340321, 32), í…ŒìŠ¤íŠ¸ ë°ì´í„°: (67900, 32)\n",
      "ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n",
      "âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "ğŸ”® ì˜ˆì¸¡ ì¤‘...\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ ìˆ˜ì •ëœ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\n",
      "============================================================\n",
      "MSE:  89,297,344,592,772,399,104\n",
      "RMSE: 9,449,727,223 ì›\n",
      "MAE:  826,261,234 ì›\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê·  ë§¤ì¶œ: 1,532,612,027 ì›\n",
      "Out-of-Bag Score: 0.6895\n",
      "\n",
      "--- ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ---\n",
      " 1. ğŸª ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_encoded: 0.5833\n",
      " 2. ğŸª í–‰ì •ë™ì½”ë“œ: 0.0478\n",
      " 3. ğŸ  ì—¬ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0404\n",
      " 4. ğŸ  ë‚¨ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0345\n",
      " 5. ğŸ  ë‚¨ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0231\n",
      " 6. ğŸ  ë‚¨ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0164\n",
      " 7. ğŸ  ì—¬ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0156\n",
      " 8. ğŸ  ì—¬ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0155\n",
      " 9. ğŸ  ì—¬ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0138\n",
      "10. ğŸ  ë‚¨ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0137\n",
      "11. ğŸ  ë‚¨ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0132\n",
      "12. ğŸ  ë‚¨ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0132\n",
      "13. ğŸ  ë‚¨ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0131\n",
      "14. ğŸ  ì—¬ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0125\n",
      "15. ğŸ  ì—¬ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0116\n",
      "16. ğŸ  ì—¬ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜: 0.0116\n",
      "17. ğŸ  ë‚¨ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0113\n",
      "18. ğŸ  ë‚¨ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0106\n",
      "19. ğŸª ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ: 0.0095\n",
      "20. ğŸ  ë‚¨ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0093\n",
      "\n",
      "ğŸ“Š LocalPeople ë°ì´í„° ì´ ê¸°ì—¬ë„: 0.3595 (35.9%)\n",
      "âœ… LocalPeople ë°ì´í„°ê°€ ìœ ì˜ë¯¸í•˜ê²Œ ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ‰ ìˆ˜ì •ëœ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 4. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "model, metrics, feature_importance, people_importance = train_and_evaluate_model_fixed(\n",
    "    X_train_filled, y_train, X_test_filled, y_test\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ‰ ìˆ˜ì •ëœ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73ed32af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/Code/Analyze_with_LocalPeople/results/localpeople_model_20250619_212155.joblib\n",
      "ğŸ“Š í‰ê°€ì§€í‘œ CSV ì €ì¥ ì™„ë£Œ: /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/Code/Analyze_with_LocalPeople/results/localpeople_metrics_20250619_212155.csv\n",
      "ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ CSV ì €ì¥ ì™„ë£Œ: /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/Code/Analyze_with_LocalPeople/results/localpeople_importance_20250619_212155.csv\n",
      "ğŸ“‹ ëª¨ë¸ ìš”ì•½ CSV ì €ì¥ ì™„ë£Œ: /Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/Code/Analyze_with_LocalPeople/results/localpeople_summary_20250619_212155.csv\n",
      "\n",
      "ğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ '/Users/rubidium/Project/BDP/test/BigDataProgramming_TeamI/Code/Analyze_with_LocalPeople/results' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "\n",
      "ğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 5. ëª¨ë¸ ë° ê²°ê³¼ ì €ì¥\n",
    "config = {\n",
    "    \"test_year\": TEST_YEAR,\n",
    "    \"train_size\": len(train_df),\n",
    "    \"test_size\": len(test_df),\n",
    "    \"n_features\": len(feature_cols),\n",
    "}\n",
    "result = save_model_and_metrics(\n",
    "    model, metrics, feature_importance, people_importance, config\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
