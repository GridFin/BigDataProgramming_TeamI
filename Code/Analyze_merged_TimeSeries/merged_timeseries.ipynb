{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e1c493e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 폴더 경로: c:\\Users\\rladj\\OneDrive\\바탕 화면\\코딩\\4학년\\빅데\\빅데 팀플\\final\\BigDataProgramming_TeamI\\Data\\LocalPeople\n",
      "\n",
      "2019년 1분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_201901.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_201902.csv 로드 완료, 284928행\n",
      "LOCAL_PEOPLE_DONG_201903.csv 로드 완료, 315456행\n",
      "2019년 1분기 집계 완료, 424개 행정동\n",
      "\n",
      "2019년 2분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_201904.csv 로드 완료, 305280행\n",
      "LOCAL_PEOPLE_DONG_201905.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_201906.csv 로드 완료, 305280행\n",
      "2019년 2분기 집계 완료, 424개 행정동\n",
      "\n",
      "2019년 3분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_201907.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_201908.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_201909.csv 로드 완료, 305280행\n",
      "2019년 3분기 집계 완료, 424개 행정동\n",
      "\n",
      "2019년 4분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_201910.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_201911.csv 로드 완료, 305280행\n",
      "LOCAL_PEOPLE_DONG_201912.csv 로드 완료, 315456행\n",
      "2019년 4분기 집계 완료, 424개 행정동\n",
      "\n",
      "2020년 1분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202001.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202002.csv 로드 완료, 295104행\n",
      "LOCAL_PEOPLE_DONG_202003.csv 로드 완료, 315456행\n",
      "2020년 1분기 집계 완료, 424개 행정동\n",
      "\n",
      "2020년 2분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202004.csv 로드 완료, 305280행\n",
      "LOCAL_PEOPLE_DONG_202005.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202006.csv 로드 완료, 305280행\n",
      "2020년 2분기 집계 완료, 424개 행정동\n",
      "\n",
      "2020년 3분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202007.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202008.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202009.csv 로드 완료, 305280행\n",
      "2020년 3분기 집계 완료, 424개 행정동\n",
      "\n",
      "2020년 4분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202010.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202011.csv 로드 완료, 305280행\n",
      "LOCAL_PEOPLE_DONG_202012.csv 로드 완료, 315456행\n",
      "2020년 4분기 집계 완료, 424개 행정동\n",
      "\n",
      "2021년 1분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202101.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202102.csv 로드 완료, 284928행\n",
      "LOCAL_PEOPLE_DONG_202103.csv 로드 완료, 315456행\n",
      "2021년 1분기 집계 완료, 424개 행정동\n",
      "\n",
      "2021년 2분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202104.csv 로드 완료, 305280행\n",
      "LOCAL_PEOPLE_DONG_202105.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202106.csv 로드 완료, 305280행\n",
      "2021년 2분기 집계 완료, 424개 행정동\n",
      "\n",
      "2021년 3분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202107.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202108.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202109.csv 로드 완료, 305280행\n",
      "2021년 3분기 집계 완료, 424개 행정동\n",
      "\n",
      "2021년 4분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202110.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202111.csv 로드 완료, 305280행\n",
      "LOCAL_PEOPLE_DONG_202112.csv 로드 완료, 315456행\n",
      "2021년 4분기 집계 완료, 424개 행정동\n",
      "\n",
      "2022년 1분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202201.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202202.csv 로드 완료, 284928행\n",
      "LOCAL_PEOPLE_DONG_202203.csv 로드 완료, 315456행\n",
      "2022년 1분기 집계 완료, 424개 행정동\n",
      "\n",
      "2022년 2분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202204.csv 로드 완료, 305280행\n",
      "LOCAL_PEOPLE_DONG_202205.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202206.csv 로드 완료, 305280행\n",
      "2022년 2분기 집계 완료, 424개 행정동\n",
      "\n",
      "2022년 3분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202207.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202208.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202209.csv 로드 완료, 305280행\n",
      "2022년 3분기 집계 완료, 424개 행정동\n",
      "\n",
      "2022년 4분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202210.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202211.csv 로드 완료, 305280행\n",
      "LOCAL_PEOPLE_DONG_202212.csv 로드 완료, 315456행\n",
      "2022년 4분기 집계 완료, 424개 행정동\n",
      "\n",
      "2023년 1분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202301.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202302.csv 로드 완료, 284928행\n",
      "LOCAL_PEOPLE_DONG_202303.csv 로드 완료, 315456행\n",
      "2023년 1분기 집계 완료, 424개 행정동\n",
      "\n",
      "2023년 2분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202304.csv 로드 완료, 305280행\n",
      "LOCAL_PEOPLE_DONG_202305.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202306.csv 로드 완료, 305280행\n",
      "2023년 2분기 집계 완료, 424개 행정동\n",
      "\n",
      "2023년 3분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202307.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202308.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202309.csv 로드 완료, 305280행\n",
      "2023년 3분기 집계 완료, 424개 행정동\n",
      "\n",
      "2023년 4분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202310.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202311.csv 로드 완료, 305280행\n",
      "LOCAL_PEOPLE_DONG_202312.csv 로드 완료, 315456행\n",
      "2023년 4분기 집계 완료, 424개 행정동\n",
      "\n",
      "2024년 1분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202401.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202402.csv 로드 완료, 295104행\n",
      "LOCAL_PEOPLE_DONG_202403.csv 로드 완료, 315456행\n",
      "2024년 1분기 집계 완료, 424개 행정동\n",
      "\n",
      "2024년 2분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202404.csv 로드 완료, 305280행\n",
      "LOCAL_PEOPLE_DONG_202405.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202406.csv 로드 완료, 305280행\n",
      "2024년 2분기 집계 완료, 424개 행정동\n",
      "\n",
      "2024년 3분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202407.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202408.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202409.csv 로드 완료, 305280행\n",
      "2024년 3분기 집계 완료, 424개 행정동\n",
      "\n",
      "2024년 4분기 처리 시작\n",
      "LOCAL_PEOPLE_DONG_202410.csv 로드 완료, 315456행\n",
      "LOCAL_PEOPLE_DONG_202411.csv 로드 완료, 305280행\n",
      "LOCAL_PEOPLE_DONG_202412.csv 로드 완료, 315456행\n",
      "2024년 4분기 집계 완료, 424개 행정동\n",
      "\n",
      "전체 완료: 총 10176행, 24개 분기\n",
      "20191 병합 중...\n",
      "→ 병합 완료: 16273행\n",
      "20192 병합 중...\n",
      "→ 병합 완료: 16418행\n",
      "20193 병합 중...\n",
      "→ 병합 완료: 16456행\n",
      "20194 병합 중...\n",
      "→ 병합 완료: 16519행\n",
      "20201 병합 중...\n",
      "→ 병합 완료: 16502행\n",
      "20202 병합 중...\n",
      "→ 병합 완료: 16648행\n",
      "20203 병합 중...\n",
      "→ 병합 완료: 16676행\n",
      "20204 병합 중...\n",
      "→ 병합 완료: 16675행\n",
      "20211 병합 중...\n",
      "→ 병합 완료: 17536행\n",
      "20212 병합 중...\n",
      "→ 병합 완료: 17541행\n",
      "20213 병합 중...\n",
      "→ 병합 완료: 17514행\n",
      "20214 병합 중...\n",
      "→ 병합 완료: 17480행\n",
      "20221 병합 중...\n",
      "→ 병합 완료: 17394행\n",
      "20222 병합 중...\n",
      "→ 병합 완료: 17401행\n",
      "20223 병합 중...\n",
      "→ 병합 완료: 17346행\n",
      "20224 병합 중...\n",
      "→ 병합 완료: 17299행\n",
      "20231 병합 중...\n",
      "→ 병합 완료: 17188행\n",
      "20232 병합 중...\n",
      "→ 병합 완료: 17196행\n",
      "20233 병합 중...\n",
      "→ 병합 완료: 17137행\n",
      "20234 병합 중...\n",
      "→ 병합 완료: 17122행\n",
      "20241 병합 중...\n",
      "→ 병합 완료: 17044행\n",
      "20242 병합 중...\n",
      "→ 병합 완료: 17048행\n",
      "20243 병합 중...\n",
      "→ 병합 완료: 16937행\n",
      "20244 병합 중...\n",
      "→ 병합 완료: 16871행\n",
      "Lag 피처 추가 완료 → 컬럼 수 114\n",
      "\n",
      "최종 마스터 데이터셋 크기: (408221, 114)\n",
      "전체 컬럼 수: 113\n",
      "숫자형 컬럼 수: 108\n",
      "숫자형 컬럼 이름:\n",
      " ['기준_년분기_코드', '행정동_코드_x', '당월_매출_건수', '주중_매출_금액', '주말_매출_금액', '월요일_매출_금액', '화요일_매출_금액', '수요일_매출_금액', '목요일_매출_금액', '금요일_매출_금액', '토요일_매출_금액', '일요일_매출_금액', '시간대_00~06_매출_금액', '시간대_06~11_매출_금액', '시간대_11~14_매출_금액', '시간대_14~17_매출_금액', '시간대_17~21_매출_금액', '시간대_21~24_매출_금액', '남성_매출_금액', '여성_매출_금액', '연령대_10_매출_금액', '연령대_20_매출_금액', '연령대_30_매출_금액', '연령대_40_매출_금액', '연령대_50_매출_금액', '연령대_60_이상_매출_금액', '주중_매출_건수', '주말_매출_건수', '월요일_매출_건수', '화요일_매출_건수', '수요일_매출_건수', '목요일_매출_건수', '금요일_매출_건수', '토요일_매출_건수', '일요일_매출_건수', '시간대_건수~06_매출_건수', '시간대_건수~11_매출_건수', '시간대_건수~14_매출_건수', '시간대_건수~17_매출_건수', '시간대_건수~21_매출_건수', '시간대_건수~24_매출_건수', '남성_매출_건수', '여성_매출_건수', '연령대_10_매출_건수', '연령대_20_매출_건수', '연령대_30_매출_건수', '연령대_40_매출_건수', '연령대_50_매출_건수', '연령대_60_이상_매출_건수', '총생활인구수', '남자0세부터9세생활인구수', '남자10세부터14세생활인구수', '남자15세부터19세생활인구수', '남자20세부터24세생활인구수', '남자25세부터29세생활인구수', '남자30세부터34세생활인구수', '남자35세부터39세생활인구수', '남자40세부터44세생활인구수', '남자45세부터49세생활인구수', '남자50세부터54세생활인구수', '남자55세부터59세생활인구수', '남자60세부터64세생활인구수', '남자65세부터69세생활인구수', '남자70세이상생활인구수', '여자0세부터9세생활인구수', '여자10세부터14세생활인구수', '여자15세부터19세생활인구수', '여자20세부터24세생활인구수', '여자25세부터29세생활인구수', '여자30세부터34세생활인구수', '여자35세부터39세생활인구수', '여자40세부터44세생활인구수', '여자45세부터49세생활인구수', '여자50세부터54세생활인구수', '여자55세부터59세생활인구수', '여자60세부터64세생활인구수', '여자65세부터69세생활인구수', '여자70세이상생활인구수', '연도', '분기', '행정동_코드_y', '총_직장_인구_수', '남성_직장_인구_수', '여성_직장_인구_수', '연령대_10_직장_인구_수', '연령대_20_직장_인구_수', '연령대_30_직장_인구_수', '연령대_40_직장_인구_수', '연령대_50_직장_인구_수', '연령대_60_이상_직장_인구_수', '남성연령대_10_직장_인구_수', '남성연령대_20_직장_인구_수', '남성연령대_30_직장_인구_수', '남성연령대_40_직장_인구_수', '남성연령대_50_직장_인구_수', '남성연령대_60_이상_직장_인구_수', '여성연령대_10_직장_인구_수', '여성연령대_20_직장_인구_수', '여성연령대_30_직장_인구_수', '여성연령대_40_직장_인구_수', '여성연령대_50_직장_인구_수', '여성연령대_60_이상_직장_인구_수', '당월_매출_금액_lag1', '당월_매출_금액_lag4', '총생활인구수_lag1', '총생활인구수_lag4', '총_직장_인구_수_lag1', '총_직장_인구_수_lag4']\n",
      "숫자형 컬럼 수: 108\n",
      "비숫자형 컬럼 수: 5\n",
      "비숫자형 컬럼 목록:\n",
      " ['행정동_코드_명_x', '서비스_업종_코드', '서비스_업종_코드_명', '행정동코드', '행정동_코드_명_y']\n",
      "학습용: 340321행 / 검증용: 67900행 / 특성 수: 62\n",
      "모델 학습 중...\n",
      "학습 완료\n",
      "\n",
      "모델 평가 결과\n",
      "MSE:  5,109,985,332,113,476,608\n",
      "RMSE: 2,260,527,667 원\n",
      "MAE:  233,748,479 원\n",
      "OOB Score: 0.8872\n",
      "\n",
      "============================================================\n",
      "💾 시계열 모델 결과 저장 중...\n",
      "============================================================\n",
      "💾 모델 저장 완료: c:\\Users\\rladj\\OneDrive\\바탕 화면\\코딩\\4학년\\빅데\\빅데 팀플\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\results\\timeseries_model_20250619_112904.joblib\n",
      "📊 평가지표 CSV 저장 완료: c:\\Users\\rladj\\OneDrive\\바탕 화면\\코딩\\4학년\\빅데\\빅데 팀플\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\results\\timeseries_metrics_20250619_112904.csv\n",
      "🔍 특성 중요도 CSV 저장 완료: c:\\Users\\rladj\\OneDrive\\바탕 화면\\코딩\\4학년\\빅데\\빅데 팀플\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\results\\timeseries_importance_20250619_112904.csv\n",
      "📋 모델 요약 CSV 저장 완료: c:\\Users\\rladj\\OneDrive\\바탕 화면\\코딩\\4학년\\빅데\\빅데 팀플\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\results\\timeseries_summary_20250619_112904.csv\n",
      "\n",
      "--- 상위 20개 특성 중요도 ---\n",
      " 1. ⏰ 당월_매출_금액_lag1: 0.9115\n",
      " 2. 📊 업종코드_encoded: 0.0229\n",
      " 3. 📊 기준_년분기_코드: 0.0116\n",
      " 4. ⏰ 당월_매출_금액_lag4: 0.0107\n",
      " 5. 📊 여성연령대_20_직장_인구_수: 0.0023\n",
      " 6. 📊 여자25세부터29세생활인구수: 0.0014\n",
      " 7. 📊 여성연령대_60_이상_직장_인구_수: 0.0014\n",
      " 8. 📊 남자30세부터34세생활인구수: 0.0012\n",
      " 9. 📊 연령대_60_이상_직장_인구_수: 0.0011\n",
      "10. 📊 여자20세부터24세생활인구수: 0.0011\n",
      "11. 📊 분기: 0.0011\n",
      "12. 📊 여자15세부터19세생활인구수: 0.0011\n",
      "13. 📊 여자10세부터14세생활인구수: 0.0011\n",
      "14. 📊 남자0세부터9세생활인구수: 0.0011\n",
      "15. 📊 남자15세부터19세생활인구수: 0.0011\n",
      "16. 📊 남자20세부터24세생활인구수: 0.0010\n",
      "17. 📊 여자70세이상생활인구수: 0.0010\n",
      "18. 📊 남자10세부터14세생활인구수: 0.0010\n",
      "19. 📊 여자0세부터9세생활인구수: 0.0010\n",
      "20. 📊 남자25세부터29세생활인구수: 0.0010\n",
      "\n",
      "📊 Lag 특성 총 기여도: 0.9238 (92.4%)\n",
      "✅ Lag 특성이 유의미하게 기여하고 있습니다.\n",
      "\n",
      "🎉 모든 결과가 'c:\\Users\\rladj\\OneDrive\\바탕 화면\\코딩\\4학년\\빅데\\빅데 팀플\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\results' 폴더에 저장되었습니다!\n",
      "     연도     행정동코드   행정동명        업종        예측_총매출    순위\n",
      "0  2024  11110515  청운효자동  CS100001  6.923591e+09   8.0\n",
      "1  2024  11110515  청운효자동  CS100003  5.679055e+09  10.0\n",
      "2  2024  11110515  청운효자동  CS100004  1.518500e+09  19.0\n",
      "3  2024  11110515  청운효자동  CS100005  5.582597e+08  32.0\n",
      "4  2024  11110515  청운효자동  CS100007  3.083015e+09  14.0\n",
      "📊 2019-2024 분석 결과 저장 완료: c:\\Users\\rladj\\OneDrive\\바탕 화면\\코딩\\4학년\\빅데\\빅데 팀플\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\timeseries_analysis_2019_2024.csv\n",
      "🔮 2025년 예측 결과 저장 완료: c:\\Users\\rladj\\OneDrive\\바탕 화면\\코딩\\4학년\\빅데\\빅데 팀플\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\timeseries_prediction_2025.csv\n",
      "\n",
      "📋 시계열 모델 2025년 예측 결과 샘플:\n",
      "     연도     행정동코드   행정동명        업종    업종명        예측_총매출    순위\n",
      "0  2025  11110515  청운효자동  CS100001  한식음식점  3.597585e+09   3.0\n",
      "1  2025  11110515  청운효자동  CS100002  중식음식점  3.036879e+08  17.0\n",
      "2  2025  11110515  청운효자동  CS100003  일식음식점  3.713122e+08  13.0\n",
      "3  2025  11110515  청운효자동  CS100004  양식음식점  2.752536e+09   4.0\n",
      "4  2025  11110515  청운효자동  CS100005    제과점  4.970719e+08  11.0\n",
      "\n",
      "📊 시계열 모델 분석 요약:\n",
      "  - 2019-2024 분석 데이터: 105390행\n",
      "  - 2025년 예측 데이터: 18059행\n",
      "  - 분석 대상 행정동 수: 424개\n",
      "  - 분석 대상 업종 수: 63개\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = os.path.abspath(\"../../Data/LocalPeople\")\n",
    "print(\"데이터 폴더 경로:\", data_dir)\n",
    "\n",
    "\n",
    "def load_localpeople_quarter(year, quarter, data_dir):\n",
    "    months = {\n",
    "        1: [\"01\", \"02\", \"03\"],\n",
    "        2: [\"04\", \"05\", \"06\"],\n",
    "        3: [\"07\", \"08\", \"09\"],\n",
    "        4: [\"10\", \"11\", \"12\"],\n",
    "    }[quarter]\n",
    "\n",
    "    dfs = []\n",
    "    for m in months:\n",
    "        filename = f\"LOCAL_PEOPLE_DONG_{year}{m}.csv\"\n",
    "        file = os.path.join(data_dir, filename)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            print(f\"파일 없음: {filename}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # 🔥 올바른 CSV 읽기 방식 (Analyze_LocalPeople.py 참조)\n",
    "            expected_cols = [\n",
    "                \"기준일ID\",\n",
    "                \"시간대구분\",\n",
    "                \"행정동코드\",\n",
    "                \"총생활인구수\",\n",
    "                \"남자0세부터9세생활인구수\",\n",
    "                \"남자10세부터14세생활인구수\",\n",
    "                \"남자15세부터19세생활인구수\",\n",
    "                \"남자20세부터24세생활인구수\",\n",
    "                \"남자25세부터29세생활인구수\",\n",
    "                \"남자30세부터34세생활인구수\",\n",
    "                \"남자35세부터39세생활인구수\",\n",
    "                \"남자40세부터44세생활인구수\",\n",
    "                \"남자45세부터49세생활인구수\",\n",
    "                \"남자50세부터54세생활인구수\",\n",
    "                \"남자55세부터59세생활인구수\",\n",
    "                \"남자60세부터64세생활인구수\",\n",
    "                \"남자65세부터69세생활인구수\",\n",
    "                \"남자70세이상생활인구수\",\n",
    "                \"여자0세부터9세생활인구수\",\n",
    "                \"여자10세부터14세생활인구수\",\n",
    "                \"여자15세부터19세생활인구수\",\n",
    "                \"여자20세부터24세생활인구수\",\n",
    "                \"여자25세부터29세생활인구수\",\n",
    "                \"여자30세부터34세생활인구수\",\n",
    "                \"여자35세부터39세생활인구수\",\n",
    "                \"여자40세부터44세생활인구수\",\n",
    "                \"여자45세부터49세생활인구수\",\n",
    "                \"여자50세부터54세생활인구수\",\n",
    "                \"여자55세부터59세생활인구수\",\n",
    "                \"여자60세부터64세생활인구수\",\n",
    "                \"여자65세부터69세생활인구수\",\n",
    "                \"여자70세이상생활인구수\",\n",
    "            ]\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(\n",
    "                    file,\n",
    "                    encoding=\"utf-8\",\n",
    "                    dtype={\"기준일ID\": str, \"시간대구분\": str, \"행정동코드\": str},\n",
    "                    usecols=expected_cols,\n",
    "                    header=0,\n",
    "                )\n",
    "            except:\n",
    "                df = pd.read_csv(\n",
    "                    file,\n",
    "                    encoding=\"cp949\",\n",
    "                    dtype={\"기준일ID\": str, \"시간대구분\": str, \"행정동코드\": str},\n",
    "                    usecols=expected_cols,\n",
    "                    header=0,\n",
    "                )\n",
    "\n",
    "            df[\"행정동코드\"] = df[\"행정동코드\"].astype(str).str.zfill(8)\n",
    "            selected_cols = [\"행정동코드\", \"총생활인구수\"] + [\n",
    "                col\n",
    "                for col in df.columns\n",
    "                if \"생활인구수\" in col and (\"남자\" in col or \"여자\" in col)\n",
    "            ]\n",
    "            df = df[selected_cols]\n",
    "            dfs.append(df)\n",
    "            print(f\"{filename} 로드 완료, {len(df)}행\")\n",
    "        except Exception as e:\n",
    "            print(f\"{filename} 읽기 실패: {e}\")\n",
    "\n",
    "    if not dfs:\n",
    "        print(f\"{year}년 {quarter}분기: 유효한 파일 없음 → 건너뜀\")\n",
    "        return None\n",
    "\n",
    "    merged = pd.concat(dfs)\n",
    "    result = merged.groupby(\"행정동코드\").sum().reset_index()\n",
    "    result[\"연도\"] = year\n",
    "    result[\"분기\"] = quarter\n",
    "    result[\"기준_년분기_코드\"] = int(f\"{year}{quarter}\")\n",
    "    print(f\"{year}년 {quarter}분기 집계 완료, {len(result)}개 행정동\")\n",
    "    return result\n",
    "\n",
    "\n",
    "all_local = []\n",
    "for year in range(2019, 2025):\n",
    "    for quarter in [1, 2, 3, 4]:\n",
    "        print(f\"\\n{year}년 {quarter}분기 처리 시작\")\n",
    "        res = load_localpeople_quarter(year, quarter, data_dir)\n",
    "        if res is not None:\n",
    "            all_local.append(res)\n",
    "\n",
    "if all_local:\n",
    "    local_df = pd.concat(all_local, ignore_index=True)\n",
    "    print(\n",
    "        f\"\\n전체 완료: 총 {len(local_df)}행, {local_df['기준_년분기_코드'].nunique()}개 분기\"\n",
    "    )\n",
    "else:\n",
    "    print(\"\\n오류: 로드된 데이터가 없습니다. 경로 또는 파일 누락 여부 확인하세요.\")\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "company_path = os.path.abspath(\"../../Data/CompanyPeople/CompanyPeople.csv\")\n",
    "trading_dir = os.path.abspath(\"../../Data/Trading_Area\")\n",
    "\n",
    "# results 폴더는 preprocess_master 함수에서 절대경로로 생성됩니다\n",
    "\n",
    "# 직장인 데이터 로드 및 전처리\n",
    "company_df = pd.read_csv(company_path, encoding=\"euc-kr\")\n",
    "company_df[\"행정동코드\"] = company_df[\"행정동_코드\"].astype(str).str.zfill(8)\n",
    "company_df[\"기준_년분기_코드\"] = company_df[\"기준_년분기_코드\"].astype(int)\n",
    "\n",
    "\n",
    "# 병합 함수 정의\n",
    "def load_trading_area(year, trading_dir):\n",
    "    file_path = os.path.join(trading_dir, f\"Trading_Area_{year}.csv\")\n",
    "    df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "    df[\"행정동코드\"] = df[\"행정동_코드\"].astype(str).str.zfill(8)\n",
    "    df[\"기준_년분기_코드\"] = df[\"기준_년분기_코드\"].astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "# 마스터 데이터 생성\n",
    "all_merged = []\n",
    "\n",
    "for year in range(2019, 2025):\n",
    "    trading_df = load_trading_area(year, trading_dir)\n",
    "\n",
    "    for quarter in [1, 2, 3, 4]:\n",
    "        quarter_code = int(f\"{year}{quarter}\")\n",
    "        print(f\"{quarter_code} 병합 중...\")\n",
    "\n",
    "        # 분기별 데이터 필터링\n",
    "        trade_q = trading_df[trading_df[\"기준_년분기_코드\"] == quarter_code].copy()\n",
    "        local_q = local_df[local_df[\"기준_년분기_코드\"] == quarter_code].copy()\n",
    "        comp_q = company_df[company_df[\"기준_년분기_코드\"] == quarter_code].copy()\n",
    "\n",
    "        if trade_q.empty:\n",
    "            print(f\"매출 데이터 없음: {quarter_code}\")\n",
    "            continue\n",
    "\n",
    "        # 병합: 매출 + 실거주 (행정동코드 + 분기 기준)\n",
    "        merged = pd.merge(\n",
    "            trade_q,\n",
    "            local_q,\n",
    "            on=[\"행정동코드\", \"기준_년분기_코드\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        # 병합: + 직장인 (동일하게 행정동코드 + 분기 기준)\n",
    "        merged = pd.merge(\n",
    "            merged,\n",
    "            comp_q,\n",
    "            on=[\"행정동코드\", \"기준_년분기_코드\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        print(f\"→ 병합 완료: {len(merged)}행\")\n",
    "        all_merged.append(merged)\n",
    "\n",
    "# 마스터 데이터프레임 완성\n",
    "master_df = pd.concat(all_merged, ignore_index=True)\n",
    "\n",
    "# ---------- ❶ Lag Feature Engineering -------------------\n",
    "#   · key  : 행정동코드 + 서비스_업종_코드\n",
    "#   · lag  : 1분기, 4분기(전년 동기)\n",
    "#   · 대상 : 매출·실거주·직장인 핵심 지표\n",
    "key_cols = [\"행정동코드\", \"서비스_업종_코드\"]\n",
    "lag_steps = [1, 4]  # t-1, t-4\n",
    "base_cols = [\"당월_매출_금액\", \"총생활인구수\", \"총_직장_인구_수\"]\n",
    "\n",
    "master_df = master_df.sort_values(key_cols + [\"기준_년분기_코드\"])\n",
    "\n",
    "for col in base_cols:\n",
    "    for lag in lag_steps:\n",
    "        master_df[f\"{col}_lag{lag}\"] = master_df.groupby(key_cols)[col].shift(lag)\n",
    "\n",
    "print(f\"Lag 피처 추가 완료 → 컬럼 수 {master_df.shape[1]}\")\n",
    "print(f\"\\n최종 마스터 데이터셋 크기: {master_df.shape}\")\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "X_all = master_df.drop(columns=[\"당월_매출_금액\"])\n",
    "X_all_numeric = X_all.select_dtypes(include=[\"number\"])\n",
    "\n",
    "print(\"전체 컬럼 수:\", X_all.shape[1])\n",
    "print(\"숫자형 컬럼 수:\", X_all_numeric.shape[1])\n",
    "print(\"숫자형 컬럼 이름:\\n\", list(X_all_numeric.columns))\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "non_numeric_cols = X_all.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "numeric_cols = X_all.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "print(\"숫자형 컬럼 수:\", len(numeric_cols))\n",
    "print(\"비숫자형 컬럼 수:\", len(non_numeric_cols))\n",
    "print(\"비숫자형 컬럼 목록:\\n\", non_numeric_cols)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "def preprocess_master(df, test_year=2024):\n",
    "    df = df.copy(deep=False)\n",
    "\n",
    "    drop_cols = [\n",
    "        \"행정동_코드_명\",\n",
    "        \"서비스_업종_코드_명\",\n",
    "        \"행정동명\",\n",
    "        \"행정동_코드_명_x\",\n",
    "        \"행정동_코드_명_y\",\n",
    "    ]\n",
    "    # 매출 파생 컬럼 중 'lag' 가 붙은 것은 유지\n",
    "    leakage_cols = [\n",
    "        c\n",
    "        for c in df.columns\n",
    "        if (\"매출\" in c and c != \"당월_매출_금액\") and (\"lag\" not in c)\n",
    "    ]\n",
    "    df.drop(\n",
    "        columns=[col for col in drop_cols + leakage_cols if col in df.columns],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    if \"서비스_업종_코드\" in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[\"업종코드_encoded\"] = le.fit_transform(df[\"서비스_업종_코드\"].astype(str))\n",
    "        df.drop(columns=[\"서비스_업종_코드\"], inplace=True)\n",
    "\n",
    "        # 절대경로로 results 디렉토리 생성 및 저장\n",
    "        script_dir = os.getcwd()\n",
    "        results_dir = os.path.join(script_dir, \"results\")\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        joblib.dump(le, os.path.join(results_dir, \"label_encoder.joblib\"))\n",
    "\n",
    "    y_all = df[\"당월_매출_금액\"].reset_index(drop=True)\n",
    "    quarter_col = df[\"기준_년분기_코드\"].reset_index(drop=True)\n",
    "\n",
    "    X_all = df.drop(columns=[\"당월_매출_금액\"])\n",
    "    # ▶ train_mask / quarter_col 은 0‑부터 다시 매겨진 인덱스를 사용하므로\n",
    "    #   피처도 동일하게 맞춰 줌(인덱스 reset) ← 여기 한 줄이 핵심\n",
    "    X_all_numeric = (\n",
    "        X_all.select_dtypes(include=[\"number\"]).reset_index(drop=True).copy()  # ★ 추가\n",
    "    )\n",
    "\n",
    "    # ──────────────────────── Imputer: fit on train only ────────────────────────\n",
    "    train_mask = quarter_col < test_year * 10 + 1\n",
    "    test_mask = ~train_mask\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_train = pd.DataFrame(\n",
    "        imputer.fit_transform(X_all_numeric[train_mask]),\n",
    "        columns=X_all_numeric.columns,\n",
    "        index=X_all_numeric[train_mask].index,\n",
    "    )\n",
    "    X_test = pd.DataFrame(\n",
    "        imputer.transform(X_all_numeric[test_mask]),\n",
    "        columns=X_all_numeric.columns,\n",
    "        index=X_all_numeric[test_mask].index,\n",
    "    )\n",
    "\n",
    "    # 절대경로로 imputer 저장\n",
    "    script_dir = os.getcwd()\n",
    "    results_dir = os.path.join(script_dir, \"results\")\n",
    "    joblib.dump(imputer, os.path.join(results_dir, \"imputer.joblib\"))\n",
    "\n",
    "    y_train = y_all[train_mask]\n",
    "    y_test = y_all[test_mask]\n",
    "\n",
    "    print(\n",
    "        f\"학습용: {len(X_train)}행 / 검증용: {len(X_test)}행 / 특성 수: {X_train.shape[1]}\"\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test, quarter_col[test_mask]\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, quarter_test = preprocess_master(master_df)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# 로그 변환하여 학습\n",
    "y_train_log = np.log1p(y_train.clip(lower=0))\n",
    "\n",
    "# 모델 정의\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100, max_depth=15, random_state=42, n_jobs=-1, oob_score=True\n",
    ")\n",
    "\n",
    "print(\"모델 학습 중...\")\n",
    "model.fit(X_train, y_train_log)\n",
    "print(\"학습 완료\")\n",
    "\n",
    "\n",
    "def rolling_forecast(model, df_all, feature_cols, start_code=20241):\n",
    "    \"\"\"\n",
    "    시작 분기(start_code)부터 끝까지 순차 예측 → 예측값을 lag1 컬럼에 반영\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    current_code = start_code\n",
    "    max_code = df_all[\"기준_년분기_코드\"].max()\n",
    "\n",
    "    while current_code <= max_code:\n",
    "        mask = df_all[\"기준_년분기_코드\"] == current_code\n",
    "        cur_data = df_all.loc[mask].copy()\n",
    "        X_cur = cur_data[feature_cols]\n",
    "        X_cur = X_cur.fillna(X_train.mean())\n",
    "        y_log = model.predict(X_cur)\n",
    "        y_hat = np.expm1(y_log).clip(min=0)\n",
    "\n",
    "        # 저장용 결과\n",
    "        result_df = cur_data[[\"행정동코드\", \"업종코드_encoded\"]].copy()\n",
    "        result_df[\"기준_년분기_코드\"] = current_code\n",
    "        result_df[\"예측_매출\"] = y_hat\n",
    "        results.append(result_df)\n",
    "\n",
    "        # 예측값을 lag1 컬럼에 주입 → 다음 분기 사용\n",
    "        next_code = current_code + 1\n",
    "        if next_code % 10 == 5:  # 4분기 다음은 +6 → Q1\n",
    "            next_code = (next_code // 10 + 1) * 10 + 1\n",
    "\n",
    "        if next_code <= max_code:\n",
    "            # 🚀 벡터화 최적화: 다음 분기 데이터와 매칭하여 lag1 값 업데이트\n",
    "            next_mask = df_all[\"기준_년분기_코드\"] == next_code\n",
    "            if next_mask.any():\n",
    "                # 현재 분기와 다음 분기 데이터를 merge로 빠르게 매칭\n",
    "                cur_predictions = cur_data[[\"행정동코드\", \"업종코드_encoded\"]].copy()\n",
    "                cur_predictions[\"pred_값\"] = y_hat\n",
    "\n",
    "                # 다음 분기 데이터 추출\n",
    "                next_data = df_all[next_mask][[\"행정동코드\", \"업종코드_encoded\"]].copy()\n",
    "                next_data[\"next_idx\"] = df_all[next_mask].index\n",
    "\n",
    "                # merge로 매칭\n",
    "                merged = pd.merge(\n",
    "                    next_data,\n",
    "                    cur_predictions,\n",
    "                    on=[\"행정동코드\", \"업종코드_encoded\"],\n",
    "                    how=\"left\",\n",
    "                )\n",
    "\n",
    "                # 매칭된 값들을 벡터화로 업데이트\n",
    "                valid_mask = merged[\"pred_값\"].notna()\n",
    "                if valid_mask.any():\n",
    "                    update_indices = merged.loc[valid_mask, \"next_idx\"]\n",
    "                    update_values = merged.loc[valid_mask, \"pred_값\"]\n",
    "                    df_all.loc[update_indices, \"당월_매출_금액_lag1\"] = (\n",
    "                        update_values.values\n",
    "                    )\n",
    "\n",
    "        current_code = next_code\n",
    "    return pd.concat(results, ignore_index=True)\n",
    "\n",
    "\n",
    "# preprocess_master에서 처리된 전체 데이터 재구성\n",
    "def get_processed_df(df, test_year=2024):\n",
    "    \"\"\"preprocess_master와 동일한 처리를 하되, 전체 데이터 반환\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    drop_cols = [\n",
    "        \"행정동_코드_명\",\n",
    "        \"서비스_업종_코드_명\",\n",
    "        \"행정동명\",\n",
    "        \"행정동_코드_명_x\",\n",
    "        \"행정동_코드_명_y\",\n",
    "    ]\n",
    "    # 매출 파생 컬럼 중 'lag' 가 붙은 것은 유지\n",
    "    leakage_cols = [\n",
    "        c\n",
    "        for c in df.columns\n",
    "        if (\"매출\" in c and c != \"당월_매출_금액\") and (\"lag\" not in c)\n",
    "    ]\n",
    "    df.drop(\n",
    "        columns=[col for col in drop_cols + leakage_cols if col in df.columns],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    if \"서비스_업종_코드\" in df.columns:\n",
    "        # 1) 인코더 로드 (절대경로)\n",
    "        script_dir = os.getcwd()\n",
    "        results_dir = os.path.join(script_dir, \"results\")\n",
    "        le = joblib.load(os.path.join(results_dir, \"label_encoder.joblib\"))\n",
    "        # 2) 인코딩 컬럼이 없으면 새로 생성\n",
    "        if \"업종코드_encoded\" not in df.columns:\n",
    "            df[\"업종코드_encoded\"] = le.transform(df[\"서비스_업종_코드\"].astype(str))\n",
    "        # 3) 원본 문자형 컬럼 제거\n",
    "        df.drop(columns=[\"서비스_업종_코드\"], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# 전처리된 전체 데이터 생성\n",
    "processed_df = get_processed_df(master_df)\n",
    "\n",
    "# 롤링 예측 실행 (2024Q1부터)\n",
    "rolling_df = rolling_forecast(\n",
    "    model,\n",
    "    processed_df,  # 전처리된 데이터 사용\n",
    "    feature_cols=X_train.columns,\n",
    "    start_code=20241,\n",
    ")\n",
    "\n",
    "mkeys = [\"기준_년분기_코드\", \"행정동코드\", \"업종코드_encoded\"]\n",
    "\n",
    "# ① rolling 예측 결과 중 테스트 구간만 추려서 key 로 정렬\n",
    "y_pred_df = (\n",
    "    rolling_df[rolling_df[\"기준_년분기_코드\"] >= 20241]\n",
    "    .sort_values(mkeys)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# ② 동일 key 로 y_test(Series) 도 정렬\n",
    "y_test_df = (\n",
    "    processed_df[processed_df[\"기준_년분기_코드\"] >= 20241]\n",
    "    .loc[:, mkeys + [\"당월_매출_금액\"]]\n",
    "    .sort_values(mkeys)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# ③ 매칭 확인\n",
    "assert (y_pred_df[mkeys] == y_test_df[mkeys]).all().all(), \"정렬 불일치\"\n",
    "\n",
    "y_pred = y_pred_df[\"예측_매출\"].values\n",
    "y_test = y_test_df[\"당월_매출_금액\"].values\n",
    "\n",
    "# 평가 지표 계산\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\n모델 평가 결과\")\n",
    "print(f\"MSE:  {mse:,.0f}\")\n",
    "print(f\"RMSE: {rmse:,.0f} 원\")\n",
    "print(f\"MAE:  {mae:,.0f} 원\")\n",
    "print(f\"OOB Score: {model.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "def save_timeseries_model_and_metrics(model, metrics, X_train):\n",
    "    \"\"\"시계열 모델과 평가지표 저장\"\"\"\n",
    "\n",
    "    # 결과 저장 디렉토리 생성 (현재 스크립트 디렉토리 기준)\n",
    "    script_dir = os.getcwd()\n",
    "    results_dir = os.path.join(script_dir, \"results\")\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "        print(f\"📁 결과 디렉토리 생성: {results_dir}\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # 1. 모델 저장\n",
    "    model_filename = os.path.join(results_dir, f\"timeseries_model_{timestamp}.joblib\")\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"💾 모델 저장 완료: {model_filename}\")\n",
    "\n",
    "    # 2. 특성 중요도 계산\n",
    "    feature_importance = pd.DataFrame(\n",
    "        {\"feature\": X_train.columns, \"importance\": model.feature_importances_}\n",
    "    ).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    # Lag 특성 기여도 계산\n",
    "    lag_features = feature_importance[\n",
    "        feature_importance[\"feature\"].str.contains(\"_lag\", regex=True)\n",
    "    ]\n",
    "    lag_importance = lag_features[\"importance\"].sum()\n",
    "\n",
    "    # 3. 평가지표 CSV 저장\n",
    "    metrics_data = {\n",
    "        \"실행시간\": [timestamp],\n",
    "        \"MSE\": [metrics[\"mse\"]],\n",
    "        \"RMSE\": [metrics[\"rmse\"]],\n",
    "        \"MAE\": [metrics[\"mae\"]],\n",
    "        \"Lag_특성_기여도\": [lag_importance],\n",
    "        \"Lag_특성_기여도_퍼센트\": [lag_importance * 100],\n",
    "        \"OOB_Score\": [model.oob_score_],\n",
    "        \"테스트_년도\": [2024],\n",
    "        \"훈련_데이터_크기\": [len(X_train)],\n",
    "        \"테스트_데이터_크기\": [len(y_pred)],\n",
    "        \"특성_개수\": [len(X_train.columns)],\n",
    "        \"롤링_예측_적용\": [\"Yes\"],\n",
    "        \"타깃_리키지_제거\": [\"Yes\"],\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_filename = os.path.join(results_dir, f\"timeseries_metrics_{timestamp}.csv\")\n",
    "    metrics_df.to_csv(metrics_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"📊 평가지표 CSV 저장 완료: {metrics_filename}\")\n",
    "\n",
    "    # 4. 특성 중요도 저장\n",
    "    importance_filename = os.path.join(\n",
    "        results_dir, f\"timeseries_importance_{timestamp}.csv\"\n",
    "    )\n",
    "    feature_importance.to_csv(importance_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"🔍 특성 중요도 CSV 저장 완료: {importance_filename}\")\n",
    "\n",
    "    # 5. 실행 정보 요약 저장\n",
    "    summary_data = {\n",
    "        \"항목\": [\n",
    "            \"실행시간\",\n",
    "            \"MSE\",\n",
    "            \"RMSE (원)\",\n",
    "            \"MAE (원)\",\n",
    "            \"Lag 특성 기여도 (%)\",\n",
    "            \"OOB Score\",\n",
    "            \"테스트 년도\",\n",
    "            \"훈련 데이터 크기\",\n",
    "            \"테스트 데이터 크기\",\n",
    "            \"특성 개수\",\n",
    "            \"롤링 예측 적용\",\n",
    "            \"타깃 리키지 제거\",\n",
    "            \"시계열 특성\",\n",
    "        ],\n",
    "        \"값\": [\n",
    "            timestamp,\n",
    "            f\"{metrics['mse']:,.0f}\",\n",
    "            f\"{metrics['rmse']:,.0f}\",\n",
    "            f\"{metrics['mae']:,.0f}\",\n",
    "            f\"{lag_importance*100:.1f}%\",\n",
    "            f\"{model.oob_score_:.4f}\",\n",
    "            \"2024\",\n",
    "            f\"{len(X_train):,}\",\n",
    "            f\"{len(y_pred):,}\",\n",
    "            len(X_train.columns),\n",
    "            \"Yes\",\n",
    "            \"Yes\",\n",
    "            \"Lag 1분기 + 4분기\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_filename = os.path.join(results_dir, f\"timeseries_summary_{timestamp}.csv\")\n",
    "    summary_df.to_csv(summary_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"📋 모델 요약 CSV 저장 완료: {summary_filename}\")\n",
    "\n",
    "    # 6. 상위 20개 특성 중요도 출력\n",
    "    print(f\"\\n--- 상위 20개 특성 중요도 ---\")\n",
    "    for i, (_, row) in enumerate(feature_importance.head(20).iterrows(), 1):\n",
    "        is_lag = \"_lag\" in row[\"feature\"]\n",
    "        marker = \"⏰\" if is_lag else \"📊\"\n",
    "        print(f\"{i:2d}. {marker} {row['feature'][:50]}: {row['importance']:.4f}\")\n",
    "\n",
    "    print(f\"\\n📊 Lag 특성 총 기여도: {lag_importance:.4f} ({lag_importance*100:.1f}%)\")\n",
    "\n",
    "    if lag_importance < 0.05:\n",
    "        print(\"⚠️ Lag 특성 기여도가 매우 낮습니다.\")\n",
    "    elif lag_importance < 0.15:\n",
    "        print(\"🔶 Lag 특성 기여도가 낮습니다.\")\n",
    "    else:\n",
    "        print(\"✅ Lag 특성이 유의미하게 기여하고 있습니다.\")\n",
    "\n",
    "    print(f\"\\n🎉 모든 결과가 '{results_dir}' 폴더에 저장되었습니다!\")\n",
    "    return {\n",
    "        \"model_file\": model_filename,\n",
    "        \"metrics_file\": metrics_filename,\n",
    "        \"importance_file\": importance_filename,\n",
    "        \"summary_file\": summary_filename,\n",
    "    }\n",
    "\n",
    "\n",
    "# 메타데이터 저장 실행\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"💾 시계열 모델 결과 저장 중...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "save_result = save_timeseries_model_and_metrics(\n",
    "    model, {\"mse\": mse, \"rmse\": rmse, \"mae\": mae}, X_train\n",
    ")\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "# 예측 결과 요약을 위한 메타 정보 추출\n",
    "meta_cols = [\"기준_년분기_코드\", \"행정동코드\", \"행정동_코드_명_x\", \"서비스_업종_코드\"]\n",
    "test_meta = master_df[master_df[\"기준_년분기_코드\"].isin(quarter_test)].copy()\n",
    "test_meta = test_meta[meta_cols].reset_index(drop=True)\n",
    "\n",
    "# 예측 결과 결합\n",
    "test_meta[\"예측_매출\"] = y_pred\n",
    "test_meta[\"실제_매출\"] = y_test_df[\"당월_매출_금액\"].values\n",
    "test_meta[\"연도\"] = test_meta[\"기준_년분기_코드\"] // 10\n",
    "\n",
    "# 연도+동+업종 단위로 집계\n",
    "summary_2024 = (\n",
    "    test_meta.groupby([\"연도\", \"행정동코드\", \"행정동_코드_명_x\", \"서비스_업종_코드\"])\n",
    "    .agg(총매출=(\"실제_매출\", \"sum\"), 예측_총매출=(\"예측_매출\", \"sum\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 순위: 행정동별 업종 순위\n",
    "summary_2024[\"순위\"] = summary_2024.groupby([\"연도\", \"행정동코드\"])[\"예측_총매출\"].rank(\n",
    "    ascending=False, method=\"min\"\n",
    ")\n",
    "\n",
    "# 결과 정리\n",
    "df_2024_result = summary_2024.rename(\n",
    "    columns={\"행정동_코드_명_x\": \"행정동명\", \"서비스_업종_코드\": \"업종\"}\n",
    ")[[\"연도\", \"행정동코드\", \"행정동명\", \"업종\", \"예측_총매출\", \"순위\"]]\n",
    "\n",
    "\n",
    "print(df_2024_result.head())\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "# master_df에서 업종 코드 ↔ 업종명 맵핑 추출\n",
    "업종코드_매핑 = master_df[[\"서비스_업종_코드\", \"서비스_업종_코드_명\"]].drop_duplicates()\n",
    "\n",
    "# df_2024_result에 업종명 붙이기\n",
    "df_2024_result = pd.merge(\n",
    "    df_2024_result,\n",
    "    업종코드_매핑,\n",
    "    how=\"left\",\n",
    "    left_on=\"업종\",\n",
    "    right_on=\"서비스_업종_코드\",\n",
    ").drop(columns=[\"서비스_업종_코드\"])\n",
    "\n",
    "# 컬럼명 정리\n",
    "df_2024_result = df_2024_result.rename(columns={\"서비스_업종_코드_명\": \"업종명\"})\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "# 1. 2019~2023 실제 매출 요약\n",
    "train_meta_cols = [\n",
    "    \"기준_년분기_코드\",\n",
    "    \"행정동코드\",\n",
    "    \"행정동_코드_명_x\",\n",
    "    \"서비스_업종_코드\",\n",
    "    \"당월_매출_금액\",\n",
    "]\n",
    "train_meta = master_df[master_df[\"기준_년분기_코드\"] < 20241].copy()\n",
    "train_meta = train_meta[train_meta_cols].copy()\n",
    "train_meta[\"연도\"] = train_meta[\"기준_년분기_코드\"] // 10\n",
    "\n",
    "summary_2019_2023 = (\n",
    "    train_meta.groupby([\"연도\", \"행정동코드\", \"행정동_코드_명_x\", \"서비스_업종_코드\"])\n",
    "    .agg(총매출=(\"당월_매출_금액\", \"sum\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary_2019_2023 = summary_2019_2023.rename(\n",
    "    columns={\"행정동_코드_명_x\": \"행정동명\", \"서비스_업종_코드\": \"업종\"}\n",
    ")\n",
    "\n",
    "# 2. 업종명 붙이기\n",
    "summary_2019_2023 = pd.merge(\n",
    "    summary_2019_2023,\n",
    "    업종코드_매핑,\n",
    "    how=\"left\",\n",
    "    left_on=\"업종\",\n",
    "    right_on=\"서비스_업종_코드\",\n",
    ").drop(columns=[\"서비스_업종_코드\"])\n",
    "\n",
    "summary_2019_2023 = summary_2019_2023.rename(columns={\"서비스_업종_코드_명\": \"업종명\"})\n",
    "\n",
    "# 3. 행정동 내 업종별 순위 계산\n",
    "summary_2019_2023[\"순위\"] = summary_2019_2023.groupby([\"연도\", \"행정동코드\"])[\n",
    "    \"총매출\"\n",
    "].rank(ascending=False, method=\"min\")\n",
    "\n",
    "# 4. 2024 예측 결과 포맷 맞추기\n",
    "df_2024_actual = df_2024_result.rename(columns={\"예측_총매출\": \"총매출\"})\n",
    "\n",
    "# 5. 2019~2024 통합\n",
    "df_2019_2024 = pd.concat([summary_2019_2023, df_2024_actual], ignore_index=True)\n",
    "\n",
    "# 6. 확인 + 연도 정수 처리\n",
    "df_2019_2024[\"연도\"] = df_2019_2024[\"연도\"].astype(int)\n",
    "df_2019_2024.head()\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "# 연도 순으로 정렬 후 저장 (시계열 모델 결과)\n",
    "df_2019_2024_sorted = df_2019_2024.sort_values(by=[\"연도\", \"행정동코드\", \"순위\"])\n",
    "\n",
    "# 현재 스크립트 디렉토리에 저장\n",
    "script_dir = os.getcwd()\n",
    "analysis_file_path = os.path.join(script_dir, \"timeseries_analysis_2019_2024.csv\")\n",
    "df_2019_2024_sorted.to_csv(analysis_file_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"📊 2019-2024 분석 결과 저장 완료: {analysis_file_path}\")\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "# 1. 2023~2024년 데이터 기반\n",
    "df_recent = master_df[master_df[\"기준_년분기_코드\"] >= 20231].copy()\n",
    "\n",
    "# 2. 저장된 LabelEncoder 로드 (리키지 방지) - 절대경로 사용\n",
    "script_dir = os.getcwd()\n",
    "results_dir = os.path.join(script_dir, \"results\")\n",
    "le = joblib.load(os.path.join(results_dir, \"label_encoder.joblib\"))\n",
    "df_recent[\"업종코드_encoded\"] = le.transform(df_recent[\"서비스_업종_코드\"].astype(str))\n",
    "\n",
    "# 3. 기본 메타 정보: 행정동 + 업종 조합\n",
    "meta_cols = [\"행정동코드\", \"행정동_코드_명_x\", \"서비스_업종_코드\"]\n",
    "df_meta = df_recent[meta_cols].drop_duplicates()\n",
    "\n",
    "# 4. 입력 특성 평균값 계산\n",
    "feature_cols = X_train.columns.tolist()\n",
    "X_recent = df_recent[feature_cols + meta_cols].copy()\n",
    "X_avg = (\n",
    "    X_recent.groupby([\"행정동코드\", \"서비스_업종_코드\"])[feature_cols]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 5. 메타정보와 평균값 병합 → X_2025 구성\n",
    "df_2025_input = pd.merge(\n",
    "    df_meta, X_avg, on=[\"행정동코드\", \"서비스_업종_코드\"], how=\"inner\"\n",
    ")\n",
    "df_2025_input[\"연도\"] = 2025\n",
    "\n",
    "# 6. 예측\n",
    "X_2025 = df_2025_input[feature_cols]\n",
    "X_2025 = X_2025.fillna(X_train.mean())\n",
    "y_2025_log = model.predict(X_2025)\n",
    "y_2025 = np.expm1(y_2025_log).clip(min=0)\n",
    "\n",
    "# 7. 결과 구성\n",
    "df_2025_result = df_2025_input[\n",
    "    [\"연도\", \"행정동코드\", \"행정동_코드_명_x\", \"서비스_업종_코드\"]\n",
    "].copy()\n",
    "df_2025_result[\"예측_총매출\"] = y_2025\n",
    "\n",
    "# 8. 업종명 붙이기 (서비스_업종_코드 유지하면서 merge)\n",
    "df_2025_result = pd.merge(\n",
    "    df_2025_result,\n",
    "    업종코드_매핑,\n",
    "    how=\"left\",\n",
    "    left_on=\"서비스_업종_코드\",\n",
    "    right_on=\"서비스_업종_코드\",\n",
    ")\n",
    "\n",
    "# 9. 컬럼 정리 및 순위 계산\n",
    "df_2025_result = df_2025_result.rename(\n",
    "    columns={\n",
    "        \"행정동_코드_명_x\": \"행정동명\",\n",
    "        \"서비스_업종_코드\": \"업종\",\n",
    "        \"서비스_업종_코드_명\": \"업종명\",\n",
    "    }\n",
    ")\n",
    "\n",
    "df_2025_result[\"순위\"] = df_2025_result.groupby(\"행정동코드\")[\"예측_총매출\"].rank(\n",
    "    ascending=False, method=\"min\"\n",
    ")\n",
    "\n",
    "df_2025_result = df_2025_result[\n",
    "    [\"연도\", \"행정동코드\", \"행정동명\", \"업종\", \"업종명\", \"예측_총매출\", \"순위\"]\n",
    "]\n",
    "\n",
    "# 10. 저장 (시계열 모델 2025년 예측 결과)\n",
    "df_2025_sorted = df_2025_result.sort_values(by=[\"행정동코드\", \"순위\"])\n",
    "\n",
    "# 현재 스크립트 디렉토리에 저장\n",
    "script_dir = os.getcwd()\n",
    "prediction_file_path = os.path.join(script_dir, \"timeseries_prediction_2025.csv\")\n",
    "df_2025_sorted.to_csv(prediction_file_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"🔮 2025년 예측 결과 저장 완료: {prediction_file_path}\")\n",
    "\n",
    "# 확인\n",
    "print(\"\\n📋 시계열 모델 2025년 예측 결과 샘플:\")\n",
    "print(df_2025_result.head())\n",
    "\n",
    "# 추가 분석 정보 출력\n",
    "print(f\"\\n📊 시계열 모델 분석 요약:\")\n",
    "print(f\"  - 2019-2024 분석 데이터: {len(df_2019_2024)}행\")\n",
    "print(f\"  - 2025년 예측 데이터: {len(df_2025_result)}행\")\n",
    "print(f\"  - 분석 대상 행정동 수: {df_2019_2024['행정동코드'].nunique()}개\")\n",
    "print(f\"  - 분석 대상 업종 수: {df_2019_2024['업종'].nunique()}개\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
