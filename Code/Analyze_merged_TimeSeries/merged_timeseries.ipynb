{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e1c493e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° í´ë” ê²½ë¡œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\Data\\LocalPeople\n",
      "\n",
      "2019ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_201901.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_201902.csv ë¡œë“œ ì™„ë£Œ, 284928í–‰\n",
      "LOCAL_PEOPLE_DONG_201903.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "2019ë…„ 1ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2019ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_201904.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "LOCAL_PEOPLE_DONG_201905.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_201906.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "2019ë…„ 2ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2019ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_201907.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_201908.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_201909.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "2019ë…„ 3ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2019ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_201910.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_201911.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "LOCAL_PEOPLE_DONG_201912.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "2019ë…„ 4ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2020ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202001.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202002.csv ë¡œë“œ ì™„ë£Œ, 295104í–‰\n",
      "LOCAL_PEOPLE_DONG_202003.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "2020ë…„ 1ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2020ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202004.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "LOCAL_PEOPLE_DONG_202005.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202006.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "2020ë…„ 2ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2020ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202007.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202008.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202009.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "2020ë…„ 3ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2020ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202010.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202011.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "LOCAL_PEOPLE_DONG_202012.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "2020ë…„ 4ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2021ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202101.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202102.csv ë¡œë“œ ì™„ë£Œ, 284928í–‰\n",
      "LOCAL_PEOPLE_DONG_202103.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "2021ë…„ 1ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2021ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202104.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "LOCAL_PEOPLE_DONG_202105.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202106.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "2021ë…„ 2ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2021ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202107.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202108.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202109.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "2021ë…„ 3ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2021ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202110.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202111.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "LOCAL_PEOPLE_DONG_202112.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "2021ë…„ 4ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2022ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202201.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202202.csv ë¡œë“œ ì™„ë£Œ, 284928í–‰\n",
      "LOCAL_PEOPLE_DONG_202203.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "2022ë…„ 1ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2022ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202204.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "LOCAL_PEOPLE_DONG_202205.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202206.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "2022ë…„ 2ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2022ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202207.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202208.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202209.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "2022ë…„ 3ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2022ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202210.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202211.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "LOCAL_PEOPLE_DONG_202212.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "2022ë…„ 4ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2023ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202301.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202302.csv ë¡œë“œ ì™„ë£Œ, 284928í–‰\n",
      "LOCAL_PEOPLE_DONG_202303.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "2023ë…„ 1ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2023ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202304.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "LOCAL_PEOPLE_DONG_202305.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202306.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "2023ë…„ 2ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2023ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202307.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202308.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202309.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "2023ë…„ 3ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2023ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202310.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202311.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "LOCAL_PEOPLE_DONG_202312.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "2023ë…„ 4ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2024ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202401.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202402.csv ë¡œë“œ ì™„ë£Œ, 295104í–‰\n",
      "LOCAL_PEOPLE_DONG_202403.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "2024ë…„ 1ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2024ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202404.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "LOCAL_PEOPLE_DONG_202405.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202406.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "2024ë…„ 2ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2024ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202407.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202408.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202409.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "2024ë…„ 3ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "2024ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\n",
      "LOCAL_PEOPLE_DONG_202410.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "LOCAL_PEOPLE_DONG_202411.csv ë¡œë“œ ì™„ë£Œ, 305280í–‰\n",
      "LOCAL_PEOPLE_DONG_202412.csv ë¡œë“œ ì™„ë£Œ, 315456í–‰\n",
      "2024ë…„ 4ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, 424ê°œ í–‰ì •ë™\n",
      "\n",
      "ì „ì²´ ì™„ë£Œ: ì´ 10176í–‰, 24ê°œ ë¶„ê¸°\n",
      "20191 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 16273í–‰\n",
      "20192 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 16418í–‰\n",
      "20193 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 16456í–‰\n",
      "20194 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 16519í–‰\n",
      "20201 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 16502í–‰\n",
      "20202 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 16648í–‰\n",
      "20203 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 16676í–‰\n",
      "20204 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 16675í–‰\n",
      "20211 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17536í–‰\n",
      "20212 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17541í–‰\n",
      "20213 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17514í–‰\n",
      "20214 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17480í–‰\n",
      "20221 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17394í–‰\n",
      "20222 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17401í–‰\n",
      "20223 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17346í–‰\n",
      "20224 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17299í–‰\n",
      "20231 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17188í–‰\n",
      "20232 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17196í–‰\n",
      "20233 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17137í–‰\n",
      "20234 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17122í–‰\n",
      "20241 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17044í–‰\n",
      "20242 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 17048í–‰\n",
      "20243 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 16937í–‰\n",
      "20244 ë³‘í•© ì¤‘...\n",
      "â†’ ë³‘í•© ì™„ë£Œ: 16871í–‰\n",
      "Lag í”¼ì²˜ ì¶”ê°€ ì™„ë£Œ â†’ ì»¬ëŸ¼ ìˆ˜ 114\n",
      "\n",
      "ìµœì¢… ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ í¬ê¸°: (408221, 114)\n",
      "ì „ì²´ ì»¬ëŸ¼ ìˆ˜: 113\n",
      "ìˆ«ìí˜• ì»¬ëŸ¼ ìˆ˜: 108\n",
      "ìˆ«ìí˜• ì»¬ëŸ¼ ì´ë¦„:\n",
      " ['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'í–‰ì •ë™_ì½”ë“œ_x', 'ë‹¹ì›”_ë§¤ì¶œ_ê±´ìˆ˜', 'ì£¼ì¤‘_ë§¤ì¶œ_ê¸ˆì•¡', 'ì£¼ë§_ë§¤ì¶œ_ê¸ˆì•¡', 'ì›”ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡', 'í™”ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡', 'ìˆ˜ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡', 'ëª©ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡', 'ê¸ˆìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡', 'í† ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡', 'ì¼ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡', 'ì‹œê°„ëŒ€_00~06_ë§¤ì¶œ_ê¸ˆì•¡', 'ì‹œê°„ëŒ€_06~11_ë§¤ì¶œ_ê¸ˆì•¡', 'ì‹œê°„ëŒ€_11~14_ë§¤ì¶œ_ê¸ˆì•¡', 'ì‹œê°„ëŒ€_14~17_ë§¤ì¶œ_ê¸ˆì•¡', 'ì‹œê°„ëŒ€_17~21_ë§¤ì¶œ_ê¸ˆì•¡', 'ì‹œê°„ëŒ€_21~24_ë§¤ì¶œ_ê¸ˆì•¡', 'ë‚¨ì„±_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—¬ì„±_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_10_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_20_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_30_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_40_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_50_ë§¤ì¶œ_ê¸ˆì•¡', 'ì—°ë ¹ëŒ€_60_ì´ìƒ_ë§¤ì¶œ_ê¸ˆì•¡', 'ì£¼ì¤‘_ë§¤ì¶œ_ê±´ìˆ˜', 'ì£¼ë§_ë§¤ì¶œ_ê±´ìˆ˜', 'ì›”ìš”ì¼_ë§¤ì¶œ_ê±´ìˆ˜', 'í™”ìš”ì¼_ë§¤ì¶œ_ê±´ìˆ˜', 'ìˆ˜ìš”ì¼_ë§¤ì¶œ_ê±´ìˆ˜', 'ëª©ìš”ì¼_ë§¤ì¶œ_ê±´ìˆ˜', 'ê¸ˆìš”ì¼_ë§¤ì¶œ_ê±´ìˆ˜', 'í† ìš”ì¼_ë§¤ì¶œ_ê±´ìˆ˜', 'ì¼ìš”ì¼_ë§¤ì¶œ_ê±´ìˆ˜', 'ì‹œê°„ëŒ€_ê±´ìˆ˜~06_ë§¤ì¶œ_ê±´ìˆ˜', 'ì‹œê°„ëŒ€_ê±´ìˆ˜~11_ë§¤ì¶œ_ê±´ìˆ˜', 'ì‹œê°„ëŒ€_ê±´ìˆ˜~14_ë§¤ì¶œ_ê±´ìˆ˜', 'ì‹œê°„ëŒ€_ê±´ìˆ˜~17_ë§¤ì¶œ_ê±´ìˆ˜', 'ì‹œê°„ëŒ€_ê±´ìˆ˜~21_ë§¤ì¶œ_ê±´ìˆ˜', 'ì‹œê°„ëŒ€_ê±´ìˆ˜~24_ë§¤ì¶œ_ê±´ìˆ˜', 'ë‚¨ì„±_ë§¤ì¶œ_ê±´ìˆ˜', 'ì—¬ì„±_ë§¤ì¶œ_ê±´ìˆ˜', 'ì—°ë ¹ëŒ€_10_ë§¤ì¶œ_ê±´ìˆ˜', 'ì—°ë ¹ëŒ€_20_ë§¤ì¶œ_ê±´ìˆ˜', 'ì—°ë ¹ëŒ€_30_ë§¤ì¶œ_ê±´ìˆ˜', 'ì—°ë ¹ëŒ€_40_ë§¤ì¶œ_ê±´ìˆ˜', 'ì—°ë ¹ëŒ€_50_ë§¤ì¶œ_ê±´ìˆ˜', 'ì—°ë ¹ëŒ€_60_ì´ìƒ_ë§¤ì¶œ_ê±´ìˆ˜', 'ì´ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ë‚¨ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜', 'ì—¬ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜', 'ì—°ë„', 'ë¶„ê¸°', 'í–‰ì •ë™_ì½”ë“œ_y', 'ì´_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ë‚¨ì„±_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—¬ì„±_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—°ë ¹ëŒ€_10_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—°ë ¹ëŒ€_20_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—°ë ¹ëŒ€_30_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—°ë ¹ëŒ€_40_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—°ë ¹ëŒ€_50_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—°ë ¹ëŒ€_60_ì´ìƒ_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ë‚¨ì„±ì—°ë ¹ëŒ€_10_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ë‚¨ì„±ì—°ë ¹ëŒ€_20_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ë‚¨ì„±ì—°ë ¹ëŒ€_30_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ë‚¨ì„±ì—°ë ¹ëŒ€_40_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ë‚¨ì„±ì—°ë ¹ëŒ€_50_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ë‚¨ì„±ì—°ë ¹ëŒ€_60_ì´ìƒ_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—¬ì„±ì—°ë ¹ëŒ€_10_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—¬ì„±ì—°ë ¹ëŒ€_20_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—¬ì„±ì—°ë ¹ëŒ€_30_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—¬ì„±ì—°ë ¹ëŒ€_40_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—¬ì„±ì—°ë ¹ëŒ€_50_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—¬ì„±ì—°ë ¹ëŒ€_60_ì´ìƒ_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡_lag1', 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡_lag4', 'ì´ìƒí™œì¸êµ¬ìˆ˜_lag1', 'ì´ìƒí™œì¸êµ¬ìˆ˜_lag4', 'ì´_ì§ì¥_ì¸êµ¬_ìˆ˜_lag1', 'ì´_ì§ì¥_ì¸êµ¬_ìˆ˜_lag4']\n",
      "ìˆ«ìí˜• ì»¬ëŸ¼ ìˆ˜: 108\n",
      "ë¹„ìˆ«ìí˜• ì»¬ëŸ¼ ìˆ˜: 5\n",
      "ë¹„ìˆ«ìí˜• ì»¬ëŸ¼ ëª©ë¡:\n",
      " ['í–‰ì •ë™_ì½”ë“œ_ëª…_x', 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ', 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…', 'í–‰ì •ë™ì½”ë“œ', 'í–‰ì •ë™_ì½”ë“œ_ëª…_y']\n",
      "í•™ìŠµìš©: 340321í–‰ / ê²€ì¦ìš©: 67900í–‰ / íŠ¹ì„± ìˆ˜: 62\n",
      "ëª¨ë¸ í•™ìŠµ ì¤‘...\n",
      "í•™ìŠµ ì™„ë£Œ\n",
      "\n",
      "ëª¨ë¸ í‰ê°€ ê²°ê³¼\n",
      "MSE:  5,109,985,332,113,476,608\n",
      "RMSE: 2,260,527,667 ì›\n",
      "MAE:  233,748,479 ì›\n",
      "OOB Score: 0.8872\n",
      "\n",
      "============================================================\n",
      "ğŸ’¾ ì‹œê³„ì—´ ëª¨ë¸ ê²°ê³¼ ì €ì¥ ì¤‘...\n",
      "============================================================\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\results\\timeseries_model_20250619_112904.joblib\n",
      "ğŸ“Š í‰ê°€ì§€í‘œ CSV ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\results\\timeseries_metrics_20250619_112904.csv\n",
      "ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ CSV ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\results\\timeseries_importance_20250619_112904.csv\n",
      "ğŸ“‹ ëª¨ë¸ ìš”ì•½ CSV ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\results\\timeseries_summary_20250619_112904.csv\n",
      "\n",
      "--- ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ---\n",
      " 1. â° ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡_lag1: 0.9115\n",
      " 2. ğŸ“Š ì—…ì¢…ì½”ë“œ_encoded: 0.0229\n",
      " 3. ğŸ“Š ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ: 0.0116\n",
      " 4. â° ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡_lag4: 0.0107\n",
      " 5. ğŸ“Š ì—¬ì„±ì—°ë ¹ëŒ€_20_ì§ì¥_ì¸êµ¬_ìˆ˜: 0.0023\n",
      " 6. ğŸ“Š ì—¬ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0014\n",
      " 7. ğŸ“Š ì—¬ì„±ì—°ë ¹ëŒ€_60_ì´ìƒ_ì§ì¥_ì¸êµ¬_ìˆ˜: 0.0014\n",
      " 8. ğŸ“Š ë‚¨ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0012\n",
      " 9. ğŸ“Š ì—°ë ¹ëŒ€_60_ì´ìƒ_ì§ì¥_ì¸êµ¬_ìˆ˜: 0.0011\n",
      "10. ğŸ“Š ì—¬ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0011\n",
      "11. ğŸ“Š ë¶„ê¸°: 0.0011\n",
      "12. ğŸ“Š ì—¬ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0011\n",
      "13. ğŸ“Š ì—¬ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0011\n",
      "14. ğŸ“Š ë‚¨ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0011\n",
      "15. ğŸ“Š ë‚¨ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0011\n",
      "16. ğŸ“Š ë‚¨ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0010\n",
      "17. ğŸ“Š ì—¬ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜: 0.0010\n",
      "18. ğŸ“Š ë‚¨ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0010\n",
      "19. ğŸ“Š ì—¬ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0010\n",
      "20. ğŸ“Š ë‚¨ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜: 0.0010\n",
      "\n",
      "ğŸ“Š Lag íŠ¹ì„± ì´ ê¸°ì—¬ë„: 0.9238 (92.4%)\n",
      "âœ… Lag íŠ¹ì„±ì´ ìœ ì˜ë¯¸í•˜ê²Œ ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ 'c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\results' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "     ì—°ë„     í–‰ì •ë™ì½”ë“œ   í–‰ì •ë™ëª…        ì—…ì¢…        ì˜ˆì¸¡_ì´ë§¤ì¶œ    ìˆœìœ„\n",
      "0  2024  11110515  ì²­ìš´íš¨ìë™  CS100001  6.923591e+09   8.0\n",
      "1  2024  11110515  ì²­ìš´íš¨ìë™  CS100003  5.679055e+09  10.0\n",
      "2  2024  11110515  ì²­ìš´íš¨ìë™  CS100004  1.518500e+09  19.0\n",
      "3  2024  11110515  ì²­ìš´íš¨ìë™  CS100005  5.582597e+08  32.0\n",
      "4  2024  11110515  ì²­ìš´íš¨ìë™  CS100007  3.083015e+09  14.0\n",
      "ğŸ“Š 2019-2024 ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\timeseries_analysis_2019_2024.csv\n",
      "ğŸ”® 2025ë…„ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\test\\Analyze_merged_TimeSeries\\timeseries_prediction_2025.csv\n",
      "\n",
      "ğŸ“‹ ì‹œê³„ì—´ ëª¨ë¸ 2025ë…„ ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ:\n",
      "     ì—°ë„     í–‰ì •ë™ì½”ë“œ   í–‰ì •ë™ëª…        ì—…ì¢…    ì—…ì¢…ëª…        ì˜ˆì¸¡_ì´ë§¤ì¶œ    ìˆœìœ„\n",
      "0  2025  11110515  ì²­ìš´íš¨ìë™  CS100001  í•œì‹ìŒì‹ì   3.597585e+09   3.0\n",
      "1  2025  11110515  ì²­ìš´íš¨ìë™  CS100002  ì¤‘ì‹ìŒì‹ì   3.036879e+08  17.0\n",
      "2  2025  11110515  ì²­ìš´íš¨ìë™  CS100003  ì¼ì‹ìŒì‹ì   3.713122e+08  13.0\n",
      "3  2025  11110515  ì²­ìš´íš¨ìë™  CS100004  ì–‘ì‹ìŒì‹ì   2.752536e+09   4.0\n",
      "4  2025  11110515  ì²­ìš´íš¨ìë™  CS100005    ì œê³¼ì   4.970719e+08  11.0\n",
      "\n",
      "ğŸ“Š ì‹œê³„ì—´ ëª¨ë¸ ë¶„ì„ ìš”ì•½:\n",
      "  - 2019-2024 ë¶„ì„ ë°ì´í„°: 105390í–‰\n",
      "  - 2025ë…„ ì˜ˆì¸¡ ë°ì´í„°: 18059í–‰\n",
      "  - ë¶„ì„ ëŒ€ìƒ í–‰ì •ë™ ìˆ˜: 424ê°œ\n",
      "  - ë¶„ì„ ëŒ€ìƒ ì—…ì¢… ìˆ˜: 63ê°œ\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = os.path.abspath(\"../../Data/LocalPeople\")\n",
    "print(\"ë°ì´í„° í´ë” ê²½ë¡œ:\", data_dir)\n",
    "\n",
    "\n",
    "def load_localpeople_quarter(year, quarter, data_dir):\n",
    "    months = {\n",
    "        1: [\"01\", \"02\", \"03\"],\n",
    "        2: [\"04\", \"05\", \"06\"],\n",
    "        3: [\"07\", \"08\", \"09\"],\n",
    "        4: [\"10\", \"11\", \"12\"],\n",
    "    }[quarter]\n",
    "\n",
    "    dfs = []\n",
    "    for m in months:\n",
    "        filename = f\"LOCAL_PEOPLE_DONG_{year}{m}.csv\"\n",
    "        file = os.path.join(data_dir, filename)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            print(f\"íŒŒì¼ ì—†ìŒ: {filename}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # ğŸ”¥ ì˜¬ë°”ë¥¸ CSV ì½ê¸° ë°©ì‹ (Analyze_LocalPeople.py ì°¸ì¡°)\n",
    "            expected_cols = [\n",
    "                \"ê¸°ì¤€ì¼ID\",\n",
    "                \"ì‹œê°„ëŒ€êµ¬ë¶„\",\n",
    "                \"í–‰ì •ë™ì½”ë“œ\",\n",
    "                \"ì´ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ë‚¨ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì0ì„¸ë¶€í„°9ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì10ì„¸ë¶€í„°14ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì15ì„¸ë¶€í„°19ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì20ì„¸ë¶€í„°24ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì25ì„¸ë¶€í„°29ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì30ì„¸ë¶€í„°34ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì35ì„¸ë¶€í„°39ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì40ì„¸ë¶€í„°44ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì45ì„¸ë¶€í„°49ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì50ì„¸ë¶€í„°54ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì55ì„¸ë¶€í„°59ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì60ì„¸ë¶€í„°64ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì65ì„¸ë¶€í„°69ì„¸ìƒí™œì¸êµ¬ìˆ˜\",\n",
    "                \"ì—¬ì70ì„¸ì´ìƒìƒí™œì¸êµ¬ìˆ˜\",\n",
    "            ]\n",
    "\n",
    "            try:\n",
    "                df = pd.read_csv(\n",
    "                    file,\n",
    "                    encoding=\"utf-8\",\n",
    "                    dtype={\"ê¸°ì¤€ì¼ID\": str, \"ì‹œê°„ëŒ€êµ¬ë¶„\": str, \"í–‰ì •ë™ì½”ë“œ\": str},\n",
    "                    usecols=expected_cols,\n",
    "                    header=0,\n",
    "                )\n",
    "            except:\n",
    "                df = pd.read_csv(\n",
    "                    file,\n",
    "                    encoding=\"cp949\",\n",
    "                    dtype={\"ê¸°ì¤€ì¼ID\": str, \"ì‹œê°„ëŒ€êµ¬ë¶„\": str, \"í–‰ì •ë™ì½”ë“œ\": str},\n",
    "                    usecols=expected_cols,\n",
    "                    header=0,\n",
    "                )\n",
    "\n",
    "            df[\"í–‰ì •ë™ì½”ë“œ\"] = df[\"í–‰ì •ë™ì½”ë“œ\"].astype(str).str.zfill(8)\n",
    "            selected_cols = [\"í–‰ì •ë™ì½”ë“œ\", \"ì´ìƒí™œì¸êµ¬ìˆ˜\"] + [\n",
    "                col\n",
    "                for col in df.columns\n",
    "                if \"ìƒí™œì¸êµ¬ìˆ˜\" in col and (\"ë‚¨ì\" in col or \"ì—¬ì\" in col)\n",
    "            ]\n",
    "            df = df[selected_cols]\n",
    "            dfs.append(df)\n",
    "            print(f\"{filename} ë¡œë“œ ì™„ë£Œ, {len(df)}í–‰\")\n",
    "        except Exception as e:\n",
    "            print(f\"{filename} ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "    if not dfs:\n",
    "        print(f\"{year}ë…„ {quarter}ë¶„ê¸°: ìœ íš¨í•œ íŒŒì¼ ì—†ìŒ â†’ ê±´ë„ˆëœ€\")\n",
    "        return None\n",
    "\n",
    "    merged = pd.concat(dfs)\n",
    "    result = merged.groupby(\"í–‰ì •ë™ì½”ë“œ\").sum().reset_index()\n",
    "    result[\"ì—°ë„\"] = year\n",
    "    result[\"ë¶„ê¸°\"] = quarter\n",
    "    result[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] = int(f\"{year}{quarter}\")\n",
    "    print(f\"{year}ë…„ {quarter}ë¶„ê¸° ì§‘ê³„ ì™„ë£Œ, {len(result)}ê°œ í–‰ì •ë™\")\n",
    "    return result\n",
    "\n",
    "\n",
    "all_local = []\n",
    "for year in range(2019, 2025):\n",
    "    for quarter in [1, 2, 3, 4]:\n",
    "        print(f\"\\n{year}ë…„ {quarter}ë¶„ê¸° ì²˜ë¦¬ ì‹œì‘\")\n",
    "        res = load_localpeople_quarter(year, quarter, data_dir)\n",
    "        if res is not None:\n",
    "            all_local.append(res)\n",
    "\n",
    "if all_local:\n",
    "    local_df = pd.concat(all_local, ignore_index=True)\n",
    "    print(\n",
    "        f\"\\nì „ì²´ ì™„ë£Œ: ì´ {len(local_df)}í–‰, {local_df['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'].nunique()}ê°œ ë¶„ê¸°\"\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nì˜¤ë¥˜: ë¡œë“œëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ ë˜ëŠ” íŒŒì¼ ëˆ„ë½ ì—¬ë¶€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "\n",
    "company_path = os.path.abspath(\"../../Data/CompanyPeople/CompanyPeople.csv\")\n",
    "trading_dir = os.path.abspath(\"../../Data/Trading_Area\")\n",
    "\n",
    "# results í´ë”ëŠ” preprocess_master í•¨ìˆ˜ì—ì„œ ì ˆëŒ€ê²½ë¡œë¡œ ìƒì„±ë©ë‹ˆë‹¤\n",
    "\n",
    "# ì§ì¥ì¸ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "company_df = pd.read_csv(company_path, encoding=\"euc-kr\")\n",
    "company_df[\"í–‰ì •ë™ì½”ë“œ\"] = company_df[\"í–‰ì •ë™_ì½”ë“œ\"].astype(str).str.zfill(8)\n",
    "company_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] = company_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"].astype(int)\n",
    "\n",
    "\n",
    "# ë³‘í•© í•¨ìˆ˜ ì •ì˜\n",
    "def load_trading_area(year, trading_dir):\n",
    "    file_path = os.path.join(trading_dir, f\"Trading_Area_{year}.csv\")\n",
    "    df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "    df[\"í–‰ì •ë™ì½”ë“œ\"] = df[\"í–‰ì •ë™_ì½”ë“œ\"].astype(str).str.zfill(8)\n",
    "    df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] = df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"].astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "# ë§ˆìŠ¤í„° ë°ì´í„° ìƒì„±\n",
    "all_merged = []\n",
    "\n",
    "for year in range(2019, 2025):\n",
    "    trading_df = load_trading_area(year, trading_dir)\n",
    "\n",
    "    for quarter in [1, 2, 3, 4]:\n",
    "        quarter_code = int(f\"{year}{quarter}\")\n",
    "        print(f\"{quarter_code} ë³‘í•© ì¤‘...\")\n",
    "\n",
    "        # ë¶„ê¸°ë³„ ë°ì´í„° í•„í„°ë§\n",
    "        trade_q = trading_df[trading_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] == quarter_code].copy()\n",
    "        local_q = local_df[local_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] == quarter_code].copy()\n",
    "        comp_q = company_df[company_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] == quarter_code].copy()\n",
    "\n",
    "        if trade_q.empty:\n",
    "            print(f\"ë§¤ì¶œ ë°ì´í„° ì—†ìŒ: {quarter_code}\")\n",
    "            continue\n",
    "\n",
    "        # ë³‘í•©: ë§¤ì¶œ + ì‹¤ê±°ì£¼ (í–‰ì •ë™ì½”ë“œ + ë¶„ê¸° ê¸°ì¤€)\n",
    "        merged = pd.merge(\n",
    "            trade_q,\n",
    "            local_q,\n",
    "            on=[\"í–‰ì •ë™ì½”ë“œ\", \"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        # ë³‘í•©: + ì§ì¥ì¸ (ë™ì¼í•˜ê²Œ í–‰ì •ë™ì½”ë“œ + ë¶„ê¸° ê¸°ì¤€)\n",
    "        merged = pd.merge(\n",
    "            merged,\n",
    "            comp_q,\n",
    "            on=[\"í–‰ì •ë™ì½”ë“œ\", \"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"],\n",
    "            how=\"left\",\n",
    "        )\n",
    "\n",
    "        print(f\"â†’ ë³‘í•© ì™„ë£Œ: {len(merged)}í–‰\")\n",
    "        all_merged.append(merged)\n",
    "\n",
    "# ë§ˆìŠ¤í„° ë°ì´í„°í”„ë ˆì„ ì™„ì„±\n",
    "master_df = pd.concat(all_merged, ignore_index=True)\n",
    "\n",
    "# ---------- â¶ Lag Feature Engineering -------------------\n",
    "#   Â· key  : í–‰ì •ë™ì½”ë“œ + ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\n",
    "#   Â· lag  : 1ë¶„ê¸°, 4ë¶„ê¸°(ì „ë…„ ë™ê¸°)\n",
    "#   Â· ëŒ€ìƒ : ë§¤ì¶œÂ·ì‹¤ê±°ì£¼Â·ì§ì¥ì¸ í•µì‹¬ ì§€í‘œ\n",
    "key_cols = [\"í–‰ì •ë™ì½”ë“œ\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"]\n",
    "lag_steps = [1, 4]  # t-1, t-4\n",
    "base_cols = [\"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\", \"ì´ìƒí™œì¸êµ¬ìˆ˜\", \"ì´_ì§ì¥_ì¸êµ¬_ìˆ˜\"]\n",
    "\n",
    "master_df = master_df.sort_values(key_cols + [\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"])\n",
    "\n",
    "for col in base_cols:\n",
    "    for lag in lag_steps:\n",
    "        master_df[f\"{col}_lag{lag}\"] = master_df.groupby(key_cols)[col].shift(lag)\n",
    "\n",
    "print(f\"Lag í”¼ì²˜ ì¶”ê°€ ì™„ë£Œ â†’ ì»¬ëŸ¼ ìˆ˜ {master_df.shape[1]}\")\n",
    "print(f\"\\nìµœì¢… ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ í¬ê¸°: {master_df.shape}\")\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "X_all = master_df.drop(columns=[\"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\"])\n",
    "X_all_numeric = X_all.select_dtypes(include=[\"number\"])\n",
    "\n",
    "print(\"ì „ì²´ ì»¬ëŸ¼ ìˆ˜:\", X_all.shape[1])\n",
    "print(\"ìˆ«ìí˜• ì»¬ëŸ¼ ìˆ˜:\", X_all_numeric.shape[1])\n",
    "print(\"ìˆ«ìí˜• ì»¬ëŸ¼ ì´ë¦„:\\n\", list(X_all_numeric.columns))\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "non_numeric_cols = X_all.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "numeric_cols = X_all.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "print(\"ìˆ«ìí˜• ì»¬ëŸ¼ ìˆ˜:\", len(numeric_cols))\n",
    "print(\"ë¹„ìˆ«ìí˜• ì»¬ëŸ¼ ìˆ˜:\", len(non_numeric_cols))\n",
    "print(\"ë¹„ìˆ«ìí˜• ì»¬ëŸ¼ ëª©ë¡:\\n\", non_numeric_cols)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "def preprocess_master(df, test_year=2024):\n",
    "    df = df.copy(deep=False)\n",
    "\n",
    "    drop_cols = [\n",
    "        \"í–‰ì •ë™_ì½”ë“œ_ëª…\",\n",
    "        \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…\",\n",
    "        \"í–‰ì •ë™ëª…\",\n",
    "        \"í–‰ì •ë™_ì½”ë“œ_ëª…_x\",\n",
    "        \"í–‰ì •ë™_ì½”ë“œ_ëª…_y\",\n",
    "    ]\n",
    "    # ë§¤ì¶œ íŒŒìƒ ì»¬ëŸ¼ ì¤‘ 'lag' ê°€ ë¶™ì€ ê²ƒì€ ìœ ì§€\n",
    "    leakage_cols = [\n",
    "        c\n",
    "        for c in df.columns\n",
    "        if (\"ë§¤ì¶œ\" in c and c != \"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\") and (\"lag\" not in c)\n",
    "    ]\n",
    "    df.drop(\n",
    "        columns=[col for col in drop_cols + leakage_cols if col in df.columns],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    if \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\" in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[\"ì—…ì¢…ì½”ë“œ_encoded\"] = le.fit_transform(df[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"].astype(str))\n",
    "        df.drop(columns=[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"], inplace=True)\n",
    "\n",
    "        # ì ˆëŒ€ê²½ë¡œë¡œ results ë””ë ‰í† ë¦¬ ìƒì„± ë° ì €ì¥\n",
    "        script_dir = os.getcwd()\n",
    "        results_dir = os.path.join(script_dir, \"results\")\n",
    "        os.makedirs(results_dir, exist_ok=True)\n",
    "        joblib.dump(le, os.path.join(results_dir, \"label_encoder.joblib\"))\n",
    "\n",
    "    y_all = df[\"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\"].reset_index(drop=True)\n",
    "    quarter_col = df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"].reset_index(drop=True)\n",
    "\n",
    "    X_all = df.drop(columns=[\"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\"])\n",
    "    # â–¶ train_mask / quarter_col ì€ 0â€‘ë¶€í„° ë‹¤ì‹œ ë§¤ê²¨ì§„ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ\n",
    "    #   í”¼ì²˜ë„ ë™ì¼í•˜ê²Œ ë§ì¶° ì¤Œ(ì¸ë±ìŠ¤ reset) â† ì—¬ê¸° í•œ ì¤„ì´ í•µì‹¬\n",
    "    X_all_numeric = (\n",
    "        X_all.select_dtypes(include=[\"number\"]).reset_index(drop=True).copy()  # â˜… ì¶”ê°€\n",
    "    )\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Imputer: fit on train only â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    train_mask = quarter_col < test_year * 10 + 1\n",
    "    test_mask = ~train_mask\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X_train = pd.DataFrame(\n",
    "        imputer.fit_transform(X_all_numeric[train_mask]),\n",
    "        columns=X_all_numeric.columns,\n",
    "        index=X_all_numeric[train_mask].index,\n",
    "    )\n",
    "    X_test = pd.DataFrame(\n",
    "        imputer.transform(X_all_numeric[test_mask]),\n",
    "        columns=X_all_numeric.columns,\n",
    "        index=X_all_numeric[test_mask].index,\n",
    "    )\n",
    "\n",
    "    # ì ˆëŒ€ê²½ë¡œë¡œ imputer ì €ì¥\n",
    "    script_dir = os.getcwd()\n",
    "    results_dir = os.path.join(script_dir, \"results\")\n",
    "    joblib.dump(imputer, os.path.join(results_dir, \"imputer.joblib\"))\n",
    "\n",
    "    y_train = y_all[train_mask]\n",
    "    y_test = y_all[test_mask]\n",
    "\n",
    "    print(\n",
    "        f\"í•™ìŠµìš©: {len(X_train)}í–‰ / ê²€ì¦ìš©: {len(X_test)}í–‰ / íŠ¹ì„± ìˆ˜: {X_train.shape[1]}\"\n",
    "    )\n",
    "    return X_train, X_test, y_train, y_test, quarter_col[test_mask]\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, quarter_test = preprocess_master(master_df)\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "# ë¡œê·¸ ë³€í™˜í•˜ì—¬ í•™ìŠµ\n",
    "y_train_log = np.log1p(y_train.clip(lower=0))\n",
    "\n",
    "# ëª¨ë¸ ì •ì˜\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100, max_depth=15, random_state=42, n_jobs=-1, oob_score=True\n",
    ")\n",
    "\n",
    "print(\"ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "model.fit(X_train, y_train_log)\n",
    "print(\"í•™ìŠµ ì™„ë£Œ\")\n",
    "\n",
    "\n",
    "def rolling_forecast(model, df_all, feature_cols, start_code=20241):\n",
    "    \"\"\"\n",
    "    ì‹œì‘ ë¶„ê¸°(start_code)ë¶€í„° ëê¹Œì§€ ìˆœì°¨ ì˜ˆì¸¡ â†’ ì˜ˆì¸¡ê°’ì„ lag1 ì»¬ëŸ¼ì— ë°˜ì˜\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    current_code = start_code\n",
    "    max_code = df_all[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"].max()\n",
    "\n",
    "    while current_code <= max_code:\n",
    "        mask = df_all[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] == current_code\n",
    "        cur_data = df_all.loc[mask].copy()\n",
    "        X_cur = cur_data[feature_cols]\n",
    "        X_cur = X_cur.fillna(X_train.mean())\n",
    "        y_log = model.predict(X_cur)\n",
    "        y_hat = np.expm1(y_log).clip(min=0)\n",
    "\n",
    "        # ì €ì¥ìš© ê²°ê³¼\n",
    "        result_df = cur_data[[\"í–‰ì •ë™ì½”ë“œ\", \"ì—…ì¢…ì½”ë“œ_encoded\"]].copy()\n",
    "        result_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] = current_code\n",
    "        result_df[\"ì˜ˆì¸¡_ë§¤ì¶œ\"] = y_hat\n",
    "        results.append(result_df)\n",
    "\n",
    "        # ì˜ˆì¸¡ê°’ì„ lag1 ì»¬ëŸ¼ì— ì£¼ì… â†’ ë‹¤ìŒ ë¶„ê¸° ì‚¬ìš©\n",
    "        next_code = current_code + 1\n",
    "        if next_code % 10 == 5:  # 4ë¶„ê¸° ë‹¤ìŒì€ +6 â†’ Q1\n",
    "            next_code = (next_code // 10 + 1) * 10 + 1\n",
    "\n",
    "        if next_code <= max_code:\n",
    "            # ğŸš€ ë²¡í„°í™” ìµœì í™”: ë‹¤ìŒ ë¶„ê¸° ë°ì´í„°ì™€ ë§¤ì¹­í•˜ì—¬ lag1 ê°’ ì—…ë°ì´íŠ¸\n",
    "            next_mask = df_all[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] == next_code\n",
    "            if next_mask.any():\n",
    "                # í˜„ì¬ ë¶„ê¸°ì™€ ë‹¤ìŒ ë¶„ê¸° ë°ì´í„°ë¥¼ mergeë¡œ ë¹ ë¥´ê²Œ ë§¤ì¹­\n",
    "                cur_predictions = cur_data[[\"í–‰ì •ë™ì½”ë“œ\", \"ì—…ì¢…ì½”ë“œ_encoded\"]].copy()\n",
    "                cur_predictions[\"pred_ê°’\"] = y_hat\n",
    "\n",
    "                # ë‹¤ìŒ ë¶„ê¸° ë°ì´í„° ì¶”ì¶œ\n",
    "                next_data = df_all[next_mask][[\"í–‰ì •ë™ì½”ë“œ\", \"ì—…ì¢…ì½”ë“œ_encoded\"]].copy()\n",
    "                next_data[\"next_idx\"] = df_all[next_mask].index\n",
    "\n",
    "                # mergeë¡œ ë§¤ì¹­\n",
    "                merged = pd.merge(\n",
    "                    next_data,\n",
    "                    cur_predictions,\n",
    "                    on=[\"í–‰ì •ë™ì½”ë“œ\", \"ì—…ì¢…ì½”ë“œ_encoded\"],\n",
    "                    how=\"left\",\n",
    "                )\n",
    "\n",
    "                # ë§¤ì¹­ëœ ê°’ë“¤ì„ ë²¡í„°í™”ë¡œ ì—…ë°ì´íŠ¸\n",
    "                valid_mask = merged[\"pred_ê°’\"].notna()\n",
    "                if valid_mask.any():\n",
    "                    update_indices = merged.loc[valid_mask, \"next_idx\"]\n",
    "                    update_values = merged.loc[valid_mask, \"pred_ê°’\"]\n",
    "                    df_all.loc[update_indices, \"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡_lag1\"] = (\n",
    "                        update_values.values\n",
    "                    )\n",
    "\n",
    "        current_code = next_code\n",
    "    return pd.concat(results, ignore_index=True)\n",
    "\n",
    "\n",
    "# preprocess_masterì—ì„œ ì²˜ë¦¬ëœ ì „ì²´ ë°ì´í„° ì¬êµ¬ì„±\n",
    "def get_processed_df(df, test_year=2024):\n",
    "    \"\"\"preprocess_masterì™€ ë™ì¼í•œ ì²˜ë¦¬ë¥¼ í•˜ë˜, ì „ì²´ ë°ì´í„° ë°˜í™˜\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    drop_cols = [\n",
    "        \"í–‰ì •ë™_ì½”ë“œ_ëª…\",\n",
    "        \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…\",\n",
    "        \"í–‰ì •ë™ëª…\",\n",
    "        \"í–‰ì •ë™_ì½”ë“œ_ëª…_x\",\n",
    "        \"í–‰ì •ë™_ì½”ë“œ_ëª…_y\",\n",
    "    ]\n",
    "    # ë§¤ì¶œ íŒŒìƒ ì»¬ëŸ¼ ì¤‘ 'lag' ê°€ ë¶™ì€ ê²ƒì€ ìœ ì§€\n",
    "    leakage_cols = [\n",
    "        c\n",
    "        for c in df.columns\n",
    "        if (\"ë§¤ì¶œ\" in c and c != \"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\") and (\"lag\" not in c)\n",
    "    ]\n",
    "    df.drop(\n",
    "        columns=[col for col in drop_cols + leakage_cols if col in df.columns],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    if \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\" in df.columns:\n",
    "        # 1) ì¸ì½”ë” ë¡œë“œ (ì ˆëŒ€ê²½ë¡œ)\n",
    "        script_dir = os.getcwd()\n",
    "        results_dir = os.path.join(script_dir, \"results\")\n",
    "        le = joblib.load(os.path.join(results_dir, \"label_encoder.joblib\"))\n",
    "        # 2) ì¸ì½”ë”© ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±\n",
    "        if \"ì—…ì¢…ì½”ë“œ_encoded\" not in df.columns:\n",
    "            df[\"ì—…ì¢…ì½”ë“œ_encoded\"] = le.transform(df[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"].astype(str))\n",
    "        # 3) ì›ë³¸ ë¬¸ìí˜• ì»¬ëŸ¼ ì œê±°\n",
    "        df.drop(columns=[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ì „ì²˜ë¦¬ëœ ì „ì²´ ë°ì´í„° ìƒì„±\n",
    "processed_df = get_processed_df(master_df)\n",
    "\n",
    "# ë¡¤ë§ ì˜ˆì¸¡ ì‹¤í–‰ (2024Q1ë¶€í„°)\n",
    "rolling_df = rolling_forecast(\n",
    "    model,\n",
    "    processed_df,  # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©\n",
    "    feature_cols=X_train.columns,\n",
    "    start_code=20241,\n",
    ")\n",
    "\n",
    "mkeys = [\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\", \"í–‰ì •ë™ì½”ë“œ\", \"ì—…ì¢…ì½”ë“œ_encoded\"]\n",
    "\n",
    "# â‘  rolling ì˜ˆì¸¡ ê²°ê³¼ ì¤‘ í…ŒìŠ¤íŠ¸ êµ¬ê°„ë§Œ ì¶”ë ¤ì„œ key ë¡œ ì •ë ¬\n",
    "y_pred_df = (\n",
    "    rolling_df[rolling_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] >= 20241]\n",
    "    .sort_values(mkeys)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# â‘¡ ë™ì¼ key ë¡œ y_test(Series) ë„ ì •ë ¬\n",
    "y_test_df = (\n",
    "    processed_df[processed_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] >= 20241]\n",
    "    .loc[:, mkeys + [\"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\"]]\n",
    "    .sort_values(mkeys)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# â‘¢ ë§¤ì¹­ í™•ì¸\n",
    "assert (y_pred_df[mkeys] == y_test_df[mkeys]).all().all(), \"ì •ë ¬ ë¶ˆì¼ì¹˜\"\n",
    "\n",
    "y_pred = y_pred_df[\"ì˜ˆì¸¡_ë§¤ì¶œ\"].values\n",
    "y_test = y_test_df[\"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\"].values\n",
    "\n",
    "# í‰ê°€ ì§€í‘œ ê³„ì‚°\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\nëª¨ë¸ í‰ê°€ ê²°ê³¼\")\n",
    "print(f\"MSE:  {mse:,.0f}\")\n",
    "print(f\"RMSE: {rmse:,.0f} ì›\")\n",
    "print(f\"MAE:  {mae:,.0f} ì›\")\n",
    "print(f\"OOB Score: {model.oob_score_:.4f}\")\n",
    "\n",
    "\n",
    "def save_timeseries_model_and_metrics(model, metrics, X_train):\n",
    "    \"\"\"ì‹œê³„ì—´ ëª¨ë¸ê³¼ í‰ê°€ì§€í‘œ ì €ì¥\"\"\"\n",
    "\n",
    "    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ê¸°ì¤€)\n",
    "    script_dir = os.getcwd()\n",
    "    results_dir = os.path.join(script_dir, \"results\")\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "        print(f\"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±: {results_dir}\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # 1. ëª¨ë¸ ì €ì¥\n",
    "    model_filename = os.path.join(results_dir, f\"timeseries_model_{timestamp}.joblib\")\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_filename}\")\n",
    "\n",
    "    # 2. íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚°\n",
    "    feature_importance = pd.DataFrame(\n",
    "        {\"feature\": X_train.columns, \"importance\": model.feature_importances_}\n",
    "    ).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    # Lag íŠ¹ì„± ê¸°ì—¬ë„ ê³„ì‚°\n",
    "    lag_features = feature_importance[\n",
    "        feature_importance[\"feature\"].str.contains(\"_lag\", regex=True)\n",
    "    ]\n",
    "    lag_importance = lag_features[\"importance\"].sum()\n",
    "\n",
    "    # 3. í‰ê°€ì§€í‘œ CSV ì €ì¥\n",
    "    metrics_data = {\n",
    "        \"ì‹¤í–‰ì‹œê°„\": [timestamp],\n",
    "        \"MSE\": [metrics[\"mse\"]],\n",
    "        \"RMSE\": [metrics[\"rmse\"]],\n",
    "        \"MAE\": [metrics[\"mae\"]],\n",
    "        \"Lag_íŠ¹ì„±_ê¸°ì—¬ë„\": [lag_importance],\n",
    "        \"Lag_íŠ¹ì„±_ê¸°ì—¬ë„_í¼ì„¼íŠ¸\": [lag_importance * 100],\n",
    "        \"OOB_Score\": [model.oob_score_],\n",
    "        \"í…ŒìŠ¤íŠ¸_ë…„ë„\": [2024],\n",
    "        \"í›ˆë ¨_ë°ì´í„°_í¬ê¸°\": [len(X_train)],\n",
    "        \"í…ŒìŠ¤íŠ¸_ë°ì´í„°_í¬ê¸°\": [len(y_pred)],\n",
    "        \"íŠ¹ì„±_ê°œìˆ˜\": [len(X_train.columns)],\n",
    "        \"ë¡¤ë§_ì˜ˆì¸¡_ì ìš©\": [\"Yes\"],\n",
    "        \"íƒ€ê¹ƒ_ë¦¬í‚¤ì§€_ì œê±°\": [\"Yes\"],\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_filename = os.path.join(results_dir, f\"timeseries_metrics_{timestamp}.csv\")\n",
    "    metrics_df.to_csv(metrics_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ“Š í‰ê°€ì§€í‘œ CSV ì €ì¥ ì™„ë£Œ: {metrics_filename}\")\n",
    "\n",
    "    # 4. íŠ¹ì„± ì¤‘ìš”ë„ ì €ì¥\n",
    "    importance_filename = os.path.join(\n",
    "        results_dir, f\"timeseries_importance_{timestamp}.csv\"\n",
    "    )\n",
    "    feature_importance.to_csv(importance_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ CSV ì €ì¥ ì™„ë£Œ: {importance_filename}\")\n",
    "\n",
    "    # 5. ì‹¤í–‰ ì •ë³´ ìš”ì•½ ì €ì¥\n",
    "    summary_data = {\n",
    "        \"í•­ëª©\": [\n",
    "            \"ì‹¤í–‰ì‹œê°„\",\n",
    "            \"MSE\",\n",
    "            \"RMSE (ì›)\",\n",
    "            \"MAE (ì›)\",\n",
    "            \"Lag íŠ¹ì„± ê¸°ì—¬ë„ (%)\",\n",
    "            \"OOB Score\",\n",
    "            \"í…ŒìŠ¤íŠ¸ ë…„ë„\",\n",
    "            \"í›ˆë ¨ ë°ì´í„° í¬ê¸°\",\n",
    "            \"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°\",\n",
    "            \"íŠ¹ì„± ê°œìˆ˜\",\n",
    "            \"ë¡¤ë§ ì˜ˆì¸¡ ì ìš©\",\n",
    "            \"íƒ€ê¹ƒ ë¦¬í‚¤ì§€ ì œê±°\",\n",
    "            \"ì‹œê³„ì—´ íŠ¹ì„±\",\n",
    "        ],\n",
    "        \"ê°’\": [\n",
    "            timestamp,\n",
    "            f\"{metrics['mse']:,.0f}\",\n",
    "            f\"{metrics['rmse']:,.0f}\",\n",
    "            f\"{metrics['mae']:,.0f}\",\n",
    "            f\"{lag_importance*100:.1f}%\",\n",
    "            f\"{model.oob_score_:.4f}\",\n",
    "            \"2024\",\n",
    "            f\"{len(X_train):,}\",\n",
    "            f\"{len(y_pred):,}\",\n",
    "            len(X_train.columns),\n",
    "            \"Yes\",\n",
    "            \"Yes\",\n",
    "            \"Lag 1ë¶„ê¸° + 4ë¶„ê¸°\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_filename = os.path.join(results_dir, f\"timeseries_summary_{timestamp}.csv\")\n",
    "    summary_df.to_csv(summary_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ“‹ ëª¨ë¸ ìš”ì•½ CSV ì €ì¥ ì™„ë£Œ: {summary_filename}\")\n",
    "\n",
    "    # 6. ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ì¶œë ¥\n",
    "    print(f\"\\n--- ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ---\")\n",
    "    for i, (_, row) in enumerate(feature_importance.head(20).iterrows(), 1):\n",
    "        is_lag = \"_lag\" in row[\"feature\"]\n",
    "        marker = \"â°\" if is_lag else \"ğŸ“Š\"\n",
    "        print(f\"{i:2d}. {marker} {row['feature'][:50]}: {row['importance']:.4f}\")\n",
    "\n",
    "    print(f\"\\nğŸ“Š Lag íŠ¹ì„± ì´ ê¸°ì—¬ë„: {lag_importance:.4f} ({lag_importance*100:.1f}%)\")\n",
    "\n",
    "    if lag_importance < 0.05:\n",
    "        print(\"âš ï¸ Lag íŠ¹ì„± ê¸°ì—¬ë„ê°€ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤.\")\n",
    "    elif lag_importance < 0.15:\n",
    "        print(\"ğŸ”¶ Lag íŠ¹ì„± ê¸°ì—¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"âœ… Lag íŠ¹ì„±ì´ ìœ ì˜ë¯¸í•˜ê²Œ ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    print(f\"\\nğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ '{results_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    return {\n",
    "        \"model_file\": model_filename,\n",
    "        \"metrics_file\": metrics_filename,\n",
    "        \"importance_file\": importance_filename,\n",
    "        \"summary_file\": summary_filename,\n",
    "    }\n",
    "\n",
    "\n",
    "# ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤í–‰\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ’¾ ì‹œê³„ì—´ ëª¨ë¸ ê²°ê³¼ ì €ì¥ ì¤‘...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "save_result = save_timeseries_model_and_metrics(\n",
    "    model, {\"mse\": mse, \"rmse\": rmse, \"mae\": mae}, X_train\n",
    ")\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½ì„ ìœ„í•œ ë©”íƒ€ ì •ë³´ ì¶”ì¶œ\n",
    "meta_cols = [\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\", \"í–‰ì •ë™ì½”ë“œ\", \"í–‰ì •ë™_ì½”ë“œ_ëª…_x\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"]\n",
    "test_meta = master_df[master_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"].isin(quarter_test)].copy()\n",
    "test_meta = test_meta[meta_cols].reset_index(drop=True)\n",
    "\n",
    "# ì˜ˆì¸¡ ê²°ê³¼ ê²°í•©\n",
    "test_meta[\"ì˜ˆì¸¡_ë§¤ì¶œ\"] = y_pred\n",
    "test_meta[\"ì‹¤ì œ_ë§¤ì¶œ\"] = y_test_df[\"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\"].values\n",
    "test_meta[\"ì—°ë„\"] = test_meta[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] // 10\n",
    "\n",
    "# ì—°ë„+ë™+ì—…ì¢… ë‹¨ìœ„ë¡œ ì§‘ê³„\n",
    "summary_2024 = (\n",
    "    test_meta.groupby([\"ì—°ë„\", \"í–‰ì •ë™ì½”ë“œ\", \"í–‰ì •ë™_ì½”ë“œ_ëª…_x\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"])\n",
    "    .agg(ì´ë§¤ì¶œ=(\"ì‹¤ì œ_ë§¤ì¶œ\", \"sum\"), ì˜ˆì¸¡_ì´ë§¤ì¶œ=(\"ì˜ˆì¸¡_ë§¤ì¶œ\", \"sum\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# ìˆœìœ„: í–‰ì •ë™ë³„ ì—…ì¢… ìˆœìœ„\n",
    "summary_2024[\"ìˆœìœ„\"] = summary_2024.groupby([\"ì—°ë„\", \"í–‰ì •ë™ì½”ë“œ\"])[\"ì˜ˆì¸¡_ì´ë§¤ì¶œ\"].rank(\n",
    "    ascending=False, method=\"min\"\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì •ë¦¬\n",
    "df_2024_result = summary_2024.rename(\n",
    "    columns={\"í–‰ì •ë™_ì½”ë“œ_ëª…_x\": \"í–‰ì •ë™ëª…\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\": \"ì—…ì¢…\"}\n",
    ")[[\"ì—°ë„\", \"í–‰ì •ë™ì½”ë“œ\", \"í–‰ì •ë™ëª…\", \"ì—…ì¢…\", \"ì˜ˆì¸¡_ì´ë§¤ì¶œ\", \"ìˆœìœ„\"]]\n",
    "\n",
    "\n",
    "print(df_2024_result.head())\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "# master_dfì—ì„œ ì—…ì¢… ì½”ë“œ â†” ì—…ì¢…ëª… ë§µí•‘ ì¶”ì¶œ\n",
    "ì—…ì¢…ì½”ë“œ_ë§¤í•‘ = master_df[[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…\"]].drop_duplicates()\n",
    "\n",
    "# df_2024_resultì— ì—…ì¢…ëª… ë¶™ì´ê¸°\n",
    "df_2024_result = pd.merge(\n",
    "    df_2024_result,\n",
    "    ì—…ì¢…ì½”ë“œ_ë§¤í•‘,\n",
    "    how=\"left\",\n",
    "    left_on=\"ì—…ì¢…\",\n",
    "    right_on=\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\",\n",
    ").drop(columns=[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"])\n",
    "\n",
    "# ì»¬ëŸ¼ëª… ì •ë¦¬\n",
    "df_2024_result = df_2024_result.rename(columns={\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…\": \"ì—…ì¢…ëª…\"})\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "# 1. 2019~2023 ì‹¤ì œ ë§¤ì¶œ ìš”ì•½\n",
    "train_meta_cols = [\n",
    "    \"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\",\n",
    "    \"í–‰ì •ë™ì½”ë“œ\",\n",
    "    \"í–‰ì •ë™_ì½”ë“œ_ëª…_x\",\n",
    "    \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\",\n",
    "    \"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\",\n",
    "]\n",
    "train_meta = master_df[master_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] < 20241].copy()\n",
    "train_meta = train_meta[train_meta_cols].copy()\n",
    "train_meta[\"ì—°ë„\"] = train_meta[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] // 10\n",
    "\n",
    "summary_2019_2023 = (\n",
    "    train_meta.groupby([\"ì—°ë„\", \"í–‰ì •ë™ì½”ë“œ\", \"í–‰ì •ë™_ì½”ë“œ_ëª…_x\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"])\n",
    "    .agg(ì´ë§¤ì¶œ=(\"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\", \"sum\"))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "summary_2019_2023 = summary_2019_2023.rename(\n",
    "    columns={\"í–‰ì •ë™_ì½”ë“œ_ëª…_x\": \"í–‰ì •ë™ëª…\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\": \"ì—…ì¢…\"}\n",
    ")\n",
    "\n",
    "# 2. ì—…ì¢…ëª… ë¶™ì´ê¸°\n",
    "summary_2019_2023 = pd.merge(\n",
    "    summary_2019_2023,\n",
    "    ì—…ì¢…ì½”ë“œ_ë§¤í•‘,\n",
    "    how=\"left\",\n",
    "    left_on=\"ì—…ì¢…\",\n",
    "    right_on=\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\",\n",
    ").drop(columns=[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"])\n",
    "\n",
    "summary_2019_2023 = summary_2019_2023.rename(columns={\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…\": \"ì—…ì¢…ëª…\"})\n",
    "\n",
    "# 3. í–‰ì •ë™ ë‚´ ì—…ì¢…ë³„ ìˆœìœ„ ê³„ì‚°\n",
    "summary_2019_2023[\"ìˆœìœ„\"] = summary_2019_2023.groupby([\"ì—°ë„\", \"í–‰ì •ë™ì½”ë“œ\"])[\n",
    "    \"ì´ë§¤ì¶œ\"\n",
    "].rank(ascending=False, method=\"min\")\n",
    "\n",
    "# 4. 2024 ì˜ˆì¸¡ ê²°ê³¼ í¬ë§· ë§ì¶”ê¸°\n",
    "df_2024_actual = df_2024_result.rename(columns={\"ì˜ˆì¸¡_ì´ë§¤ì¶œ\": \"ì´ë§¤ì¶œ\"})\n",
    "\n",
    "# 5. 2019~2024 í†µí•©\n",
    "df_2019_2024 = pd.concat([summary_2019_2023, df_2024_actual], ignore_index=True)\n",
    "\n",
    "# 6. í™•ì¸ + ì—°ë„ ì •ìˆ˜ ì²˜ë¦¬\n",
    "df_2019_2024[\"ì—°ë„\"] = df_2019_2024[\"ì—°ë„\"].astype(int)\n",
    "df_2019_2024.head()\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "# ì—°ë„ ìˆœìœ¼ë¡œ ì •ë ¬ í›„ ì €ì¥ (ì‹œê³„ì—´ ëª¨ë¸ ê²°ê³¼)\n",
    "df_2019_2024_sorted = df_2019_2024.sort_values(by=[\"ì—°ë„\", \"í–‰ì •ë™ì½”ë“œ\", \"ìˆœìœ„\"])\n",
    "\n",
    "# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ì— ì €ì¥\n",
    "script_dir = os.getcwd()\n",
    "analysis_file_path = os.path.join(script_dir, \"timeseries_analysis_2019_2024.csv\")\n",
    "df_2019_2024_sorted.to_csv(analysis_file_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"ğŸ“Š 2019-2024 ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {analysis_file_path}\")\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "# 1. 2023~2024ë…„ ë°ì´í„° ê¸°ë°˜\n",
    "df_recent = master_df[master_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] >= 20231].copy()\n",
    "\n",
    "# 2. ì €ì¥ëœ LabelEncoder ë¡œë“œ (ë¦¬í‚¤ì§€ ë°©ì§€) - ì ˆëŒ€ê²½ë¡œ ì‚¬ìš©\n",
    "script_dir = os.getcwd()\n",
    "results_dir = os.path.join(script_dir, \"results\")\n",
    "le = joblib.load(os.path.join(results_dir, \"label_encoder.joblib\"))\n",
    "df_recent[\"ì—…ì¢…ì½”ë“œ_encoded\"] = le.transform(df_recent[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"].astype(str))\n",
    "\n",
    "# 3. ê¸°ë³¸ ë©”íƒ€ ì •ë³´: í–‰ì •ë™ + ì—…ì¢… ì¡°í•©\n",
    "meta_cols = [\"í–‰ì •ë™ì½”ë“œ\", \"í–‰ì •ë™_ì½”ë“œ_ëª…_x\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"]\n",
    "df_meta = df_recent[meta_cols].drop_duplicates()\n",
    "\n",
    "# 4. ì…ë ¥ íŠ¹ì„± í‰ê· ê°’ ê³„ì‚°\n",
    "feature_cols = X_train.columns.tolist()\n",
    "X_recent = df_recent[feature_cols + meta_cols].copy()\n",
    "X_avg = (\n",
    "    X_recent.groupby([\"í–‰ì •ë™ì½”ë“œ\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"])[feature_cols]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# 5. ë©”íƒ€ì •ë³´ì™€ í‰ê· ê°’ ë³‘í•© â†’ X_2025 êµ¬ì„±\n",
    "df_2025_input = pd.merge(\n",
    "    df_meta, X_avg, on=[\"í–‰ì •ë™ì½”ë“œ\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"], how=\"inner\"\n",
    ")\n",
    "df_2025_input[\"ì—°ë„\"] = 2025\n",
    "\n",
    "# 6. ì˜ˆì¸¡\n",
    "X_2025 = df_2025_input[feature_cols]\n",
    "X_2025 = X_2025.fillna(X_train.mean())\n",
    "y_2025_log = model.predict(X_2025)\n",
    "y_2025 = np.expm1(y_2025_log).clip(min=0)\n",
    "\n",
    "# 7. ê²°ê³¼ êµ¬ì„±\n",
    "df_2025_result = df_2025_input[\n",
    "    [\"ì—°ë„\", \"í–‰ì •ë™ì½”ë“œ\", \"í–‰ì •ë™_ì½”ë“œ_ëª…_x\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"]\n",
    "].copy()\n",
    "df_2025_result[\"ì˜ˆì¸¡_ì´ë§¤ì¶œ\"] = y_2025\n",
    "\n",
    "# 8. ì—…ì¢…ëª… ë¶™ì´ê¸° (ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ ìœ ì§€í•˜ë©´ì„œ merge)\n",
    "df_2025_result = pd.merge(\n",
    "    df_2025_result,\n",
    "    ì—…ì¢…ì½”ë“œ_ë§¤í•‘,\n",
    "    how=\"left\",\n",
    "    left_on=\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\",\n",
    "    right_on=\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\",\n",
    ")\n",
    "\n",
    "# 9. ì»¬ëŸ¼ ì •ë¦¬ ë° ìˆœìœ„ ê³„ì‚°\n",
    "df_2025_result = df_2025_result.rename(\n",
    "    columns={\n",
    "        \"í–‰ì •ë™_ì½”ë“œ_ëª…_x\": \"í–‰ì •ë™ëª…\",\n",
    "        \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\": \"ì—…ì¢…\",\n",
    "        \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…\": \"ì—…ì¢…ëª…\",\n",
    "    }\n",
    ")\n",
    "\n",
    "df_2025_result[\"ìˆœìœ„\"] = df_2025_result.groupby(\"í–‰ì •ë™ì½”ë“œ\")[\"ì˜ˆì¸¡_ì´ë§¤ì¶œ\"].rank(\n",
    "    ascending=False, method=\"min\"\n",
    ")\n",
    "\n",
    "df_2025_result = df_2025_result[\n",
    "    [\"ì—°ë„\", \"í–‰ì •ë™ì½”ë“œ\", \"í–‰ì •ë™ëª…\", \"ì—…ì¢…\", \"ì—…ì¢…ëª…\", \"ì˜ˆì¸¡_ì´ë§¤ì¶œ\", \"ìˆœìœ„\"]\n",
    "]\n",
    "\n",
    "# 10. ì €ì¥ (ì‹œê³„ì—´ ëª¨ë¸ 2025ë…„ ì˜ˆì¸¡ ê²°ê³¼)\n",
    "df_2025_sorted = df_2025_result.sort_values(by=[\"í–‰ì •ë™ì½”ë“œ\", \"ìˆœìœ„\"])\n",
    "\n",
    "# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ì— ì €ì¥\n",
    "script_dir = os.getcwd()\n",
    "prediction_file_path = os.path.join(script_dir, \"timeseries_prediction_2025.csv\")\n",
    "df_2025_sorted.to_csv(prediction_file_path, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"ğŸ”® 2025ë…„ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {prediction_file_path}\")\n",
    "\n",
    "# í™•ì¸\n",
    "print(\"\\nğŸ“‹ ì‹œê³„ì—´ ëª¨ë¸ 2025ë…„ ì˜ˆì¸¡ ê²°ê³¼ ìƒ˜í”Œ:\")\n",
    "print(df_2025_result.head())\n",
    "\n",
    "# ì¶”ê°€ ë¶„ì„ ì •ë³´ ì¶œë ¥\n",
    "print(f\"\\nğŸ“Š ì‹œê³„ì—´ ëª¨ë¸ ë¶„ì„ ìš”ì•½:\")\n",
    "print(f\"  - 2019-2024 ë¶„ì„ ë°ì´í„°: {len(df_2019_2024)}í–‰\")\n",
    "print(f\"  - 2025ë…„ ì˜ˆì¸¡ ë°ì´í„°: {len(df_2025_result)}í–‰\")\n",
    "print(f\"  - ë¶„ì„ ëŒ€ìƒ í–‰ì •ë™ ìˆ˜: {df_2019_2024['í–‰ì •ë™ì½”ë“œ'].nunique()}ê°œ\")\n",
    "print(f\"  - ë¶„ì„ ëŒ€ìƒ ì—…ì¢… ìˆ˜: {df_2019_2024['ì—…ì¢…'].nunique()}ê°œ\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
