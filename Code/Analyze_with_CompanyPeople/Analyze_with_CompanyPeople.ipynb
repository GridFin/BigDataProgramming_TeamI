{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45770ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\tkfkg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.5.1-py3-none-any.whl (307 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\tkfkg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\tkfkg\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Installing collected packages: joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.1 scikit-learn-1.6.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\tkfkg\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#pip install scikit-learn\n",
    "#pip install catboost\n",
    "#pip install OS\n",
    "#pip install numpy\n",
    "#pip install pandas\n",
    "#pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47450354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Œ 1. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae17bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ì—°ë„</th>\n",
       "      <th>í–‰ì •ë™ì½”ë“œ</th>\n",
       "      <th>í–‰ì •ë™ëª…</th>\n",
       "      <th>ì—…ì¢…</th>\n",
       "      <th>ì˜ˆì¸¡_ì´ë§¤ì¶œ</th>\n",
       "      <th>ìˆœìœ„</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025</td>\n",
       "      <td>11110515</td>\n",
       "      <td>ì²­ìš´íš¨ìë™</td>\n",
       "      <td>ì¡°ëª…ìš©í’ˆ</td>\n",
       "      <td>5.775176e+09</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025</td>\n",
       "      <td>11110515</td>\n",
       "      <td>ì²­ìš´íš¨ìë™</td>\n",
       "      <td>ì»¤í”¼-ìŒë£Œ</td>\n",
       "      <td>4.306592e+09</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025</td>\n",
       "      <td>11110515</td>\n",
       "      <td>ì²­ìš´íš¨ìë™</td>\n",
       "      <td>í•œì‹ìŒì‹ì </td>\n",
       "      <td>3.738617e+09</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025</td>\n",
       "      <td>11110515</td>\n",
       "      <td>ì²­ìš´íš¨ìë™</td>\n",
       "      <td>ì„œì </td>\n",
       "      <td>3.597058e+09</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025</td>\n",
       "      <td>11110515</td>\n",
       "      <td>ì²­ìš´íš¨ìë™</td>\n",
       "      <td>ì–‘ì‹ìŒì‹ì </td>\n",
       "      <td>2.744975e+09</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025</td>\n",
       "      <td>11110515</td>\n",
       "      <td>ì²­ìš´íš¨ìë™</td>\n",
       "      <td>ìŠˆí¼ë§ˆì¼“</td>\n",
       "      <td>2.040304e+09</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025</td>\n",
       "      <td>11110515</td>\n",
       "      <td>ì²­ìš´íš¨ìë™</td>\n",
       "      <td>í¸ì˜ì </td>\n",
       "      <td>1.719586e+09</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025</td>\n",
       "      <td>11110515</td>\n",
       "      <td>ì²­ìš´íš¨ìë™</td>\n",
       "      <td>ì˜ë£Œê¸°ê¸°</td>\n",
       "      <td>1.307927e+09</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025</td>\n",
       "      <td>11110515</td>\n",
       "      <td>ì²­ìš´íš¨ìë™</td>\n",
       "      <td>ì»´í“¨í„°ë°ì£¼ë³€ì¥ì¹˜íŒë§¤</td>\n",
       "      <td>1.212852e+09</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025</td>\n",
       "      <td>11110515</td>\n",
       "      <td>ì²­ìš´íš¨ìë™</td>\n",
       "      <td>ìŠ¤í¬ì¸ í´ëŸ½</td>\n",
       "      <td>1.031641e+09</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ì—°ë„     í–‰ì •ë™ì½”ë“œ   í–‰ì •ë™ëª…          ì—…ì¢…        ì˜ˆì¸¡_ì´ë§¤ì¶œ    ìˆœìœ„\n",
       "0  2025  11110515  ì²­ìš´íš¨ìë™        ì¡°ëª…ìš©í’ˆ  5.775176e+09   1.0\n",
       "1  2025  11110515  ì²­ìš´íš¨ìë™       ì»¤í”¼-ìŒë£Œ  4.306592e+09   2.0\n",
       "2  2025  11110515  ì²­ìš´íš¨ìë™       í•œì‹ìŒì‹ì   3.738617e+09   3.0\n",
       "3  2025  11110515  ì²­ìš´íš¨ìë™          ì„œì   3.597058e+09   4.0\n",
       "4  2025  11110515  ì²­ìš´íš¨ìë™       ì–‘ì‹ìŒì‹ì   2.744975e+09   5.0\n",
       "5  2025  11110515  ì²­ìš´íš¨ìë™        ìŠˆí¼ë§ˆì¼“  2.040304e+09   6.0\n",
       "6  2025  11110515  ì²­ìš´íš¨ìë™         í¸ì˜ì   1.719586e+09   7.0\n",
       "7  2025  11110515  ì²­ìš´íš¨ìë™        ì˜ë£Œê¸°ê¸°  1.307927e+09   8.0\n",
       "8  2025  11110515  ì²­ìš´íš¨ìë™  ì»´í“¨í„°ë°ì£¼ë³€ì¥ì¹˜íŒë§¤  1.212852e+09   9.0\n",
       "9  2025  11110515  ì²­ìš´íš¨ìë™       ìŠ¤í¬ì¸ í´ëŸ½  1.031641e+09  10.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ğŸ“Œ 2. ì—°ë„ë³„ ë°ì´í„° ë¡œë“œ\n",
    "data_dir = '../../Data'  # ê²½ë¡œëŠ” í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë”°ë¼ ë§ê²Œ ì„¤ì •\n",
    "years = list(range(2019, 2024))\n",
    "\n",
    "dfs = []\n",
    "for year in years:\n",
    "    file = os.path.join(data_dir, 'Trading_Area', f'Trading_Area_{year}.csv')\n",
    "    if os.path.exists(file):\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(file, encoding='cp949')\n",
    "        df['ì—°ë„'] = year\n",
    "        if 'í–‰ì •ë™ì½”ë“œ' not in df.columns:\n",
    "            if 'í–‰ì •ë™_ì½”ë“œ' in df.columns:\n",
    "                df['í–‰ì •ë™_ì½”ë“œ'] = df['í–‰ì •ë™_ì½”ë“œ'].astype(str).str.zfill(8)\n",
    "            else:\n",
    "                raise KeyError(f'íŒŒì¼ {file}ì—ì„œ í–‰ì •ë™ì½”ë“œ ê´€ë ¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')\n",
    "        dfs.append(df)\n",
    "\n",
    "people_df = pd.read_csv(os.path.join(data_dir, 'CompanyPeople.csv'), encoding='cp949')\n",
    "people_df['í–‰ì •ë™_ì½”ë“œ'] = people_df['í–‰ì •ë™_ì½”ë“œ'].astype(str).str.zfill(8)\n",
    "\n",
    "dong_map = pd.read_excel(os.path.join(data_dir, 'í–‰ì •ë™ì½”ë“œ_ë§¤í•‘ì •ë³´.xlsx'), header=1)\n",
    "dong_map = dong_map[['H_DNG_CD', 'H_DNG_NM']].rename(columns={'H_DNG_CD':'í–‰ì •ë™ì½”ë“œ', 'H_DNG_NM':'í–‰ì •ë™ëª…'})\n",
    "dong_map['í–‰ì •ë™ì½”ë“œ'] = dong_map['í–‰ì •ë™ì½”ë“œ'].astype(str).str.zfill(8)\n",
    "\n",
    "# ğŸ“Œ 3. ëª¨ë“  ì—°ë„ë³„ ë°ì´í„° í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# ğŸ“Œ 4. ì§ì¥ì¸êµ¬ ë°ì´í„° ë³‘í•©\n",
    "data = data.merge(people_df, on=['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'í–‰ì •ë™_ì½”ë“œ'], how='left')\n",
    "\n",
    "# ğŸ“Œ 5. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (í‰ê·  ëŒ€ì²´)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data_num = data.select_dtypes(include=[np.number])\n",
    "data[data_num.columns] = imputer.fit_transform(data_num)\n",
    "\n",
    "# ğŸ“Œ 6. ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬\n",
    "le_dong = LabelEncoder()\n",
    "le_biz = LabelEncoder()\n",
    "data['í–‰ì •ë™ì½”ë“œ_le'] = le_dong.fit_transform(data['í–‰ì •ë™_ì½”ë“œ'])\n",
    "data['ì—…ì¢…_le'] = le_biz.fit_transform(data['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…'])\n",
    "\n",
    "# ğŸ“Œ 7. í•™ìŠµ ë°ì´í„° ì¤€ë¹„\n",
    "X = data[['ì—°ë„', 'í–‰ì •ë™ì½”ë“œ_le', 'ì—…ì¢…_le']]\n",
    "y = data['ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡']\n",
    "\n",
    "# ğŸ“Œ 8. RandomForestRegressor í•™ìŠµ\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=300,  # íŠ¸ë¦¬ ê°œìˆ˜\n",
    "    max_depth=15,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X, y)\n",
    "\n",
    "# ğŸ“Œ 9. 2025ë…„ ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„ (ëª¨ë“  (í–‰ì •ë™ì½”ë“œ, ì—…ì¢…) ì¡°í•©)\n",
    "dong_list = data['í–‰ì •ë™_ì½”ë“œ'].unique()\n",
    "biz_list = data['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…'].unique()\n",
    "\n",
    "pred_df = pd.DataFrame([\n",
    "    {'ì—°ë„': 2025, 'í–‰ì •ë™ì½”ë“œ': d, 'ì—…ì¢…': b}\n",
    "    for d in dong_list for b in biz_list\n",
    "])\n",
    "\n",
    "# ğŸ“Œ 10. ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "pred_df['í–‰ì •ë™ì½”ë“œ_le'] = le_dong.transform(pred_df['í–‰ì •ë™ì½”ë“œ'])\n",
    "pred_df['ì—…ì¢…_le'] = le_biz.transform(pred_df['ì—…ì¢…'])\n",
    "\n",
    "# ğŸ“Œ 11. ì§ì¥ì¸êµ¬ ë°ì´í„° ë³‘í•© (2024ë…„ ë°ì´í„° ì‚¬ìš© ê°€ì •)\n",
    "people_2024 = people_df[people_df['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'] == 2024].drop(columns=['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'])\n",
    "\n",
    "# people_df ì»¬ëŸ¼ëª… í†µì¼\n",
    "if 'í–‰ì •ë™_ì½”ë“œ' in people_df.columns:\n",
    "    people_df.rename(columns={'í–‰ì •ë™_ì½”ë“œ': 'í–‰ì •ë™ì½”ë“œ'}, inplace=True)\n",
    "\n",
    "# 2024ë…„ ë°ì´í„° ì¤€ë¹„\n",
    "people_2024 = people_df[people_df['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'] == 2024].drop(columns=['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ'])\n",
    "\n",
    "# âœ… ë³‘í•©: í–‰ì •ë™ì½”ë“œ ê¸°ì¤€ìœ¼ë¡œ ì •í™•íˆ!\n",
    "pred_df = pred_df.merge(people_2024, on='í–‰ì •ë™ì½”ë“œ', how='left')\n",
    "pred_df.fillna(people_2024.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "# ğŸ“Œ 12. ì˜ˆì¸¡\n",
    "X_pred = pred_df[['ì—°ë„', 'í–‰ì •ë™ì½”ë“œ_le', 'ì—…ì¢…_le']]\n",
    "pred_df['ì˜ˆì¸¡_ì´ë§¤ì¶œ'] = model.predict(X_pred)\n",
    "\n",
    "# ğŸ“Œ 13. í–‰ì •ë™ëª… ë¶™ì´ê¸°\n",
    "pred_df = pred_df.merge(dong_map, on='í–‰ì •ë™ì½”ë“œ', how='left')\n",
    "\n",
    "# ğŸ“Œ 14. ìˆœìœ„ ê³„ì‚°\n",
    "pred_df['ìˆœìœ„'] = pred_df.groupby('í–‰ì •ë™ì½”ë“œ')['ì˜ˆì¸¡_ì´ë§¤ì¶œ'].rank(ascending=False, method='min')\n",
    "pred_df['ì—°ë„'] = 2025\n",
    "\n",
    "# ğŸ“Œ 15. ìµœì¢… ì •ë¦¬ ë° ì €ì¥\n",
    "final = pred_df[['ì—°ë„', 'í–‰ì •ë™ì½”ë“œ', 'í–‰ì •ë™ëª…', 'ì—…ì¢…', 'ì˜ˆì¸¡_ì´ë§¤ì¶œ', 'ìˆœìœ„']]\n",
    "final = final.sort_values(by=['í–‰ì •ë™ì½”ë“œ', 'ìˆœìœ„']).reset_index(drop=True)\n",
    "\n",
    "final.to_csv('./Predicted_2025_Top_Business_Company.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°\n",
    "final.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb0fdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 9993481164.7541695\ttotal: 221ms\tremaining: 11m 1s\n",
      "100:\tlearn: 9608486570.2059059\ttotal: 6.11s\tremaining: 2m 55s\n",
      "200:\tlearn: 9396529486.1952553\ttotal: 12s\tremaining: 2m 47s\n",
      "300:\tlearn: 9225420797.3857040\ttotal: 18s\tremaining: 2m 41s\n",
      "400:\tlearn: 9011574334.0982780\ttotal: 23.9s\tremaining: 2m 34s\n",
      "500:\tlearn: 8898343370.5100136\ttotal: 29.7s\tremaining: 2m 28s\n",
      "600:\tlearn: 8789411231.4412670\ttotal: 35.3s\tremaining: 2m 21s\n",
      "700:\tlearn: 8705097999.5050926\ttotal: 41s\tremaining: 2m 14s\n",
      "800:\tlearn: 8630754892.9278831\ttotal: 46.6s\tremaining: 2m 8s\n",
      "900:\tlearn: 8575898801.5083399\ttotal: 52.2s\tremaining: 2m 1s\n",
      "1000:\tlearn: 8513196902.6411648\ttotal: 57.8s\tremaining: 1m 55s\n",
      "1100:\tlearn: 8481382743.9434233\ttotal: 1m 3s\tremaining: 1m 49s\n",
      "1200:\tlearn: 8446234049.9579210\ttotal: 1m 9s\tremaining: 1m 43s\n",
      "1300:\tlearn: 8390761224.3383198\ttotal: 1m 14s\tremaining: 1m 37s\n",
      "1400:\tlearn: 8353813193.1701746\ttotal: 1m 20s\tremaining: 1m 31s\n",
      "1500:\tlearn: 8319670708.8945866\ttotal: 1m 26s\tremaining: 1m 25s\n",
      "1600:\tlearn: 8300265697.5415783\ttotal: 1m 31s\tremaining: 1m 20s\n",
      "1700:\tlearn: 8286107800.9177608\ttotal: 1m 37s\tremaining: 1m 14s\n",
      "1800:\tlearn: 8267143837.6062479\ttotal: 1m 43s\tremaining: 1m 8s\n",
      "1900:\tlearn: 8248985737.6891584\ttotal: 1m 49s\tremaining: 1m 3s\n",
      "2000:\tlearn: 8225743631.1233788\ttotal: 1m 54s\tremaining: 57.3s\n",
      "2100:\tlearn: 8197578686.1683121\ttotal: 2m\tremaining: 51.6s\n",
      "2200:\tlearn: 8170700614.6488028\ttotal: 2m 6s\tremaining: 45.9s\n",
      "2300:\tlearn: 8142796450.1963606\ttotal: 2m 12s\tremaining: 40.2s\n",
      "2400:\tlearn: 8118774022.4305849\ttotal: 2m 17s\tremaining: 34.4s\n",
      "2500:\tlearn: 8089920005.2245398\ttotal: 2m 23s\tremaining: 28.7s\n",
      "2600:\tlearn: 8056744400.6993017\ttotal: 2m 29s\tremaining: 22.9s\n",
      "2700:\tlearn: 8025467389.5695601\ttotal: 2m 35s\tremaining: 17.2s\n",
      "2800:\tlearn: 8014059385.0652857\ttotal: 2m 40s\tremaining: 11.4s\n",
      "2900:\tlearn: 7997973443.1926899\ttotal: 2m 46s\tremaining: 5.68s\n",
      "2999:\tlearn: 7987086414.7527666\ttotal: 2m 52s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x20686631d10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "# 1. ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ íŒŒì¼ í•©ì¹˜ê¸°\n",
    "years = list(range(2019, 2024))\n",
    "df_list = []\n",
    "for year in years:\n",
    "    file = os.path.join(data_dir, f'{year}_sales.csv')\n",
    "    if os.path.exists(file):\n",
    "        try:\n",
    "            df = pd.read_csv(file, encoding='utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            df = pd.read_csv(file, encoding='cp949')\n",
    "        df['ì—°ë„'] = year\n",
    "        if 'í–‰ì •ë™ì½”ë“œ' not in df.columns:\n",
    "            if 'í–‰ì •ë™_ì½”ë“œ' in df.columns:\n",
    "                df['í–‰ì •ë™_ì½”ë“œ'] = df['í–‰ì •ë™_ì½”ë“œ'].astype(str).str.zfill(8)\n",
    "            else:\n",
    "                raise KeyError(f'íŒŒì¼ {file}ì—ì„œ í–‰ì •ë™ì½”ë“œ ê´€ë ¨ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')\n",
    "        dfs.append(df)\n",
    "\n",
    "\n",
    "# 2. í–‰ì •ë™ì½”ë“œ ë§¤í•‘ì •ë³´ ë¡œë“œ\n",
    "dong_map = pd.read_excel('../../Data/í–‰ì •ë™ì½”ë“œ_ë§¤í•‘ì •ë³´.xlsx', header=1, engine='openpyxl')\n",
    "dong_map = dong_map[['H_DNG_CD', 'H_DNG_NM']].rename(columns={'H_DNG_CD': 'í–‰ì •ë™ì½”ë“œ', 'H_DNG_NM': 'í–‰ì •ë™ëª…'})\n",
    "dong_map['í–‰ì •ë™ì½”ë“œ'] = dong_map['í–‰ì •ë™ì½”ë“œ'].astype(str).str.zfill(8)\n",
    "\n",
    "# 1ï¸âƒ£ ì»¬ëŸ¼ëª… í†µì¼\n",
    "data = data.rename(columns={\n",
    "    'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡': 'ì´ë§¤ì¶œ'  # ì´ ë¶€ë¶„ì´ ì¤‘ìš”!\n",
    "})\n",
    "\n",
    "# 4ï¸âƒ£ ì „ë…„ë„ ë§¤ì¶œ ë°ì´í„°ì™€ mergeí•´ì„œ ì¦ê°ë¥  ê³„ì‚°\n",
    "data_prev = data.copy()\n",
    "data_prev['ì—°ë„'] += 1\n",
    "data_prev = data_prev.rename(columns={'ì´ë§¤ì¶œ': 'ì´ë§¤ì¶œ_prev'})\n",
    "\n",
    "data_merged = data.merge(data_prev[['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'í–‰ì •ë™_ì½”ë“œ', 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…', 'ì´ë§¤ì¶œ_prev']],\n",
    "                          on=['ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ', 'í–‰ì •ë™_ì½”ë“œ', 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…'], how='left')\n",
    "data_merged['ë§¤ì¶œì¦ê°ë¥ '] = (data_merged['ì´ë§¤ì¶œ'] - data_merged['ì´ë§¤ì¶œ_prev']) / data_merged['ì´ë§¤ì¶œ_prev']\n",
    "data_merged['ë§¤ì¶œì¦ê°ë¥ '] = data_merged['ë§¤ì¶œì¦ê°ë¥ '].fillna(0)\n",
    "\n",
    "# 3. ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬\n",
    "X = data_merged[['ì—°ë„', 'í–‰ì •ë™_ì½”ë“œ', 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…']]\n",
    "y = data_merged['ì´ë§¤ì¶œ']\n",
    "cat_features = ['í–‰ì •ë™_ì½”ë“œ', 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…']\n",
    "\n",
    "train_pool = Pool(X, y, cat_features=cat_features)\n",
    "\n",
    "# 4. CatBoostRegressor ëª¨ë¸ í•™ìŠµ\n",
    "model = CatBoostRegressor(\n",
    "    iterations=3000,\n",
    "    learning_rate=0.01,\n",
    "    depth=8,\n",
    "    l2_leaf_reg=3,\n",
    "    loss_function='RMSE',\n",
    "    random_seed=42,\n",
    "    cat_features=cat_features,\n",
    "    task_type='GPU',  # GPU ì‚¬ìš© (ì—†ìœ¼ë©´ 'CPU'ë¡œ ë°”ê¿”ì£¼ì„¸ìš”)\n",
    "    verbose=100\n",
    ")\n",
    "model.fit(train_pool)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b949a0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: ë§¤ì¶œì¦ê°ë¥ '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m pred_df \u001b[38;5;241m=\u001b[39m pred_df\u001b[38;5;241m.\u001b[39mmerge(dong_map, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mí–‰ì •ë™ì½”ë“œ\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 7-1. ê³¼ê±° í‰ê·  ë§¤ì¶œì¦ê°ë¥  ê³„ì‚°\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m avg_rate \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mí–‰ì •ë™_ì½”ë“œ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124më§¤ì¶œì¦ê°ë¥ \u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m     22\u001b[0m avg_rate\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mí–‰ì •ë™ì½”ë“œ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mì—…ì¢…\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mê³¼ê±°_í‰ê· _ì¦ê°ë¥ \u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     23\u001b[0m pred_df \u001b[38;5;241m=\u001b[39m pred_df\u001b[38;5;241m.\u001b[39mmerge(avg_rate, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mí–‰ì •ë™ì½”ë“œ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mì—…ì¢…\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rladj\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\generic.py:1416\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1408\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[0;32m   1409\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise warning\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndexing with multiple keys (implicitly converted to a tuple \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof keys) will be deprecated, use a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1413\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m   1414\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1415\u001b[0m     )\n\u001b[1;32m-> 1416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(key)\n",
      "File \u001b[1;32mc:\\Users\\rladj\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:248\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[1;32m--> 248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    249\u001b[0m     subset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\n\u001b[0;32m    250\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m subset\u001b[38;5;241m.\u001b[39mndim\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Column not found: ë§¤ì¶œì¦ê°ë¥ '"
     ]
    }
   ],
   "source": [
    "# 5. 2025ë…„ ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„ (ëª¨ë“  (í–‰ì •ë™ì½”ë“œ, ì—…ì¢…) ì¡°í•©)\n",
    "dong_list = sorted(X['í–‰ì •ë™_ì½”ë“œ'].unique())\n",
    "biz_list = sorted(X['ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…'].unique())\n",
    "pred_df = pd.DataFrame([\n",
    "    {\"ì—°ë„\": 2025, \"í–‰ì •ë™_ì½”ë“œ\": d, \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…\": b}\n",
    "    for d in dong_list for b in biz_list\n",
    "])\n",
    "pred_pool = Pool(pred_df, cat_features=cat_features)\n",
    "\n",
    "# 6. ë§¤ì¶œ ì˜ˆì¸¡\n",
    "pred_df['ì˜ˆì¸¡_ì´ë§¤ì¶œ'] = model.predict(pred_pool)\n",
    "\n",
    "\n",
    "# ì»¬ëŸ¼ëª… ì •ë¦¬\n",
    "pred_df = pred_df.rename(columns={'í–‰ì •ë™_ì½”ë“œ': 'í–‰ì •ë™ì½”ë“œ', 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…': 'ì—…ì¢…'})\n",
    "\n",
    "# 7. í–‰ì •ë™ëª… ë³‘í•©\n",
    "pred_df = pred_df.merge(dong_map, on='í–‰ì •ë™ì½”ë“œ', how='left')\n",
    "\n",
    "# 7-1. ê³¼ê±° í‰ê·  ë§¤ì¶œì¦ê°ë¥  ê³„ì‚°\n",
    "avg_rate = data.groupby(['í–‰ì •ë™_ì½”ë“œ', 'ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…'])['ë§¤ì¶œì¦ê°ë¥ '].mean().reset_index()\n",
    "avg_rate.columns = ['í–‰ì •ë™ì½”ë“œ', 'ì—…ì¢…', 'ê³¼ê±°_í‰ê· _ì¦ê°ë¥ ']\n",
    "pred_df = pred_df.merge(avg_rate, on=['í–‰ì •ë™ì½”ë“œ', 'ì—…ì¢…'], how='left')\n",
    "pred_df['ê³¼ê±°_í‰ê· _ì¦ê°ë¥ '] = pred_df['ê³¼ê±°_í‰ê· _ì¦ê°ë¥ '].fillna(0)\n",
    "\n",
    "# 7-2. ì ìˆ˜ ê³„ì‚° ë° ìˆœìœ„\n",
    "pred_df['ì˜ˆì¸¡_ì ìˆ˜'] = pred_df['ì˜ˆì¸¡_ì´ë§¤ì¶œ'] * (1 + pred_df['ê³¼ê±°_í‰ê· _ì¦ê°ë¥ '])\n",
    "pred_df['ìˆœìœ„'] = pred_df.groupby('í–‰ì •ë™ì½”ë“œ')['ì˜ˆì¸¡_ì ìˆ˜'].rank(ascending=False, method='min')\n",
    "pred_df['ì—°ë„'] = 2025\n",
    "\n",
    "# 8. ìµœì¢… ì •ë¦¬ ë° CSV ì €ì¥\n",
    "final = pred_df[['ì—°ë„', 'í–‰ì •ë™ì½”ë“œ', 'í–‰ì •ë™ëª…', 'ì—…ì¢…', 'ì˜ˆì¸¡_ì´ë§¤ì¶œ', 'ìˆœìœ„']]\n",
    "final = final.sort_values(by=['í–‰ì •ë™ì½”ë“œ', 'ìˆœìœ„']).reset_index(drop=True)\n",
    "final.to_csv('./Predicted_2025_Top_Business.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"âœ… 2025ë…„ ì—…ì¢…ë³„ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ! ./Predicted_2025_Top_Business.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
