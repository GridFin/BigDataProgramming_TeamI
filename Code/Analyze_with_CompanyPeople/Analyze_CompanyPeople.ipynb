{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f627d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜ ì•ˆ í–ˆë‹¤ë©´ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤í–‰ì‹œí‚¤ì„¸ìš”.\n",
    "# !pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee6b99ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ CompanyPeople ìƒê¶Œ ë§¤ì¶œ ì˜ˆì¸¡ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸\n",
      "==================================================\n",
      "=== CompanyPeople ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘ ===\n",
      "\n",
      "ğŸ“… 2019ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2019 ë¡œë“œ ì™„ë£Œ: 65666í–‰\n",
      "  ğŸ”„ 2019ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2019ë…„ 1ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2019ë…„ 1ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16273 + ì§ì¥ì¸êµ¬ 414 â†’ 16273í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 99.0%\n",
      "  ğŸ”„ 2019ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2019ë…„ 2ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2019ë…„ 2ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16418 + ì§ì¥ì¸êµ¬ 414 â†’ 16418í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 99.0%\n",
      "  ğŸ”„ 2019ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2019ë…„ 3ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2019ë…„ 3ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16456 + ì§ì¥ì¸êµ¬ 414 â†’ 16456í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 99.0%\n",
      "  ğŸ”„ 2019ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2019ë…„ 4ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2019ë…„ 4ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16519 + ì§ì¥ì¸êµ¬ 414 â†’ 16519í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 99.0%\n",
      "\n",
      "ğŸ“… 2020ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2020 ë¡œë“œ ì™„ë£Œ: 66501í–‰\n",
      "  ğŸ”„ 2020ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2020ë…„ 1ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2020ë…„ 1ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16502 + ì§ì¥ì¸êµ¬ 414 â†’ 16502í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.9%\n",
      "  ğŸ”„ 2020ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2020ë…„ 2ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2020ë…„ 2ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16648 + ì§ì¥ì¸êµ¬ 414 â†’ 16648í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.9%\n",
      "  ğŸ”„ 2020ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2020ë…„ 3ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2020ë…„ 3ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16676 + ì§ì¥ì¸êµ¬ 414 â†’ 16676í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.9%\n",
      "  ğŸ”„ 2020ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2020ë…„ 4ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2020ë…„ 4ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16675 + ì§ì¥ì¸êµ¬ 414 â†’ 16675í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.9%\n",
      "\n",
      "ğŸ“… 2021ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2021 ë¡œë“œ ì™„ë£Œ: 70071í–‰\n",
      "  ğŸ”„ 2021ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2021ë…„ 1ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2021ë…„ 1ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17536 + ì§ì¥ì¸êµ¬ 414 â†’ 17536í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.8%\n",
      "  ğŸ”„ 2021ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2021ë…„ 2ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2021ë…„ 2ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17541 + ì§ì¥ì¸êµ¬ 414 â†’ 17541í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.9%\n",
      "  ğŸ”„ 2021ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2021ë…„ 3ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2021ë…„ 3ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17514 + ì§ì¥ì¸êµ¬ 414 â†’ 17514í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.8%\n",
      "  ğŸ”„ 2021ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2021ë…„ 4ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2021ë…„ 4ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17480 + ì§ì¥ì¸êµ¬ 414 â†’ 17480í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.8%\n",
      "\n",
      "ğŸ“… 2022ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2022 ë¡œë“œ ì™„ë£Œ: 69440í–‰\n",
      "  ğŸ”„ 2022ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2022ë…„ 1ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2022ë…„ 1ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17394 + ì§ì¥ì¸êµ¬ 414 â†’ 17394í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.9%\n",
      "  ğŸ”„ 2022ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2022ë…„ 2ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2022ë…„ 2ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17401 + ì§ì¥ì¸êµ¬ 414 â†’ 17401í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.8%\n",
      "  ğŸ”„ 2022ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2022ë…„ 3ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2022ë…„ 3ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17346 + ì§ì¥ì¸êµ¬ 414 â†’ 17346í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.8%\n",
      "  ğŸ”„ 2022ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2022ë…„ 4ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2022ë…„ 4ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17299 + ì§ì¥ì¸êµ¬ 414 â†’ 17299í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.8%\n",
      "\n",
      "ğŸ“… 2023ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2023 ë¡œë“œ ì™„ë£Œ: 68643í–‰\n",
      "  ğŸ”„ 2023ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2023ë…„ 1ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2023ë…„ 1ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17188 + ì§ì¥ì¸êµ¬ 414 â†’ 17188í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.8%\n",
      "  ğŸ”„ 2023ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2023ë…„ 2ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2023ë…„ 2ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17196 + ì§ì¥ì¸êµ¬ 414 â†’ 17196í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.8%\n",
      "  ğŸ”„ 2023ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2023ë…„ 3ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2023ë…„ 3ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17137 + ì§ì¥ì¸êµ¬ 414 â†’ 17137í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.8%\n",
      "  ğŸ”„ 2023ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2023ë…„ 4ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2023ë…„ 4ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17122 + ì§ì¥ì¸êµ¬ 414 â†’ 17122í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.8%\n",
      "\n",
      "ğŸ“… 2024ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\n",
      "  Trading Area 2024 ë¡œë“œ ì™„ë£Œ: 67900í–‰\n",
      "  ğŸ”„ 2024ë…„ 1ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2024ë…„ 1ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2024ë…„ 1ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17044 + ì§ì¥ì¸êµ¬ 414 â†’ 17044í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.8%\n",
      "  ğŸ”„ 2024ë…„ 2ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2024ë…„ 2ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2024ë…„ 2ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 17048 + ì§ì¥ì¸êµ¬ 414 â†’ 17048í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.8%\n",
      "  ğŸ”„ 2024ë…„ 3ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2024ë…„ 3ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2024ë…„ 3ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16937 + ì§ì¥ì¸êµ¬ 414 â†’ 16937í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.8%\n",
      "  ğŸ”„ 2024ë…„ 4ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\n",
      "    2024ë…„ 4ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\n",
      "    âœ… 2024ë…„ 4ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 414ê°œ í–‰ì •ë™\n",
      "    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ 16871 + ì§ì¥ì¸êµ¬ 414 â†’ 16871í–‰\n",
      "    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : 98.9%\n",
      "\n",
      "ğŸ”— ì „ì²´ ë°ì´í„° ê²°í•© ì¤‘...\n",
      "âœ… ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: (408221, 74)\n",
      "\n",
      "=== ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ===\n",
      "ì›ë³¸ ë°ì´í„° í¬ê¸°: (408221, 74)\n",
      "ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€ë¥¼ ìœ„í•´ ì œê±°í•  ë§¤ì¶œ ê´€ë ¨ ì»¬ëŸ¼: 65ê°œ\n",
      "ì œê±° ì»¬ëŸ¼ ì˜ˆì‹œ: ['ë‹¹ì›”_ë§¤ì¶œ_ê±´ìˆ˜', 'ì£¼ì¤‘_ë§¤ì¶œ_ê¸ˆì•¡', 'ì£¼ë§_ë§¤ì¶œ_ê¸ˆì•¡', 'ì›”ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡', 'í™”ìš”ì¼_ë§¤ì¶œ_ê¸ˆì•¡']\n",
      "ê²°ì¸¡ë¥  70% ì´ìƒ ì»¬ëŸ¼ ì œê±°: 0ê°œ\n",
      "ğŸ“Š CompanyPeople ê´€ë ¨ ì»¬ëŸ¼: 3ê°œ\n",
      "âœ… CompanyPeople ë°ì´í„° í¬í•¨ í™•ì¸ë¨\n",
      "   ì˜ˆì‹œ: ['ì´_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ë‚¨ì„±_ì§ì¥_ì¸êµ¬_ìˆ˜', 'ì—¬ì„±_ì§ì¥_ì¸êµ¬_ìˆ˜']\n",
      "ì „ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: (408221, 7)\n",
      "\n",
      "=== ë°ì´í„° ë¶„í•  (2024ë…„ í…ŒìŠ¤íŠ¸) ===\n",
      "í›ˆë ¨ ë°ì´í„°: 340321í–‰\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°: 67900í–‰\n",
      "ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...\n",
      "\n",
      "=== ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ===\n",
      "í›ˆë ¨ ë°ì´í„°: (340321, 6), í…ŒìŠ¤íŠ¸ ë°ì´í„°: (67900, 6)\n",
      "ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\n",
      "âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "ğŸ”® ì˜ˆì¸¡ ì¤‘...\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ CompanyPeople ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\n",
      "============================================================\n",
      "MSE:  87,881,875,468,726,059,008\n",
      "RMSE: 9,374,533,347 ì›\n",
      "MAE:  862,320,753 ì›\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê·  ë§¤ì¶œ: 1,532,612,027 ì›\n",
      "Out-of-Bag Score: 0.6968\n",
      "\n",
      "--- ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ---\n",
      " 1. ğŸª ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_encoded: 0.5974\n",
      " 2. ğŸª í–‰ì •ë™ì½”ë“œ: 0.1277\n",
      " 3. ğŸ¢ ì—¬ì„±_ì§ì¥_ì¸êµ¬_ìˆ˜: 0.0925\n",
      " 4. ğŸ¢ ì´_ì§ì¥_ì¸êµ¬_ìˆ˜: 0.0922\n",
      " 5. ğŸ¢ ë‚¨ì„±_ì§ì¥_ì¸êµ¬_ìˆ˜: 0.0697\n",
      " 6. ğŸª ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ: 0.0205\n",
      "\n",
      "ğŸ“Š CompanyPeople ë°ì´í„° ì´ ê¸°ì—¬ë„: 0.2544 (25.4%)\n",
      "âœ… CompanyPeople ë°ì´í„°ê°€ ìœ ì˜ë¯¸í•˜ê²Œ ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ‰ CompanyPeople ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "==================================================\n",
      "ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\Code\\Analyze_with_CompanyPeople\\results\\companypeople_model_20250619_115304.joblib\n",
      "ğŸ“Š í‰ê°€ì§€í‘œ CSV ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\Code\\Analyze_with_CompanyPeople\\results\\companypeople_metrics_20250619_115304.csv\n",
      "ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ CSV ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\Code\\Analyze_with_CompanyPeople\\results\\companypeople_importance_20250619_115304.csv\n",
      "ğŸ“‹ ëª¨ë¸ ìš”ì•½ CSV ì €ì¥ ì™„ë£Œ: c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\Code\\Analyze_with_CompanyPeople\\results\\companypeople_summary_20250619_115304.csv\n",
      "\n",
      "ğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ 'c:\\Users\\rladj\\OneDrive\\ë°”íƒ• í™”ë©´\\ì½”ë”©\\4í•™ë…„\\ë¹…ë°\\ë¹…ë° íŒ€í”Œ\\final\\BigDataProgramming_TeamI\\Code\\Analyze_with_CompanyPeople\\results' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "\n",
      "ğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "import gc\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def load_companypeople_quarterly_fixed(year, quarter, people_dir):\n",
    "    \"\"\"ìˆ˜ì •ëœ ë¶„ê¸°ë³„ CompanyPeople ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "\n",
    "    file_path = os.path.join(people_dir, \"CompanyPeople.csv\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"    âŒ CompanyPeople íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"    {year}ë…„ {quarter}ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
    "\n",
    "    try:\n",
    "        # CSV ì½ê¸° - euc-kr ì¸ì½”ë”© ìš°ì„  ì‹œë„\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=\"euc-kr\")\n",
    "        except:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, encoding=\"cp949\")\n",
    "            except:\n",
    "                df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "\n",
    "        # í•´ë‹¹ ë…„ë„/ë¶„ê¸° ë°ì´í„° í•„í„°ë§\n",
    "        quarter_code = int(f\"{year}{quarter}\")\n",
    "        df_filtered = df[df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] == quarter_code].copy()\n",
    "\n",
    "        if len(df_filtered) == 0:\n",
    "            print(f\"    âŒ {year}ë…„ {quarter}ë¶„ê¸° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤\")\n",
    "            return None\n",
    "\n",
    "        # í–‰ì •ë™ì½”ë“œ ì •ë¦¬\n",
    "        df_filtered[\"í–‰ì •ë™ì½”ë“œ\"] = df_filtered[\"í–‰ì •ë™_ì½”ë“œ\"].astype(str).str.zfill(8)\n",
    "\n",
    "        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "        numeric_cols = [\n",
    "            \"ì´_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ë‚¨ì„±_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ì—¬ì„±_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ì—°ë ¹ëŒ€_10_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ì—°ë ¹ëŒ€_20_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ì—°ë ¹ëŒ€_30_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ì—°ë ¹ëŒ€_40_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ì—°ë ¹ëŒ€_50_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ì—°ë ¹ëŒ€_60_ì´ìƒ_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ë‚¨ì„±ì—°ë ¹ëŒ€_10_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ë‚¨ì„±ì—°ë ¹ëŒ€_20_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ë‚¨ì„±ì—°ë ¹ëŒ€_30_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ë‚¨ì„±ì—°ë ¹ëŒ€_40_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ë‚¨ì„±ì—°ë ¹ëŒ€_50_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ë‚¨ì„±ì—°ë ¹ëŒ€_60_ì´ìƒ_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ì—¬ì„±ì—°ë ¹ëŒ€_10_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ì—¬ì„±ì—°ë ¹ëŒ€_20_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ì—¬ì„±ì—°ë ¹ëŒ€_30_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ì—¬ì„±ì—°ë ¹ëŒ€_40_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ì—¬ì„±ì—°ë ¹ëŒ€_50_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "            \"ì—¬ì„±ì—°ë ¹ëŒ€_60_ì´ìƒ_ì§ì¥_ì¸êµ¬_ìˆ˜\",\n",
    "        ]\n",
    "\n",
    "        keep_cols = [\"í–‰ì •ë™ì½”ë“œ\"] + [\n",
    "            col for col in numeric_cols if col in df_filtered.columns\n",
    "        ]\n",
    "        result_df = df_filtered[keep_cols].copy()\n",
    "\n",
    "        # ì§ì¥ì¸êµ¬ ë°ì´í„°ë„ ëˆ„ì í•©ìœ¼ë¡œ ë³€ê²½\n",
    "        result_df = result_df.groupby(\"í–‰ì •ë™ì½”ë“œ\")[numeric_cols].sum().reset_index()\n",
    "\n",
    "        print(\n",
    "            f\"    âœ… {year}ë…„ {quarter}ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(result_df)}ê°œ í–‰ì •ë™\"\n",
    "        )\n",
    "        return result_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ {year}ë…„ {quarter}ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_trading_area_data(year, biz_dir):\n",
    "    \"\"\"Trading Area ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "    file_path = os.path.join(biz_dir, f\"Trading_Area_{year}.csv\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=\"utf-8\")\n",
    "        except:\n",
    "            df = pd.read_csv(file_path, encoding=\"cp949\")\n",
    "\n",
    "        df = df.rename(columns={\"í–‰ì •ë™_ì½”ë“œ\": \"í–‰ì •ë™ì½”ë“œ\"})\n",
    "        df[\"í–‰ì •ë™ì½”ë“œ\"] = df[\"í–‰ì •ë™ì½”ë“œ\"].astype(str).str.zfill(8)\n",
    "\n",
    "        print(f\"  Trading Area {year} ë¡œë“œ ì™„ë£Œ: {len(df)}í–‰\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Trading Area {year} ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_master_dataset_fixed(years, people_dir, biz_dir):\n",
    "    \"\"\"ìˆ˜ì •ëœ ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± (CompanyPeople ë²„ì „)\"\"\"\n",
    "    print(\"=== CompanyPeople ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘ ===\")\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for year in years:\n",
    "        print(f\"\\nğŸ“… {year}ë…„ ë°ì´í„° ì²˜ë¦¬ ì¤‘...\")\n",
    "\n",
    "        # Trading Area ë°ì´í„° ë¡œë“œ\n",
    "        biz_df = load_trading_area_data(year, biz_dir)\n",
    "        if biz_df is None:\n",
    "            continue\n",
    "\n",
    "        # ê° ë¶„ê¸°ë³„ë¡œ ì²˜ë¦¬\n",
    "        for quarter in [1, 2, 3, 4]:\n",
    "            print(f\"  ğŸ”„ {year}ë…„ {quarter}ë¶„ê¸° ì²˜ë¦¬ ì¤‘...\")\n",
    "\n",
    "            # í•´ë‹¹ ë¶„ê¸° Trading Area ë°ì´í„° í•„í„°ë§\n",
    "            quarter_code = int(f\"{year}{quarter}\")\n",
    "            biz_quarter = biz_df[biz_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] == quarter_code].copy()\n",
    "\n",
    "            if len(biz_quarter) == 0:\n",
    "                print(f\"    âŒ {year}ë…„ {quarter}ë¶„ê¸° ë§¤ì¶œ ë°ì´í„° ì—†ìŒ\")\n",
    "                continue\n",
    "\n",
    "            # CompanyPeople ë°ì´í„° ë¡œë“œ\n",
    "            people_quarter = load_companypeople_quarterly_fixed(\n",
    "                year, quarter, people_dir\n",
    "            )\n",
    "\n",
    "            if people_quarter is None:\n",
    "                print(f\"    âŒ {year}ë…„ {quarter}ë¶„ê¸° ì§ì¥ì¸êµ¬ ë°ì´í„° ì—†ìŒ\")\n",
    "                continue\n",
    "\n",
    "            # ë°ì´í„° ë³‘í•©\n",
    "            merged_data = pd.merge(\n",
    "                biz_quarter, people_quarter, on=\"í–‰ì •ë™ì½”ë“œ\", how=\"left\"\n",
    "            )\n",
    "\n",
    "            # ë³‘í•© ê²°ê³¼ í™•ì¸\n",
    "            people_cols = [col for col in people_quarter.columns if col != \"í–‰ì •ë™ì½”ë“œ\"]\n",
    "            if people_cols:\n",
    "                people_match_rate = (\n",
    "                    (~merged_data[people_cols[0]].isna()).sum() / len(merged_data) * 100\n",
    "                )\n",
    "            else:\n",
    "                people_match_rate = 0\n",
    "\n",
    "            print(\n",
    "                f\"    âœ… ë³‘í•© ì™„ë£Œ: ë§¤ì¶œ {len(biz_quarter)} + ì§ì¥ì¸êµ¬ {len(people_quarter)} â†’ {len(merged_data)}í–‰\"\n",
    "            )\n",
    "            print(f\"    ğŸ“Š ì§ì¥ì¸êµ¬ ë°ì´í„° ë§¤ì¹­ë¥ : {people_match_rate:.1f}%\")\n",
    "\n",
    "            all_data.append(merged_data)\n",
    "\n",
    "            # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "            del biz_quarter, people_quarter, merged_data\n",
    "            gc.collect()\n",
    "\n",
    "    if not all_data:\n",
    "        raise ValueError(\"ìƒì„±ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "    # ì „ì²´ ë°ì´í„° ê²°í•©\n",
    "    print(\"\\nğŸ”— ì „ì²´ ë°ì´í„° ê²°í•© ì¤‘...\")\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"âœ… ë§ˆìŠ¤í„° ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {final_df.shape}\")\n",
    "\n",
    "    return final_df\n",
    "\n",
    "\n",
    "def preprocess_data_fixed(df):\n",
    "    \"\"\"ìˆ˜ì •ëœ ë°ì´í„° ì „ì²˜ë¦¬ (CompanyPeople ë²„ì „)\"\"\"\n",
    "    print(\"\\n=== ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘ ===\")\n",
    "    print(f\"ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "\n",
    "    # íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸\n",
    "    if \"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\" not in df.columns:\n",
    "        raise ValueError(\"íƒ€ê²Ÿ ë³€ìˆ˜ 'ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡'ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "    # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° + ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€\n",
    "    drop_cols = [\"í–‰ì •ë™_ì½”ë“œ_ëª…\", \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_ëª…\"]\n",
    "\n",
    "    # ğŸ”¥ ë§¤ì¶œ ê´€ë ¨ íŠ¹ì„± ì œê±° (ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€)\n",
    "    sales_cols = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if any(\n",
    "            keyword in col\n",
    "            for keyword in [\n",
    "                \"ë§¤ì¶œ_ê¸ˆì•¡\",\n",
    "                \"ë§¤ì¶œ_ê±´ìˆ˜\",\n",
    "                \"ì›”ìš”ì¼_\",\n",
    "                \"í™”ìš”ì¼_\",\n",
    "                \"ìˆ˜ìš”ì¼_\",\n",
    "                \"ëª©ìš”ì¼_\",\n",
    "                \"ê¸ˆìš”ì¼_\",\n",
    "                \"í† ìš”ì¼_\",\n",
    "                \"ì¼ìš”ì¼_\",\n",
    "                \"ì£¼ì¤‘_\",\n",
    "                \"ì£¼ë§_\",\n",
    "                \"ì‹œê°„ëŒ€_\",\n",
    "                \"ë‚¨ì„±_ë§¤ì¶œ\",\n",
    "                \"ì—¬ì„±_ë§¤ì¶œ\",\n",
    "                \"ì—°ë ¹ëŒ€_\",\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # íƒ€ê²Ÿ ë³€ìˆ˜ëŠ” ìœ ì§€\n",
    "    sales_cols = [col for col in sales_cols if col != \"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\"]\n",
    "\n",
    "    print(f\"ë°ì´í„° ë¦¬í‚¤ì§€ ë°©ì§€ë¥¼ ìœ„í•´ ì œê±°í•  ë§¤ì¶œ ê´€ë ¨ ì»¬ëŸ¼: {len(sales_cols)}ê°œ\")\n",
    "    print(f\"ì œê±° ì»¬ëŸ¼ ì˜ˆì‹œ: {sales_cols[:5]}\")\n",
    "\n",
    "    drop_cols.extend(sales_cols)\n",
    "    df = df.drop(columns=[col for col in drop_cols if col in df.columns])\n",
    "\n",
    "    # ê²°ì¸¡ê°’ì´ ë„ˆë¬´ ë§ì€ ì»¬ëŸ¼ ì œê±° (70% ì´ìƒ)\n",
    "    null_ratio = df.isnull().mean()\n",
    "    high_null_cols = null_ratio[null_ratio > 0.7].index.tolist()\n",
    "    print(f\"ê²°ì¸¡ë¥  70% ì´ìƒ ì»¬ëŸ¼ ì œê±°: {len(high_null_cols)}ê°œ\")\n",
    "    if high_null_cols:\n",
    "        df = df.drop(columns=high_null_cols)\n",
    "\n",
    "    # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "    if \"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\" in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ_encoded\"] = le.fit_transform(\n",
    "            df[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"].astype(str)\n",
    "        )\n",
    "        df = df.drop(columns=[\"ì„œë¹„ìŠ¤_ì—…ì¢…_ì½”ë“œ\"])\n",
    "\n",
    "    # CompanyPeople ê´€ë ¨ ì»¬ëŸ¼ í™•ì¸\n",
    "    people_cols = [\n",
    "        col\n",
    "        for col in df.columns\n",
    "        if any(\n",
    "            keyword in col\n",
    "            for keyword in [\"ì§ì¥_ì¸êµ¬_ìˆ˜\", \"ë‚¨ì„±_ì§ì¥\", \"ì—¬ì„±_ì§ì¥\", \"ì—°ë ¹ëŒ€_\"]\n",
    "        )\n",
    "    ]\n",
    "    print(f\"ğŸ“Š CompanyPeople ê´€ë ¨ ì»¬ëŸ¼: {len(people_cols)}ê°œ\")\n",
    "\n",
    "    if len(people_cols) == 0:\n",
    "        print(\"âš ï¸ ê²½ê³ : CompanyPeople ë°ì´í„°ê°€ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!\")\n",
    "    else:\n",
    "        print(\"âœ… CompanyPeople ë°ì´í„° í¬í•¨ í™•ì¸ë¨\")\n",
    "        # ëª‡ ê°œ ì»¬ëŸ¼ëª… ì¶œë ¥\n",
    "        sample_cols = people_cols[:5]\n",
    "        print(f\"   ì˜ˆì‹œ: {sample_cols}\")\n",
    "\n",
    "    print(f\"ì „ì²˜ë¦¬ í›„ ë°ì´í„° í¬ê¸°: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def train_and_evaluate_model_fixed(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"ìˆ˜ì •ëœ ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ (CompanyPeople ë²„ì „)\"\"\"\n",
    "    print(\"\\n=== ëª¨ë¸ í•™ìŠµ ë° í‰ê°€ ===\")\n",
    "    print(f\"í›ˆë ¨ ë°ì´í„°: {X_train.shape}, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape}\")\n",
    "\n",
    "    # íƒ€ê²Ÿ ë³€ìˆ˜ ë¡œê·¸ ë³€í™˜\n",
    "    y_train_log = np.log1p(y_train.clip(lower=0))\n",
    "\n",
    "    # RandomForest ëª¨ë¸\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100, max_depth=15, random_state=42, n_jobs=-1, oob_score=True\n",
    "    )\n",
    "\n",
    "    print(\"ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n",
    "    model.fit(X_train, y_train_log)\n",
    "    print(\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "\n",
    "    # ì˜ˆì¸¡\n",
    "    print(\"ğŸ”® ì˜ˆì¸¡ ì¤‘...\")\n",
    "    y_pred_log = model.predict(X_test)\n",
    "    y_pred = np.expm1(y_pred_log)\n",
    "    y_pred = np.clip(y_pred, 0, None)  # ìŒìˆ˜ ì œê±°\n",
    "\n",
    "    # ì„±ëŠ¥ í‰ê°€\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ¯ CompanyPeople ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ê²°ê³¼\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"MSE:  {mse:,.0f}\")\n",
    "    print(f\"RMSE: {rmse:,.0f} ì›\")\n",
    "    print(f\"MAE:  {mae:,.0f} ì›\")\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê·  ë§¤ì¶œ: {y_test.mean():,.0f} ì›\")\n",
    "    print(f\"Out-of-Bag Score: {model.oob_score_:.4f}\")\n",
    "\n",
    "    # ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ì¶œë ¥\n",
    "    feature_importance = pd.DataFrame(\n",
    "        {\"feature\": X_train.columns, \"importance\": model.feature_importances_}\n",
    "    ).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    print(f\"\\n--- ìƒìœ„ 20ê°œ íŠ¹ì„± ì¤‘ìš”ë„ ---\")\n",
    "    for i, (_, row) in enumerate(feature_importance.head(20).iterrows(), 1):\n",
    "        is_people = any(\n",
    "            keyword in row[\"feature\"]\n",
    "            for keyword in [\"ì§ì¥_ì¸êµ¬_ìˆ˜\", \"ë‚¨ì„±_ì§ì¥\", \"ì—¬ì„±_ì§ì¥\", \"ì—°ë ¹ëŒ€_\"]\n",
    "        )\n",
    "        marker = \"ğŸ¢\" if is_people else \"ğŸª\"\n",
    "        print(f\"{i:2d}. {marker} {row['feature'][:50]}: {row['importance']:.4f}\")\n",
    "\n",
    "    # CompanyPeople ë°ì´í„° ê¸°ì—¬ë„\n",
    "    people_features = feature_importance[\n",
    "        feature_importance[\"feature\"].str.contains(\n",
    "            \"ì§ì¥_ì¸êµ¬_ìˆ˜|ë‚¨ì„±_ì§ì¥|ì—¬ì„±_ì§ì¥|ì—°ë ¹ëŒ€_\", regex=True\n",
    "        )\n",
    "    ]\n",
    "    people_importance = people_features[\"importance\"].sum()\n",
    "\n",
    "    print(\n",
    "        f\"\\nğŸ“Š CompanyPeople ë°ì´í„° ì´ ê¸°ì—¬ë„: {people_importance:.4f} ({people_importance*100:.1f}%)\"\n",
    "    )\n",
    "\n",
    "    if people_importance < 0.05:\n",
    "        print(\"âš ï¸ CompanyPeople ë°ì´í„° ê¸°ì—¬ë„ê°€ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤.\")\n",
    "    elif people_importance < 0.15:\n",
    "        print(\"ğŸ”¶ CompanyPeople ë°ì´í„° ê¸°ì—¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"âœ… CompanyPeople ë°ì´í„°ê°€ ìœ ì˜ë¯¸í•˜ê²Œ ê¸°ì—¬í•˜ê³  ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    return (\n",
    "        model,\n",
    "        {\"mse\": mse, \"rmse\": rmse, \"mae\": mae},\n",
    "        feature_importance,\n",
    "        people_importance,\n",
    "    )\n",
    "\n",
    "\n",
    "def save_model_and_metrics(\n",
    "    model, metrics, feature_importance_df, people_importance, config\n",
    "):\n",
    "    \"\"\"ëª¨ë¸ê³¼ í‰ê°€ì§€í‘œ ì €ì¥ (CompanyPeople ë²„ì „)\"\"\"\n",
    "\n",
    "    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ë””ë ‰í† ë¦¬ ê¸°ì¤€)\n",
    "    script_dir = os.getcwd()\n",
    "    results_dir = os.path.join(script_dir, \"results\")\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "        print(f\"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±: {results_dir}\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # 1. ëª¨ë¸ ì €ì¥\n",
    "    model_filename = os.path.join(\n",
    "        results_dir, f\"companypeople_model_{timestamp}.joblib\"\n",
    "    )\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"ğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_filename}\")\n",
    "\n",
    "    # 2. í‰ê°€ì§€í‘œ CSV ì €ì¥\n",
    "    metrics_data = {\n",
    "        \"ì‹¤í–‰ì‹œê°„\": [timestamp],\n",
    "        \"MSE\": [metrics[\"mse\"]],\n",
    "        \"RMSE\": [metrics[\"rmse\"]],\n",
    "        \"MAE\": [metrics[\"mae\"]],\n",
    "        \"CompanyPeople_ê¸°ì—¬ë„\": [people_importance],\n",
    "        \"CompanyPeople_ê¸°ì—¬ë„_í¼ì„¼íŠ¸\": [people_importance * 100],\n",
    "        \"OOB_Score\": [model.oob_score_],\n",
    "        \"í…ŒìŠ¤íŠ¸_ë…„ë„\": [config[\"test_year\"]],\n",
    "        \"í›ˆë ¨_ë°ì´í„°_í¬ê¸°\": [config[\"train_size\"]],\n",
    "        \"í…ŒìŠ¤íŠ¸_ë°ì´í„°_í¬ê¸°\": [config[\"test_size\"]],\n",
    "        \"íŠ¹ì„±_ê°œìˆ˜\": [config[\"n_features\"]],\n",
    "    }\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    metrics_filename = os.path.join(\n",
    "        results_dir, f\"companypeople_metrics_{timestamp}.csv\"\n",
    "    )\n",
    "    metrics_df.to_csv(metrics_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ“Š í‰ê°€ì§€í‘œ CSV ì €ì¥ ì™„ë£Œ: {metrics_filename}\")\n",
    "\n",
    "    # 3. íŠ¹ì„± ì¤‘ìš”ë„ ì €ì¥\n",
    "    importance_filename = os.path.join(\n",
    "        results_dir, f\"companypeople_importance_{timestamp}.csv\"\n",
    "    )\n",
    "    feature_importance_df.to_csv(importance_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ” íŠ¹ì„± ì¤‘ìš”ë„ CSV ì €ì¥ ì™„ë£Œ: {importance_filename}\")\n",
    "\n",
    "    # 4. ì‹¤í–‰ ì •ë³´ ìš”ì•½ ì €ì¥\n",
    "    summary_data = {\n",
    "        \"í•­ëª©\": [\n",
    "            \"ì‹¤í–‰ì‹œê°„\",\n",
    "            \"MSE\",\n",
    "            \"RMSE (ì›)\",\n",
    "            \"MAE (ì›)\",\n",
    "            \"CompanyPeople ê¸°ì—¬ë„ (%)\",\n",
    "            \"OOB Score\",\n",
    "            \"í…ŒìŠ¤íŠ¸ ë…„ë„\",\n",
    "            \"í›ˆë ¨ ë°ì´í„° í¬ê¸°\",\n",
    "            \"í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°\",\n",
    "            \"íŠ¹ì„± ê°œìˆ˜\",\n",
    "        ],\n",
    "        \"ê°’\": [\n",
    "            timestamp,\n",
    "            f\"{metrics['mse']:,.0f}\",\n",
    "            f\"{metrics['rmse']:,.0f}\",\n",
    "            f\"{metrics['mae']:,.0f}\",\n",
    "            f\"{people_importance*100:.1f}%\",\n",
    "            f\"{model.oob_score_:.4f}\",\n",
    "            config[\"test_year\"],\n",
    "            f\"{config['train_size']:,}\",\n",
    "            f\"{config['test_size']:,}\",\n",
    "            config[\"n_features\"],\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_filename = os.path.join(\n",
    "        results_dir, f\"companypeople_summary_{timestamp}.csv\"\n",
    "    )\n",
    "    summary_df.to_csv(summary_filename, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"ğŸ“‹ ëª¨ë¸ ìš”ì•½ CSV ì €ì¥ ì™„ë£Œ: {summary_filename}\")\n",
    "\n",
    "    print(f\"\\nğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ '{results_dir}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    return {\n",
    "        \"model_file\": model_filename,\n",
    "        \"metrics_file\": metrics_filename,\n",
    "        \"importance_file\": importance_filename,\n",
    "        \"summary_file\": summary_filename,\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"main í•¨ìˆ˜ (CompanyPeople ë²„ì „)\"\"\"\n",
    "    print(\"ğŸš€ CompanyPeople ìƒê¶Œ ë§¤ì¶œ ì˜ˆì¸¡ ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # ì„¤ì •\n",
    "    YEARS = range(2019, 2025)\n",
    "    PEOPLE_DIR = \"../../Data/CompanyPeople\"\n",
    "    BIZ_DIR = \"../../Data/Trading_Area\"\n",
    "    TEST_YEAR = 2024\n",
    "\n",
    "    try:\n",
    "        # 1. ë°ì´í„° ë¡œë“œ ë° ë³‘í•©\n",
    "        master_df = create_master_dataset_fixed(YEARS, PEOPLE_DIR, BIZ_DIR)\n",
    "\n",
    "        # 2. ë°ì´í„° ì „ì²˜ë¦¬\n",
    "        processed_df = preprocess_data_fixed(master_df)\n",
    "\n",
    "        # 3. ë°ì´í„° ë¶„í• \n",
    "        print(f\"\\n=== ë°ì´í„° ë¶„í•  ({TEST_YEAR}ë…„ í…ŒìŠ¤íŠ¸) ===\")\n",
    "        train_mask = processed_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] < (TEST_YEAR * 10 + 1)\n",
    "        test_mask = processed_df[\"ê¸°ì¤€_ë…„ë¶„ê¸°_ì½”ë“œ\"] >= (TEST_YEAR * 10 + 1)\n",
    "\n",
    "        train_df = processed_df[train_mask].copy()\n",
    "        test_df = processed_df[test_mask].copy()\n",
    "\n",
    "        print(f\"í›ˆë ¨ ë°ì´í„°: {len(train_df)}í–‰\")\n",
    "        print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_df)}í–‰\")\n",
    "\n",
    "        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\n",
    "        target_col = \"ë‹¹ì›”_ë§¤ì¶œ_ê¸ˆì•¡\"\n",
    "        feature_cols = [col for col in train_df.columns if col != target_col]\n",
    "\n",
    "        X_train = train_df[feature_cols]\n",
    "        y_train = train_df[target_col]\n",
    "        X_test = test_df[feature_cols]\n",
    "        y_test = test_df[target_col]\n",
    "\n",
    "        # ê²°ì¸¡ê°’ ì²˜ë¦¬\n",
    "        print(\"ê²°ì¸¡ê°’ ì²˜ë¦¬ ì¤‘...\")\n",
    "        imputer = SimpleImputer(strategy=\"mean\")\n",
    "        X_train_filled = pd.DataFrame(\n",
    "            imputer.fit_transform(X_train), columns=X_train.columns\n",
    "        )\n",
    "        X_test_filled = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "        # 4. ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "        model, metrics, feature_importance, people_importance = (\n",
    "            train_and_evaluate_model_fixed(\n",
    "                X_train_filled, y_train, X_test_filled, y_test\n",
    "            )\n",
    "        )\n",
    "\n",
    "        print(\"\\nğŸ‰ CompanyPeople ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        # 5. ëª¨ë¸ ë° ê²°ê³¼ ì €ì¥\n",
    "        config = {\n",
    "            \"test_year\": TEST_YEAR,\n",
    "            \"train_size\": len(train_df),\n",
    "            \"test_size\": len(test_df),\n",
    "            \"n_features\": len(feature_cols),\n",
    "        }\n",
    "        result = save_model_and_metrics(\n",
    "            model, metrics, feature_importance, people_importance, config\n",
    "        )\n",
    "\n",
    "        print(\"\\nğŸ‰ ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
